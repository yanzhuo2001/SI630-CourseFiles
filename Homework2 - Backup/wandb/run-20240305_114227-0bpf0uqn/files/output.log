
Epoch  0
Step 3000, Avg Loss: 0.6228839677174886
Step 6000, Avg Loss: 0.5001388376156489
Epoch  1
Step 3000, Avg Loss: 0.4536871209740639
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="RegexpTokenizer" type="ABCMeta" qualifier="abc" value="%3Cclass %27nltk.tokenize.regexp.RegexpTokenizer%27&gt;" isContainer="True" />
<var name="avg_loss" type="float" qualifier="builtins" value="0.4536871209740639" />
<var name="batch" type="list" qualifier="builtins" value="%5B0.6931471805599453%2C 2.0794415416798357%2C 3.4657359027997265%2C 4.1588830833596715%2C 4.852030263919617%2C 5.545177444479562%2C 6.238324625039508%2C 6.931471805599453%2C 7.6246189861593985%2C 8.317766166719343%2C 9.010913347279288%5D" isContainer="True" shape="11" />
<var name="batch1" type="int" qualifier="builtins" value="8192" />
<var name="batch_size" type="int" qualifier="builtins" value="8192" />
<var name="batch_sizes" type="list" qualifier="builtins" value="%5B2%2C 8%2C 32%2C 64%2C 128%2C 256%2C 512%2C 1024%2C 2048%2C 4096%2C 8192%5D" isContainer="True" shape="11" />
<var name="best_batch_size" type="int" qualifier="builtins" value="2048" />
<var name="context_ids" type="Tensor" qualifier="torch" value="tensor%28%5B%5B  266%2C  1280%2C  1233%2C  ...%2C   258%2C 10325%2C  1239%5D%2C%0A        %5B 1295%2C   643%2C   377%2C  ...%2C  2505%2C  2573%2C  1105%5D%2C%0A        %5B ...%5B 2366%2C  9035%2C  2622%2C  ...%2C 29682%2C    21%2C 11685%5D%2C%0A        %5B   76%2C  1879%2C  3514%2C  ...%2C  2508%2C  5807%2C 13592%5D%5D%2C dtype=torch.int32%29" isContainer="True" shape="(2048, 12)" />
<var name="context_size" type="int" qualifier="builtins" value="12" />
<var name="corpus" type="Corpus" qualifier="__main__" value="%3C__main__.Corpus object at 0x0000027422C91010&gt;" isContainer="True" />
<var name="criterion" type="BCELoss" qualifier="torch.nn.modules.loss" value="BCELoss%28%29" isContainer="True" />
<var name="data" type="list" qualifier="builtins" value="%5Btensor%28%5B   13%2C   184%2C    78%2C  ...%2C    11%2C 28488%2C    29%5D%2C dtype=torch.int32%29%2C tensor%28%5B%5B  266%2C  1280%2C  1233%2C  ...%2C   258%2C 10325%2C  1239%5D%2C%0A        %5B 1295%2C   643%2C   377%2C  ...%2C  2505%2C  2573%2C  1105%5D%2C%0A        %5B ...%5B 2366%2C  9035%2C  2622%2C  ...%2C 29682%2C    21%2C 11685%5D%2C%0A        %5B   76%2C  1879%2C  3514%2C  ...%2C  2508%2C  5807%2C 13592%5D%5D%2C dtype=torch.int32%29%2C tensor%28%5B%5B1.%2C 1.%2C 1.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A        %5B1.%2C 1.%2C 1.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A        %5B1.%2C 1.%2C 1.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A      ....%2C 0.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A        %5B1.%2C 1.%2C 1.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A        %5B1.%2C 1.%2C 0.%2C  ...%2C 0.%2C 0.%2C 0.%5D%5D%2C dtype=torch.float64%29%5D" isContainer="True" shape="3" />
<var name="device" type="device" qualifier="torch" value="device%28type=%27cpu%27%29" isContainer="True" />
<var name="embedding_size" type="int" qualifier="builtins" value="50" />
<var name="end_time" type="float" qualifier="builtins" value="1709609188.165713" />
<var name="epoch" type="int" qualifier="builtins" value="1" />
<var name="estimated_time_per_epoch" type="float" qualifier="builtins" value="1042.653461651802" />
<var name="estimated_times_per_epoch" type="list" qualifier="builtins" value="%5B289599.46827554225%2C 68143.46297184705%2C 17810.88461116791%2C 8879.608075675964%2C 4704.605176699161%2C 2528.0013314342496%2C 1410.881297879219%2C 897.8396677017212%2C 581.737455124855%2C 1186.9392780494688%2C 1042.653461651802%5D" isContainer="True" shape="11" />
<var name="f" type="BufferedWriter" qualifier="_io" value="%3C_io.BufferedWriter name=%27./models/1st_model_index_to_word.pkl%27&gt;" isContainer="True" />
<var name="index_to_word" type="dict" qualifier="builtins" value="%7B0%3A %27this%27%2C 1%3A %27was%27%2C 2%3A %27bought%27%2C 3%3A %27as%27%2C 4%3A %27a%27%2C 5%3A %27gift%27%2C 6%3A %27but%27%2C 7%3A %27the%27%2C 8%3A %27person%27%2C 9%3A %27who%27%2C 10%3A %27got%27%2C 11%3A %27it%27%2C 12%3A %27loved%27%2C 13%3A %27and%27%2C 14%3A %27they%27%2C 15%3A %27will%27%2C 16%3A %27use%27%2C 17%3A %27soon%27%2C 18%3A %27very%27%2C 19%3A %27well%27%2C 20%3A %27written%27%2C 21%3A %27book%27%2C 22%3A %27on%27%2C 23%3A %27period%27%2C 24%3A %27of%27%2C 25%3A %27world%27%2C 26%3A %27history%27%2C 27%3A %27with%27%2C 28%3A %27which%27%2C 29%3A %27i%27%2C 30%3A %27am%27%2C 31%3A %27familiar%27%2C 32%3A %27despite%27%2C 33%3A %27my%27%2C 34%3A %27familiarity%27%2C 35%3A %27subject%27%2C 36%3A %27area%27%2C 37%3A %27learned%27%2C 38%3A %27lot%27%2C 39%3A %27new%27%2C 40%3A %27information%27%2C 41%3A %27also%27%2C 42%3A %27one%27%2C 43%3A %27best%27%2C 44%3A %27concise%27%2C 45%3A %27descriptions%27%2C 46%3A %27wwii%27%2C 47%3A %27that%27%2C 48%3A %27have%27%2C 49%3A %27ever%27%2C 50%3A %27read%27%2C 51%3A %27thought%27%2C 52%3A %27provoking%27%2C 53%3A %27hot%27%2C 54%3A %27cross%27%2C 55%3A %27buns%27%2C 56%3A %27contains%27%2C 57%3A %27cast%27%2C 58%3A %27characters%27%2C 59%3A %27you%27%2C 60%3A %27fall%27%2C 61%3A %27in%27%2C 62%3A %27love%27%2C 63%3A %27want%27%2C 64%3A %27to%27%2C 65%3A %27hang%27%2C 66%3A %27out%27%2C 67%3A %27has%27%2C 68%3A %27few%27%2C 69%3A %27different%27%2C 70%3A %27plot%27%2C 71%3A %27story%27%2C 72%3A %27lines%27%2C 73%3A %27intersect%27%2C 74%3A %27unexpected%27%2C 75%3A %27ways%27%2C 76%3A %27stories%27%2C 77%3A %27are%27%2C 78%3A %27full%27%2C 79%3A %27h..." isContainer="True" shape="40547" />
<var name="labels" type="Tensor" qualifier="torch" value="tensor%28%5B%5B1.%2C 1.%2C 1.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A        %5B1.%2C 1.%2C 1.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A        %5B1.%2C 1.%2C 1.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A      ....%2C 0.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A        %5B1.%2C 1.%2C 1.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A        %5B1.%2C 1.%2C 0.%2C  ...%2C 0.%2C 0.%2C 0.%5D%5D%2C dtype=torch.float64%29" isContainer="True" shape="(2048, 12)" />
<var name="last_loss_sum" type="int" qualifier="builtins" value="0" />
<var name="loss" type="Tensor" qualifier="torch" value="tensor%280.4496%2C grad_fn=%3CBinaryCrossEntropyBackward0&gt;%29" isContainer="True" shape="()" />
<var name="loss_sum" type="float" qualifier="builtins" value="103.7759148478508" />
<var name="lr" type="float" qualifier="builtins" value="5e-05" />
<var name="max_step" type="int" qualifier="builtins" value="1000000000" />
<var name="model" type="Word2Vec" qualifier="__main__" value="Word2Vec%28%0A  %28target_embeddings%29%3A Embedding%2840547%2C 50%29%0A  %28context_embeddings%29%3A Embedding%2840547%2C 50%29%0A  %28sig%29%3A Sigmoid%28%29%0A%29" isContainer="True" />
<var name="model_name" type="str" qualifier="builtins" value="1st_model" />
<var name="num_epoch" type="int" qualifier="builtins" value="6" />
<var name="num_negative_samples_per_target" type="int" qualifier="builtins" value="2" />
<var name="optimizer" type="Adam" qualifier="torch.optim.adam" value="Adam %28%0AParameter Group 0%0A    amsgrad%3A False%0A    betas%3A %280.9%2C 0.999%29%0A    capturable%3A False%0A    differentiable%3A False%0A    eps%3A 1e-08%0A    foreach%3A None%0A    fused%3A None%0A    lr%3A 5e-05%0A    maximize%3A False%0A    weight_decay%3A 0%0A%29" isContainer="True" />
<var name="outputs" type="Tensor" qualifier="torch" value="tensor%28%5B%5B0.4442%2C 0.2355%2C 0.4295%2C  ...%2C 0.0072%2C 0.2098%2C 0.2278%5D%2C%0A        %5B0.2870%2C 0.4022%2C 0.3175%2C  ...%2C 0.2470%2C 0.2687%2C 0.4026%5D....%2C 0.4832%2C 0.4903%2C 0.4613%5D%2C%0A        %5B0.3767%2C 0.2335%2C 0.0899%2C  ...%2C 0.2927%2C 0.1712%2C 0.1662%5D%5D%2C%0A       grad_fn=%3CSqueezeBackward0&gt;%29" isContainer="True" shape="(2048, 12)" />
<var name="start_time" type="float" qualifier="builtins" value="1709609131.8365147" />
<var name="step" type="int" qualifier="builtins" value="3231" />
<var name="stop_words" type="set" qualifier="builtins" value="%7B%27a%27%2C %27about%27%2C %27above%27%2C %27after%27%2C %27again%27%2C %27against%27%2C %27ain%27%2C %27all%27%2C %27am%27%2C %27an%27%2C %27and%27%2C %27any%27%2C %27are%27%2C %27aren%27%2C %22aren%27t%22%2C %27as%27%2C %27at%27%2C %27be%27%2C %27because%27%2C %27been%27%2C %27before%27%2C %27being%27%2C %27below%27%2C %27between%27%2C %27both%27%2C %27but%27%2C %27by%27%2C %27can%27%2C %27couldn%27%2C %22couldn%27t%22%2C %27d%27%2C %27did%27%2C %27didn%27%2C %22didn%27t%22%2C %27do%27%2C %27does%27%2C %27doesn%27%2C %22doesn%27t%22%2C %27doing%27%2C %27don%27%2C %22don%27t%22%2C %27down%27%2C %27during%27%2C %27each%27%2C %27few%27%2C %27for%27%2C %27from%27%2C %27further%27%2C %27had%27%2C %27hadn%27%2C %22hadn%27t%22%2C %27has%27%2C %27hasn%27%2C %22hasn%27t%22%2C %27have%27%2C %27haven%27%2C %22haven%27t%22%2C %27having%27%2C %27he%27%2C %27her%27%2C %27here%27%2C %27hers%27%2C %27herself%27%2C %27him%27%2C %27himself%27%2C %27his%27%2C %27how%27%2C %27i%27%2C %27if%27%2C %27in%27%2C %27into%27%2C %27is%27%2C %27isn%27%2C %22isn%27t%22%2C %27it%27%2C %22it%27s%22%2C %27its%27%2C %27itself%27%2C %27just%27%2C %27ll%27%2C %27m%27%2C %27ma%27%2C %27me%27%2C %27mightn%27%2C %22mightn%27t%22%2C %27more%27%2C %27most%27%2C %27mustn%27%2C %22mustn%27t%22%2C %27my%27%2C %27myself%27%2C %27needn%27%2C %22needn%27t%22%2C %27no%27%2C %27nor%27%2C %27not%27%2C %27now%27%2C %27o%27%2C %27of%27%2C %27off%27%2C %27on%27%2C %27once%27%2C %27only%27%2C %27or%27%2C %27other%27%2C %27our%27%2C %27ours%27%2C %27ourselves%27%2C %27out%27%2C %27over%27%2C %27own%27%2C %27re%27%2C %27s%27%2C %27same%27%2C %27shan%27%2C %22shan%27t%22%2C %27she%27%2C %22she%27s%22%2C %27should%27%2C %22should%27ve%22%2C %27shouldn%27%2C %22shouldn%27t%22%2C %27so%27%2C %27some%27%2C..." isContainer="True" shape="179" />
<var name="stopwords" type="WordListCorpusReader" qualifier="nltk.corpus.reader.wordlist" value="%3CWordListCorpusReader in %27C%3A%5C%5CUsers%5C%5C16979%5C%5CAppData%5C%5CRoaming%5C%5Cnltk_data%5C%5Ccorpora%5C%5Cstopwords%27&gt;" isContainer="True" />
<var name="target_ids" type="Tensor" qualifier="torch" value="tensor%28%5B   13%2C   184%2C    78%2C  ...%2C    11%2C 28488%2C    29%5D%2C dtype=torch.int32%29" isContainer="True" shape="(2048,)" />
<var name="time1" type="float" qualifier="builtins" value="1042.653461651802" />
<var name="time_per_batch" type="float" qualifier="builtins" value="0.5632919836044311" />
<var name="times" type="list" qualifier="builtins" value="%5B12.576254103426896%2C 11.129370511347823%2C 9.787565044402719%2C 9.091512699390135%2C 8.456297132812743%2C 7.83518428194155%2C 7.251969822076738%2C 6.799991508599361%2C 6.366019237918704%2C 7.079133237487744%2C 6.949524148260695%5D" isContainer="True" shape="11" />
<var name="times_per_batch" type="list" qualifier="builtins" value="%5B0.038215651512145996%2C 0.03596893072128296%2C 0.0376052188873291%2C 0.03749612808227539%2C 0.039732491970062254%2C 0.042699840068817135%2C 0.0476616883277893%2C 0.06066074371337891%2C 0.07860254764556884%2C 0.32070772171020506%2C 0.5632919836044311%5D" isContainer="True" shape="11" />
<var name="train_dataloader" type="DataLoader" qualifier="torch.utils.data.dataloader" value="%3Ctorch.utils.data.dataloader.DataLoader object at 0x0000027432B62DE0&gt;" isContainer="True" shape="7401" />
<var name="training_data" type="list" qualifier="builtins" value="%5B%282%2C %5B   5  255   11 2310 2056 7954 9694  662   41   63 9193  210%5D%2C %5B1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %285%2C %5B   2    8  192    1  333 5383  123 1960 1522  104  163 6917%5D%2C %5B1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %287%2C %5B    2     5     8   801    71  9392  3565 15285  3574 23772    11   281%5D%2C %5B1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %288%2C %5B    5    10  3276  1217 16109   566    92  9156  2188   410   104  2181%5D%2C %5B1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %289%2C %5B   8   10   12  626   48 8834  757    0  505  225  310 2134%5D%2C %5B1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %2810%2C %5B    8    12    13  4793    98  4408  3245   504 10475    24 20680  2725%5D%2C %5B1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %2812%2C %5B   10 17698 12442    24 11642  1954     4  2105   442   229   411  2737%5D%2C %5B1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %2814%2C %5B   10    12    16    64   207  2479  1236  2288 10731  3866  2269  4415%5D%2C %5B1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %2815%2C %5B   12    16  3665  1851     0 28633     0    10  9698    83   477   210%5D%2C ..." isContainer="True" shape="15156066" />
<var name="vocab_size" type="int" qualifier="builtins" value="40547" />
<var name="window_size" type="int" qualifier="builtins" value="2" />
<var name="word_to_index" type="dict" qualifier="builtins" value="%7B%270%27%3A 6860%2C %2700%27%3A 7030%2C %27000%27%3A 7717%2C %27001%27%3A 38825%2C %27007%27%3A 28099%2C %2700am%27%3A 25993%2C %2701%27%3A 24762%2C %2702%27%3A 29846%2C %2703%27%3A 11089%2C %27039%27%3A 38140%2C %2704%27%3A 8057%2C %2705%27%3A 32280%2C %2706%27%3A 30353%2C %2707%27%3A 7063%2C %2708%27%3A 24586%2C %2709%27%3A 22275%2C %270f%27%3A 37971%2C %271%27%3A 793%2C %2710%27%3A 1684%2C %27100%27%3A 870%2C %271000%27%3A 10968%2C %2710000%27%3A 31123%2C %271000s%27%3A 20833%2C %271000x%27%3A 33996%2C %271001%27%3A 7910%2C %27100k%27%3A 39109%2C %27100s%27%3A 25367%2C %27100th%27%3A 879%2C %27101%27%3A 7005%2C %27101st%27%3A 26963%2C %27102%27%3A 29336%2C %27103%27%3A 31073%2C %27104%27%3A 31072%2C %27105%27%3A 27289%2C %27106%27%3A 11911%2C %271066%27%3A 34895%2C %27107%27%3A 733%2C %27108%27%3A 15245%2C %27109%27%3A 34772%2C %2710k%27%3A 16506%2C %2710th%27%3A 24530%2C %2710x%27%3A 22765%2C %2710yr%27%3A 28921%2C %2711%27%3A 3831%2C %27110%27%3A 18961%2C %271100%27%3A 36651%2C %27111%27%3A 18962%2C %27112%27%3A 11145%2C %27113%27%3A 32771%2C %27114%27%3A 24557%2C %27115%27%3A 15244%2C %27116%27%3A 19634%2C %27117%27%3A 39597%2C %27118%27%3A 21937%2C %27119%27%3A 38487%2C %2711pm%27%3A 25792%2C %2711th%27%3A 10687%2C %2712%27%3A 1681%2C %27120%27%3A 14299%2C %271200%27%3A 13958%2C %27121%27%3A 33184%2C %27122%27%3A 38431%2C %27123%27%3A 18402%2C %27124%27%3A 39041%2C %27125%27%3A 25024%2C %27126%27%3A 39242%2C %27127%27%3A 35211%2C %27128%27%3A 37280%2C %27129%27%3A 39683%2C %2712th%27%3A 10890%2C %2712yr%27%3A 17641%2C %2713%27%3A 3671%2C %27130%27..." isContainer="True" shape="40547" />
<var name="writer" type="SummaryWriter" qualifier="torch.utils.tensorboard.writer" value="%3Ctorch.utils.tensorboard.writer.SummaryWriter object at 0x000002741F5BC200&gt;" isContainer="True" />
</xml>
Reading data and tokenizing
[nltk_data] Downloading package stopwords to
[nltk_data]     C:\Users\16979\AppData\Roaming\nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
Counting token frequencies
Performing minimum thresholding
Updating token frequencies after filtering <UNK>
Create words and id mapping
Compute probability of subsampling
Create all token ID list
Loaded all data from reviews-word2vec.large.txt.gz; saw 15156066 tokens (40547 unique)
Generating negative sampling table