
Epoch  0
Step 100, Avg Loss: 0.6833540469408035
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="RegexpTokenizer" type="ABCMeta" qualifier="abc" value="%3Cclass %27nltk.tokenize.regexp.RegexpTokenizer%27&gt;" isContainer="True" />
<var name="avg_loss" type="float" qualifier="builtins" value="0.6833540469408035" />
<var name="batch_size" type="int" qualifier="builtins" value="1024" />
<var name="batch_sizes" type="list" qualifier="builtins" value="%5B2%2C 8%2C 32%2C 64%2C 128%2C 256%2C 512%2C 1024%2C 2048%2C 4096%2C 8192%5D" isContainer="True" shape="11" />
<var name="best_batch_size" type="int" qualifier="builtins" value="256" />
<var name="context_ids" type="Tensor" qualifier="torch" value="tensor%28%5B%5B 3967%2C  3265%2C   437%2C  ...%2C  3344%2C 14537%2C     3%5D%2C%0A        %5B 8774%2C   751%2C 10744%2C  ...%2C   733%2C 13410%2C  1340%5D%2C%0A        %5B ...%5B   50%2C   106%2C    98%2C  ...%2C  7288%2C  7460%2C    67%5D%2C%0A        %5B   19%2C   242%2C    24%2C  ...%2C   156%2C 16334%2C  8247%5D%5D%2C dtype=torch.int32%29" isContainer="True" shape="(256, 12)" />
<var name="context_size" type="int" qualifier="builtins" value="12" />
<var name="corpus" type="Corpus" qualifier="__main__" value="%3C__main__.Corpus object at 0x000001B9DF963E30&gt;" isContainer="True" />
<var name="criterion" type="BCELoss" qualifier="torch.nn.modules.loss" value="BCELoss%28%29" isContainer="True" />
<var name="data" type="list" qualifier="builtins" value="%5Btensor%28%5B    7%2C   700%2C   257%2C 12023%2C  8113%2C   128%2C    18%2C   513%2C  3929%2C     7%2C%0A          873%2C  8395%2C    28%2C    50%2C   221%2C    21...%2C   177%2C    19%2C   340%2C  4296%2C  3215%2C  2029%2C    71%2C   175%2C%0A           21%2C  1146%2C   979%2C    59%2C   637%2C   221%5D%2C dtype=torch.int32%29%2C tensor%28%5B%5B 3967%2C  3265%2C   437%2C  ...%2C  3344%2C 14537%2C     3%5D%2C%0A        %5B 8774%2C   751%2C 10744%2C  ...%2C   733%2C 13410%2C  1340%5D%2C%0A        %5B ...%5B   50%2C   106%2C    98%2C  ...%2C  7288%2C  7460%2C    67%5D%2C%0A        %5B   19%2C   242%2C    24%2C  ...%2C   156%2C 16334%2C  8247%5D%5D%2C dtype=torch.int32%29%2C tensor%28%5B%5B1.%2C 1.%2C 1.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A        %5B1.%2C 1.%2C 0.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A        %5B1.%2C 1.%2C 1.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A      ....%2C 1.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A        %5B1.%2C 1.%2C 0.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A        %5B1.%2C 0.%2C 0.%2C  ...%2C 0.%2C 0.%2C 0.%5D%5D%2C dtype=torch.float64%29%5D" isContainer="True" shape="3" />
<var name="device" type="device" qualifier="torch" value="device%28type=%27cpu%27%29" isContainer="True" />
<var name="embedding_size" type="int" qualifier="builtins" value="50" />
<var name="end_time" type="float" qualifier="builtins" value="1709538301.5303206" />
<var name="epoch" type="int" qualifier="builtins" value="0" />
<var name="estimated_time_per_epoch" type="float" qualifier="builtins" value="472451.6426421833" />
<var name="estimated_times_per_epoch" type="list" qualifier="builtins" value="%5B12023663.246537393%2C 3030037.749051013%2C 990769.4440470601%2C 668150.7084301471%2C 512695.93168382405%2C 427523.36273840663%2C 472451.6426421833%5D" isContainer="True" shape="7" />
<var name="labels" type="Tensor" qualifier="torch" value="tensor%28%5B%5B1.%2C 1.%2C 1.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A        %5B1.%2C 1.%2C 0.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A        %5B1.%2C 1.%2C 1.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A      ....%2C 1.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A        %5B1.%2C 1.%2C 0.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A        %5B1.%2C 0.%2C 0.%2C  ...%2C 0.%2C 0.%2C 0.%5D%5D%2C dtype=torch.float64%29" isContainer="True" shape="(256, 12)" />
<var name="last_loss_sum" type="int" qualifier="builtins" value="0" />
<var name="loss" type="Tensor" qualifier="torch" value="tensor%280.6283%2C grad_fn=%3CBinaryCrossEntropyBackward0&gt;%29" isContainer="True" shape="()" />
<var name="loss_sum" type="float" qualifier="builtins" value="23.838708221912384" />
<var name="lr" type="float" qualifier="builtins" value="0.001" />
<var name="max_step" type="int" qualifier="builtins" value="1000000000" />
<var name="model" type="Word2Vec" qualifier="__main__" value="Word2Vec%28%0A  %28target_embeddings%29%3A Embedding%28120361%2C 50%29%0A  %28context_embeddings%29%3A Embedding%28120361%2C 50%29%0A  %28sig%29%3A Sigmoid%28%29%0A%29" isContainer="True" />
<var name="num_epoch" type="int" qualifier="builtins" value="1" />
<var name="num_negative_samples_per_target" type="int" qualifier="builtins" value="2" />
<var name="optimizer" type="Adam" qualifier="torch.optim.adam" value="Adam %28%0AParameter Group 0%0A    amsgrad%3A False%0A    betas%3A %280.9%2C 0.999%29%0A    capturable%3A False%0A    differentiable%3A False%0A    eps%3A 1e-08%0A    foreach%3A None%0A    fused%3A None%0A    lr%3A 0.001%0A    maximize%3A False%0A    weight_decay%3A 0%0A%29" isContainer="True" />
<var name="outputs" type="Tensor" qualifier="torch" value="tensor%28%5B%5B0.5029%2C 0.4659%2C 0.4282%2C  ...%2C 0.4372%2C 0.4289%2C 0.2113%5D%2C%0A        %5B0.4574%2C 0.4638%2C 0.4765%2C  ...%2C 0.5032%2C 0.4855%2C 0.4660%5D....%2C 0.4880%2C 0.4629%2C 0.3134%5D%2C%0A        %5B0.5011%2C 0.4493%2C 0.3075%2C  ...%2C 0.3163%2C 0.4859%2C 0.4926%5D%5D%2C%0A       grad_fn=%3CSqueezeBackward0&gt;%29" isContainer="True" shape="(256, 12)" />
<var name="start_time" type="float" qualifier="builtins" value="1709538301.6347365" />
<var name="step" type="int" qualifier="builtins" value="136" />
<var name="stop_words" type="set" qualifier="builtins" value="%7B%27a%27%2C %27about%27%2C %27above%27%2C %27after%27%2C %27again%27%2C %27against%27%2C %27ain%27%2C %27all%27%2C %27am%27%2C %27an%27%2C %27and%27%2C %27any%27%2C %27are%27%2C %27aren%27%2C %22aren%27t%22%2C %27as%27%2C %27at%27%2C %27be%27%2C %27because%27%2C %27been%27%2C %27before%27%2C %27being%27%2C %27below%27%2C %27between%27%2C %27both%27%2C %27but%27%2C %27by%27%2C %27can%27%2C %27couldn%27%2C %22couldn%27t%22%2C %27d%27%2C %27did%27%2C %27didn%27%2C %22didn%27t%22%2C %27do%27%2C %27does%27%2C %27doesn%27%2C %22doesn%27t%22%2C %27doing%27%2C %27don%27%2C %22don%27t%22%2C %27down%27%2C %27during%27%2C %27each%27%2C %27few%27%2C %27for%27%2C %27from%27%2C %27further%27%2C %27had%27%2C %27hadn%27%2C %22hadn%27t%22%2C %27has%27%2C %27hasn%27%2C %22hasn%27t%22%2C %27have%27%2C %27haven%27%2C %22haven%27t%22%2C %27having%27%2C %27he%27%2C %27her%27%2C %27here%27%2C %27hers%27%2C %27herself%27%2C %27him%27%2C %27himself%27%2C %27his%27%2C %27how%27%2C %27i%27%2C %27if%27%2C %27in%27%2C %27into%27%2C %27is%27%2C %27isn%27%2C %22isn%27t%22%2C %27it%27%2C %22it%27s%22%2C %27its%27%2C %27itself%27%2C %27just%27%2C %27ll%27%2C %27m%27%2C %27ma%27%2C %27me%27%2C %27mightn%27%2C %22mightn%27t%22%2C %27more%27%2C %27most%27%2C %27mustn%27%2C %22mustn%27t%22%2C %27my%27%2C %27myself%27%2C %27needn%27%2C %22needn%27t%22%2C %27no%27%2C %27nor%27%2C %27not%27%2C %27now%27%2C %27o%27%2C %27of%27%2C %27off%27%2C %27on%27%2C %27once%27%2C %27only%27%2C %27or%27%2C %27other%27%2C %27our%27%2C %27ours%27%2C %27ourselves%27%2C %27out%27%2C %27over%27%2C %27own%27%2C %27re%27%2C %27s%27%2C %27same%27%2C %27shan%27%2C %22shan%27t%22%2C %27she%27%2C %22she%27s%22%2C %27should%27%2C %22should%27ve%22%2C %27shouldn%27%2C %22shouldn%27t%22%2C %27so%27%2C %27some%27%2C..." isContainer="True" shape="179" />
<var name="stopwords" type="WordListCorpusReader" qualifier="nltk.corpus.reader.wordlist" value="%3CWordListCorpusReader in %27C%3A%5C%5CUsers%5C%5C16979%5C%5CAppData%5C%5CRoaming%5C%5Cnltk_data%5C%5Ccorpora%5C%5Cstopwords%27&gt;" isContainer="True" />
<var name="target_ids" type="Tensor" qualifier="torch" value="tensor%28%5B    7%2C   700%2C   257%2C 12023%2C  8113%2C   128%2C    18%2C   513%2C  3929%2C     7%2C%0A          873%2C  8395%2C    28%2C    50%2C   221%2C    21...%2C   177%2C    19%2C   340%2C  4296%2C  3215%2C  2029%2C    71%2C   175%2C%0A           21%2C  1146%2C   979%2C    59%2C   637%2C   221%5D%2C dtype=torch.int32%29" isContainer="True" shape="(256,)" />
<var name="time_per_batch" type="float" qualifier="builtins" value="1.5880834245681763" />
<var name="times_per_batch" type="list" qualifier="builtins" value="%5B0.15787519931793212%2C 0.15914211750030519%2C 0.2081467652320862%2C 0.2807381868362427%2C 0.4308408999443054%2C 0.7185326981544494%2C 1.5880834245681763%5D" isContainer="True" shape="7" />
<var name="train_dataloader" type="DataLoader" qualifier="torch.utils.data.dataloader" value="%3Ctorch.utils.data.dataloader.DataLoader object at 0x000001B9DFBB2A50&gt;" isContainer="True" shape="594995" />
<var name="training_data" type="list" qualifier="builtins" value="%5B%282%2C %5B    5   284    11  2901  2568 10895 13946   759    47    64 13137   242%5D%2C %5B1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %285%2C %5B   2    8  207    1  375 7031  142 2411 1804  119  195 9268%5D%2C %5B1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %287%2C %5B    2     5     8   986    80 13432  4505 24472  4543 45907    11   313%5D%2C %5B1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %288%2C %5B    5    10  4091  1456 26266   683    98 13093  2693   514   117  2683%5D%2C %5B1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %289%2C %5B    8    10    12   733    50 12489   903     0   621   261   339  2626%5D%2C %5B1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %2810%2C %5B    8    12    13  6221   108  5677  4030   606 15276    24 37235  3387%5D%2C %5B1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %2812%2C %5B   10 29946 18971    27 17476  2392     4  2597   545   264   514  3398%5D%2C %5B1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %2814%2C %5B   10    12    16    67   235  3114  1506  2872 15734  4945  2830  5685%5D%2C %5B1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %2815%2C %5B   12    16  4674  2245     1 62509     0    11 13..." isContainer="True" shape="152318582" />
<var name="vocab_size" type="int" qualifier="builtins" value="120361" />
<var name="window_size" type="int" qualifier="builtins" value="2" />
<var name="writer" type="SummaryWriter" qualifier="torch.utils.tensorboard.writer" value="%3Ctorch.utils.tensorboard.writer.SummaryWriter object at 0x000001B9DFA52F60&gt;" isContainer="True" />
</xml>
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="RegexpTokenizer" type="ABCMeta" qualifier="abc" value="%3Cclass %27nltk.tokenize.regexp.RegexpTokenizer%27&gt;" isContainer="True" />
<var name="avg_loss" type="float" qualifier="builtins" value="0.6833540469408035" />
<var name="batch_size" type="int" qualifier="builtins" value="1024" />
<var name="batch_sizes" type="list" qualifier="builtins" value="%5B2%2C 8%2C 32%2C 64%2C 128%2C 256%2C 512%2C 1024%2C 2048%2C 4096%2C 8192%5D" isContainer="True" shape="11" />
<var name="best_batch_size" type="int" qualifier="builtins" value="256" />
<var name="context_ids" type="Tensor" qualifier="torch" value="tensor%28%5B%5B 3967%2C  3265%2C   437%2C  ...%2C  3344%2C 14537%2C     3%5D%2C%0A        %5B 8774%2C   751%2C 10744%2C  ...%2C   733%2C 13410%2C  1340%5D%2C%0A        %5B ...%5B   50%2C   106%2C    98%2C  ...%2C  7288%2C  7460%2C    67%5D%2C%0A        %5B   19%2C   242%2C    24%2C  ...%2C   156%2C 16334%2C  8247%5D%5D%2C dtype=torch.int32%29" isContainer="True" shape="(256, 12)" />
<var name="context_size" type="int" qualifier="builtins" value="12" />
<var name="corpus" type="Corpus" qualifier="__main__" value="%3C__main__.Corpus object at 0x000001B9DF963E30&gt;" isContainer="True" />
<var name="criterion" type="BCELoss" qualifier="torch.nn.modules.loss" value="BCELoss%28%29" isContainer="True" />
<var name="data" type="list" qualifier="builtins" value="%5Btensor%28%5B    7%2C   700%2C   257%2C 12023%2C  8113%2C   128%2C    18%2C   513%2C  3929%2C     7%2C%0A          873%2C  8395%2C    28%2C    50%2C   221%2C    21...%2C   177%2C    19%2C   340%2C  4296%2C  3215%2C  2029%2C    71%2C   175%2C%0A           21%2C  1146%2C   979%2C    59%2C   637%2C   221%5D%2C dtype=torch.int32%29%2C tensor%28%5B%5B 3967%2C  3265%2C   437%2C  ...%2C  3344%2C 14537%2C     3%5D%2C%0A        %5B 8774%2C   751%2C 10744%2C  ...%2C   733%2C 13410%2C  1340%5D%2C%0A        %5B ...%5B   50%2C   106%2C    98%2C  ...%2C  7288%2C  7460%2C    67%5D%2C%0A        %5B   19%2C   242%2C    24%2C  ...%2C   156%2C 16334%2C  8247%5D%5D%2C dtype=torch.int32%29%2C tensor%28%5B%5B1.%2C 1.%2C 1.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A        %5B1.%2C 1.%2C 0.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A        %5B1.%2C 1.%2C 1.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A      ....%2C 1.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A        %5B1.%2C 1.%2C 0.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A        %5B1.%2C 0.%2C 0.%2C  ...%2C 0.%2C 0.%2C 0.%5D%5D%2C dtype=torch.float64%29%5D" isContainer="True" shape="3" />
<var name="device" type="device" qualifier="torch" value="device%28type=%27cpu%27%29" isContainer="True" />
<var name="embedding_size" type="int" qualifier="builtins" value="50" />
<var name="end_time" type="float" qualifier="builtins" value="1709538301.5303206" />
<var name="epoch" type="int" qualifier="builtins" value="0" />
<var name="estimated_time_per_epoch" type="float" qualifier="builtins" value="472451.6426421833" />
<var name="estimated_times_per_epoch" type="list" qualifier="builtins" value="%5B12023663.246537393%2C 3030037.749051013%2C 990769.4440470601%2C 668150.7084301471%2C 512695.93168382405%2C 427523.36273840663%2C 472451.6426421833%5D" isContainer="True" shape="7" />
<var name="labels" type="Tensor" qualifier="torch" value="tensor%28%5B%5B1.%2C 1.%2C 1.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A        %5B1.%2C 1.%2C 0.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A        %5B1.%2C 1.%2C 1.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A      ....%2C 1.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A        %5B1.%2C 1.%2C 0.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A        %5B1.%2C 0.%2C 0.%2C  ...%2C 0.%2C 0.%2C 0.%5D%5D%2C dtype=torch.float64%29" isContainer="True" shape="(256, 12)" />
<var name="last_loss_sum" type="int" qualifier="builtins" value="0" />
<var name="loss" type="Tensor" qualifier="torch" value="tensor%280.6283%2C grad_fn=%3CBinaryCrossEntropyBackward0&gt;%29" isContainer="True" shape="()" />
<var name="loss_sum" type="float" qualifier="builtins" value="23.838708221912384" />
<var name="lr" type="float" qualifier="builtins" value="0.001" />
<var name="max_step" type="int" qualifier="builtins" value="10000" />
<var name="model" type="Word2Vec" qualifier="__main__" value="Word2Vec%28%0A  %28target_embeddings%29%3A Embedding%28120361%2C 50%29%0A  %28context_embeddings%29%3A Embedding%28120361%2C 50%29%0A  %28sig%29%3A Sigmoid%28%29%0A%29" isContainer="True" />
<var name="num_epoch" type="int" qualifier="builtins" value="1" />
<var name="num_negative_samples_per_target" type="int" qualifier="builtins" value="2" />
<var name="optimizer" type="Adam" qualifier="torch.optim.adam" value="Adam %28%0AParameter Group 0%0A    amsgrad%3A False%0A    betas%3A %280.9%2C 0.999%29%0A    capturable%3A False%0A    differentiable%3A False%0A    eps%3A 1e-08%0A    foreach%3A None%0A    fused%3A None%0A    lr%3A 0.001%0A    maximize%3A False%0A    weight_decay%3A 0%0A%29" isContainer="True" />
<var name="outputs" type="Tensor" qualifier="torch" value="tensor%28%5B%5B0.5029%2C 0.4659%2C 0.4282%2C  ...%2C 0.4372%2C 0.4289%2C 0.2113%5D%2C%0A        %5B0.4574%2C 0.4638%2C 0.4765%2C  ...%2C 0.5032%2C 0.4855%2C 0.4660%5D....%2C 0.4880%2C 0.4629%2C 0.3134%5D%2C%0A        %5B0.5011%2C 0.4493%2C 0.3075%2C  ...%2C 0.3163%2C 0.4859%2C 0.4926%5D%5D%2C%0A       grad_fn=%3CSqueezeBackward0&gt;%29" isContainer="True" shape="(256, 12)" />
<var name="start_time" type="float" qualifier="builtins" value="1709538301.6347365" />
<var name="step" type="int" qualifier="builtins" value="136" />
<var name="stop_words" type="set" qualifier="builtins" value="%7B%27a%27%2C %27about%27%2C %27above%27%2C %27after%27%2C %27again%27%2C %27against%27%2C %27ain%27%2C %27all%27%2C %27am%27%2C %27an%27%2C %27and%27%2C %27any%27%2C %27are%27%2C %27aren%27%2C %22aren%27t%22%2C %27as%27%2C %27at%27%2C %27be%27%2C %27because%27%2C %27been%27%2C %27before%27%2C %27being%27%2C %27below%27%2C %27between%27%2C %27both%27%2C %27but%27%2C %27by%27%2C %27can%27%2C %27couldn%27%2C %22couldn%27t%22%2C %27d%27%2C %27did%27%2C %27didn%27%2C %22didn%27t%22%2C %27do%27%2C %27does%27%2C %27doesn%27%2C %22doesn%27t%22%2C %27doing%27%2C %27don%27%2C %22don%27t%22%2C %27down%27%2C %27during%27%2C %27each%27%2C %27few%27%2C %27for%27%2C %27from%27%2C %27further%27%2C %27had%27%2C %27hadn%27%2C %22hadn%27t%22%2C %27has%27%2C %27hasn%27%2C %22hasn%27t%22%2C %27have%27%2C %27haven%27%2C %22haven%27t%22%2C %27having%27%2C %27he%27%2C %27her%27%2C %27here%27%2C %27hers%27%2C %27herself%27%2C %27him%27%2C %27himself%27%2C %27his%27%2C %27how%27%2C %27i%27%2C %27if%27%2C %27in%27%2C %27into%27%2C %27is%27%2C %27isn%27%2C %22isn%27t%22%2C %27it%27%2C %22it%27s%22%2C %27its%27%2C %27itself%27%2C %27just%27%2C %27ll%27%2C %27m%27%2C %27ma%27%2C %27me%27%2C %27mightn%27%2C %22mightn%27t%22%2C %27more%27%2C %27most%27%2C %27mustn%27%2C %22mustn%27t%22%2C %27my%27%2C %27myself%27%2C %27needn%27%2C %22needn%27t%22%2C %27no%27%2C %27nor%27%2C %27not%27%2C %27now%27%2C %27o%27%2C %27of%27%2C %27off%27%2C %27on%27%2C %27once%27%2C %27only%27%2C %27or%27%2C %27other%27%2C %27our%27%2C %27ours%27%2C %27ourselves%27%2C %27out%27%2C %27over%27%2C %27own%27%2C %27re%27%2C %27s%27%2C %27same%27%2C %27shan%27%2C %22shan%27t%22%2C %27she%27%2C %22she%27s%22%2C %27should%27%2C %22should%27ve%22%2C %27shouldn%27%2C %22shouldn%27t%22%2C %27so%27%2C %27some%27%2C..." isContainer="True" shape="179" />
<var name="stopwords" type="WordListCorpusReader" qualifier="nltk.corpus.reader.wordlist" value="%3CWordListCorpusReader in %27C%3A%5C%5CUsers%5C%5C16979%5C%5CAppData%5C%5CRoaming%5C%5Cnltk_data%5C%5Ccorpora%5C%5Cstopwords%27&gt;" isContainer="True" />
<var name="target_ids" type="Tensor" qualifier="torch" value="tensor%28%5B    7%2C   700%2C   257%2C 12023%2C  8113%2C   128%2C    18%2C   513%2C  3929%2C     7%2C%0A          873%2C  8395%2C    28%2C    50%2C   221%2C    21...%2C   177%2C    19%2C   340%2C  4296%2C  3215%2C  2029%2C    71%2C   175%2C%0A           21%2C  1146%2C   979%2C    59%2C   637%2C   221%5D%2C dtype=torch.int32%29" isContainer="True" shape="(256,)" />
<var name="time_per_batch" type="float" qualifier="builtins" value="1.5880834245681763" />
<var name="times_per_batch" type="list" qualifier="builtins" value="%5B0.15787519931793212%2C 0.15914211750030519%2C 0.2081467652320862%2C 0.2807381868362427%2C 0.4308408999443054%2C 0.7185326981544494%2C 1.5880834245681763%5D" isContainer="True" shape="7" />
<var name="train_dataloader" type="DataLoader" qualifier="torch.utils.data.dataloader" value="%3Ctorch.utils.data.dataloader.DataLoader object at 0x000001B9DFBB2A50&gt;" isContainer="True" shape="594995" />
<var name="training_data" type="list" qualifier="builtins" value="%5B%282%2C %5B    5   284    11  2901  2568 10895 13946   759    47    64 13137   242%5D%2C %5B1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %285%2C %5B   2    8  207    1  375 7031  142 2411 1804  119  195 9268%5D%2C %5B1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %287%2C %5B    2     5     8   986    80 13432  4505 24472  4543 45907    11   313%5D%2C %5B1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %288%2C %5B    5    10  4091  1456 26266   683    98 13093  2693   514   117  2683%5D%2C %5B1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %289%2C %5B    8    10    12   733    50 12489   903     0   621   261   339  2626%5D%2C %5B1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %2810%2C %5B    8    12    13  6221   108  5677  4030   606 15276    24 37235  3387%5D%2C %5B1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %2812%2C %5B   10 29946 18971    27 17476  2392     4  2597   545   264   514  3398%5D%2C %5B1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %2814%2C %5B   10    12    16    67   235  3114  1506  2872 15734  4945  2830  5685%5D%2C %5B1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %2815%2C %5B   12    16  4674  2245     1 62509     0    11 13..." isContainer="True" shape="152318582" />
<var name="vocab_size" type="int" qualifier="builtins" value="120361" />
<var name="window_size" type="int" qualifier="builtins" value="2" />
<var name="writer" type="SummaryWriter" qualifier="torch.utils.tensorboard.writer" value="%3Ctorch.utils.tensorboard.writer.SummaryWriter object at 0x000001B9DFA52F60&gt;" isContainer="True" />
</xml>
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="RegexpTokenizer" type="ABCMeta" qualifier="abc" value="%3Cclass %27nltk.tokenize.regexp.RegexpTokenizer%27&gt;" isContainer="True" />
<var name="avg_loss" type="float" qualifier="builtins" value="0.6833540469408035" />
<var name="batch_size" type="int" qualifier="builtins" value="1024" />
<var name="batch_sizes" type="list" qualifier="builtins" value="%5B2%2C 8%2C 32%2C 64%2C 128%2C 256%2C 512%2C 1024%2C 2048%2C 4096%2C 8192%5D" isContainer="True" shape="11" />
<var name="best_batch_size" type="int" qualifier="builtins" value="256" />
<var name="context_ids" type="Tensor" qualifier="torch" value="tensor%28%5B%5B 3967%2C  3265%2C   437%2C  ...%2C  3344%2C 14537%2C     3%5D%2C%0A        %5B 8774%2C   751%2C 10744%2C  ...%2C   733%2C 13410%2C  1340%5D%2C%0A        %5B ...%5B   50%2C   106%2C    98%2C  ...%2C  7288%2C  7460%2C    67%5D%2C%0A        %5B   19%2C   242%2C    24%2C  ...%2C   156%2C 16334%2C  8247%5D%5D%2C dtype=torch.int32%29" isContainer="True" shape="(256, 12)" />
<var name="context_size" type="int" qualifier="builtins" value="12" />
<var name="corpus" type="Corpus" qualifier="__main__" value="%3C__main__.Corpus object at 0x000001B9DF963E30&gt;" isContainer="True" />
<var name="criterion" type="BCELoss" qualifier="torch.nn.modules.loss" value="BCELoss%28%29" isContainer="True" />
<var name="data" type="list" qualifier="builtins" value="%5Btensor%28%5B    7%2C   700%2C   257%2C 12023%2C  8113%2C   128%2C    18%2C   513%2C  3929%2C     7%2C%0A          873%2C  8395%2C    28%2C    50%2C   221%2C    21...%2C   177%2C    19%2C   340%2C  4296%2C  3215%2C  2029%2C    71%2C   175%2C%0A           21%2C  1146%2C   979%2C    59%2C   637%2C   221%5D%2C dtype=torch.int32%29%2C tensor%28%5B%5B 3967%2C  3265%2C   437%2C  ...%2C  3344%2C 14537%2C     3%5D%2C%0A        %5B 8774%2C   751%2C 10744%2C  ...%2C   733%2C 13410%2C  1340%5D%2C%0A        %5B ...%5B   50%2C   106%2C    98%2C  ...%2C  7288%2C  7460%2C    67%5D%2C%0A        %5B   19%2C   242%2C    24%2C  ...%2C   156%2C 16334%2C  8247%5D%5D%2C dtype=torch.int32%29%2C tensor%28%5B%5B1.%2C 1.%2C 1.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A        %5B1.%2C 1.%2C 0.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A        %5B1.%2C 1.%2C 1.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A      ....%2C 1.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A        %5B1.%2C 1.%2C 0.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A        %5B1.%2C 0.%2C 0.%2C  ...%2C 0.%2C 0.%2C 0.%5D%5D%2C dtype=torch.float64%29%5D" isContainer="True" shape="3" />
<var name="device" type="device" qualifier="torch" value="device%28type=%27cpu%27%29" isContainer="True" />
<var name="embedding_size" type="int" qualifier="builtins" value="50" />
<var name="end_time" type="float" qualifier="builtins" value="1709538301.5303206" />
<var name="epoch" type="int" qualifier="builtins" value="0" />
<var name="estimated_time_per_epoch" type="float" qualifier="builtins" value="472451.6426421833" />
<var name="estimated_times_per_epoch" type="list" qualifier="builtins" value="%5B12023663.246537393%2C 3030037.749051013%2C 990769.4440470601%2C 668150.7084301471%2C 512695.93168382405%2C 427523.36273840663%2C 472451.6426421833%5D" isContainer="True" shape="7" />
<var name="labels" type="Tensor" qualifier="torch" value="tensor%28%5B%5B1.%2C 1.%2C 1.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A        %5B1.%2C 1.%2C 0.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A        %5B1.%2C 1.%2C 1.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A      ....%2C 1.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A        %5B1.%2C 1.%2C 0.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A        %5B1.%2C 0.%2C 0.%2C  ...%2C 0.%2C 0.%2C 0.%5D%5D%2C dtype=torch.float64%29" isContainer="True" shape="(256, 12)" />
<var name="last_loss_sum" type="int" qualifier="builtins" value="0" />
<var name="loss" type="Tensor" qualifier="torch" value="tensor%280.6283%2C grad_fn=%3CBinaryCrossEntropyBackward0&gt;%29" isContainer="True" shape="()" />
<var name="loss_sum" type="float" qualifier="builtins" value="23.838708221912384" />
<var name="lr" type="float" qualifier="builtins" value="0.001" />
<var name="max_step" type="int" qualifier="builtins" value="10000" />
<var name="model" type="Word2Vec" qualifier="__main__" value="Word2Vec%28%0A  %28target_embeddings%29%3A Embedding%28120361%2C 50%29%0A  %28context_embeddings%29%3A Embedding%28120361%2C 50%29%0A  %28sig%29%3A Sigmoid%28%29%0A%29" isContainer="True" />
<var name="num_epoch" type="int" qualifier="builtins" value="1" />
<var name="num_negative_samples_per_target" type="int" qualifier="builtins" value="2" />
<var name="optimizer" type="Adam" qualifier="torch.optim.adam" value="Adam %28%0AParameter Group 0%0A    amsgrad%3A False%0A    betas%3A %280.9%2C 0.999%29%0A    capturable%3A False%0A    differentiable%3A False%0A    eps%3A 1e-08%0A    foreach%3A None%0A    fused%3A None%0A    lr%3A 0.001%0A    maximize%3A False%0A    weight_decay%3A 0%0A%29" isContainer="True" />
<var name="outputs" type="Tensor" qualifier="torch" value="tensor%28%5B%5B0.5029%2C 0.4659%2C 0.4282%2C  ...%2C 0.4372%2C 0.4289%2C 0.2113%5D%2C%0A        %5B0.4574%2C 0.4638%2C 0.4765%2C  ...%2C 0.5032%2C 0.4855%2C 0.4660%5D....%2C 0.4880%2C 0.4629%2C 0.3134%5D%2C%0A        %5B0.5011%2C 0.4493%2C 0.3075%2C  ...%2C 0.3163%2C 0.4859%2C 0.4926%5D%5D%2C%0A       grad_fn=%3CSqueezeBackward0&gt;%29" isContainer="True" shape="(256, 12)" />
<var name="start_time" type="float" qualifier="builtins" value="1709538301.6347365" />
<var name="step" type="int" qualifier="builtins" value="136" />
<var name="stop_words" type="set" qualifier="builtins" value="%7B%27a%27%2C %27about%27%2C %27above%27%2C %27after%27%2C %27again%27%2C %27against%27%2C %27ain%27%2C %27all%27%2C %27am%27%2C %27an%27%2C %27and%27%2C %27any%27%2C %27are%27%2C %27aren%27%2C %22aren%27t%22%2C %27as%27%2C %27at%27%2C %27be%27%2C %27because%27%2C %27been%27%2C %27before%27%2C %27being%27%2C %27below%27%2C %27between%27%2C %27both%27%2C %27but%27%2C %27by%27%2C %27can%27%2C %27couldn%27%2C %22couldn%27t%22%2C %27d%27%2C %27did%27%2C %27didn%27%2C %22didn%27t%22%2C %27do%27%2C %27does%27%2C %27doesn%27%2C %22doesn%27t%22%2C %27doing%27%2C %27don%27%2C %22don%27t%22%2C %27down%27%2C %27during%27%2C %27each%27%2C %27few%27%2C %27for%27%2C %27from%27%2C %27further%27%2C %27had%27%2C %27hadn%27%2C %22hadn%27t%22%2C %27has%27%2C %27hasn%27%2C %22hasn%27t%22%2C %27have%27%2C %27haven%27%2C %22haven%27t%22%2C %27having%27%2C %27he%27%2C %27her%27%2C %27here%27%2C %27hers%27%2C %27herself%27%2C %27him%27%2C %27himself%27%2C %27his%27%2C %27how%27%2C %27i%27%2C %27if%27%2C %27in%27%2C %27into%27%2C %27is%27%2C %27isn%27%2C %22isn%27t%22%2C %27it%27%2C %22it%27s%22%2C %27its%27%2C %27itself%27%2C %27just%27%2C %27ll%27%2C %27m%27%2C %27ma%27%2C %27me%27%2C %27mightn%27%2C %22mightn%27t%22%2C %27more%27%2C %27most%27%2C %27mustn%27%2C %22mustn%27t%22%2C %27my%27%2C %27myself%27%2C %27needn%27%2C %22needn%27t%22%2C %27no%27%2C %27nor%27%2C %27not%27%2C %27now%27%2C %27o%27%2C %27of%27%2C %27off%27%2C %27on%27%2C %27once%27%2C %27only%27%2C %27or%27%2C %27other%27%2C %27our%27%2C %27ours%27%2C %27ourselves%27%2C %27out%27%2C %27over%27%2C %27own%27%2C %27re%27%2C %27s%27%2C %27same%27%2C %27shan%27%2C %22shan%27t%22%2C %27she%27%2C %22she%27s%22%2C %27should%27%2C %22should%27ve%22%2C %27shouldn%27%2C %22shouldn%27t%22%2C %27so%27%2C %27some%27%2C..." isContainer="True" shape="179" />
<var name="stopwords" type="WordListCorpusReader" qualifier="nltk.corpus.reader.wordlist" value="%3CWordListCorpusReader in %27C%3A%5C%5CUsers%5C%5C16979%5C%5CAppData%5C%5CRoaming%5C%5Cnltk_data%5C%5Ccorpora%5C%5Cstopwords%27&gt;" isContainer="True" />
<var name="target_ids" type="Tensor" qualifier="torch" value="tensor%28%5B    7%2C   700%2C   257%2C 12023%2C  8113%2C   128%2C    18%2C   513%2C  3929%2C     7%2C%0A          873%2C  8395%2C    28%2C    50%2C   221%2C    21...%2C   177%2C    19%2C   340%2C  4296%2C  3215%2C  2029%2C    71%2C   175%2C%0A           21%2C  1146%2C   979%2C    59%2C   637%2C   221%5D%2C dtype=torch.int32%29" isContainer="True" shape="(256,)" />
<var name="time_per_batch" type="float" qualifier="builtins" value="1.5880834245681763" />
<var name="times_per_batch" type="list" qualifier="builtins" value="%5B0.15787519931793212%2C 0.15914211750030519%2C 0.2081467652320862%2C 0.2807381868362427%2C 0.4308408999443054%2C 0.7185326981544494%2C 1.5880834245681763%5D" isContainer="True" shape="7" />
<var name="train_dataloader" type="DataLoader" qualifier="torch.utils.data.dataloader" value="%3Ctorch.utils.data.dataloader.DataLoader object at 0x000001B9DFBB2A50&gt;" isContainer="True" shape="594995" />
<var name="training_data" type="list" qualifier="builtins" value="%5B%282%2C %5B    5   284    11  2901  2568 10895 13946   759    47    64 13137   242%5D%2C %5B1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %285%2C %5B   2    8  207    1  375 7031  142 2411 1804  119  195 9268%5D%2C %5B1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %287%2C %5B    2     5     8   986    80 13432  4505 24472  4543 45907    11   313%5D%2C %5B1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %288%2C %5B    5    10  4091  1456 26266   683    98 13093  2693   514   117  2683%5D%2C %5B1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %289%2C %5B    8    10    12   733    50 12489   903     0   621   261   339  2626%5D%2C %5B1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %2810%2C %5B    8    12    13  6221   108  5677  4030   606 15276    24 37235  3387%5D%2C %5B1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %2812%2C %5B   10 29946 18971    27 17476  2392     4  2597   545   264   514  3398%5D%2C %5B1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %2814%2C %5B   10    12    16    67   235  3114  1506  2872 15734  4945  2830  5685%5D%2C %5B1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %2815%2C %5B   12    16  4674  2245     1 62509     0    11 13..." isContainer="True" shape="152318582" />
<var name="vocab_size" type="int" qualifier="builtins" value="120361" />
<var name="window_size" type="int" qualifier="builtins" value="2" />
<var name="writer" type="SummaryWriter" qualifier="torch.utils.tensorboard.writer" value="%3Ctorch.utils.tensorboard.writer.SummaryWriter object at 0x000001B9DFA52F60&gt;" isContainer="True" />
</xml>