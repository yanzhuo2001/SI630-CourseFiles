
Step 500, Avg Loss: 0.7063740156888961
Step 1000, Avg Loss: 0.6690838242173195
Step 1500, Avg Loss: 0.6710940192937851
Step 2000, Avg Loss: 0.6416965731978417
Step 2500, Avg Loss: 0.664360339820385
Step 3000, Avg Loss: 0.6408256154060363
Step 3500, Avg Loss: 0.6219880764484406
Step 4000, Avg Loss: 0.6262354829907417
Step 4500, Avg Loss: 0.6182727155685425
Step 5000, Avg Loss: 0.6229372587800026
-----Step 5000, F1 Score: 0.7150351734827709-----
Step 5500, Avg Loss: 0.6173186347484588
Step 6000, Avg Loss: 0.6325475800037385
Step 6500, Avg Loss: 0.5887129383683205
Step 7000, Avg Loss: 0.6063905549049378
Step 7500, Avg Loss: 0.5964332305192948
Step 8000, Avg Loss: 0.6053036161065102
Step 8500, Avg Loss: 0.576331036567688
Step 9000, Avg Loss: 0.5984818696379661
Step 9500, Avg Loss: 0.6024626339673996
Step 10000, Avg Loss: 0.5853106815218926
-----Step 10000, F1 Score: 0.7879639133488197-----
Step 10500, Avg Loss: 0.6045066975951194
Step 11000, Avg Loss: 0.5990895519852638
Step 11500, Avg Loss: 0.6025713908672333
Step 12000, Avg Loss: 0.5945930997729302
Step 12500, Avg Loss: 0.6004578600525856
Step 13000, Avg Loss: 0.5832919328808784
Step 13500, Avg Loss: 0.5881819829940796
Step 14000, Avg Loss: 0.5846521648168563
Step 14500, Avg Loss: 0.5884763289690018
Step 15000, Avg Loss: 0.5964366135597229
-----Step 15000, F1 Score: 0.7872622733303848-----
Step 15500, Avg Loss: 0.5868490883708
Step 16000, Avg Loss: 0.5907454125285149
Step 16500, Avg Loss: 0.6083347199559211
Step 17000, Avg Loss: 0.5986561837792397
Step 17500, Avg Loss: 0.5974684547781944
Step 18000, Avg Loss: 0.5960528343319893
Step 18500, Avg Loss: 0.5927959544062614
Step 19000, Avg Loss: 0.5859969104528427
Step 19500, Avg Loss: 0.6022085729837418
Step 20000, Avg Loss: 0.5752854390740395
-----Step 20000, F1 Score: 0.8190939180802648-----
Step 20500, Avg Loss: 0.5841937635540962
Step 21000, Avg Loss: 0.5913211702108383
Step 21500, Avg Loss: 0.6059050390124321
Step 22000, Avg Loss: 0.5849579461812973
Step 22500, Avg Loss: 0.5786286098361015
Step 23000, Avg Loss: 0.5815764282941818
Step 23500, Avg Loss: 0.5974919819831848
Step 24000, Avg Loss: 0.5781187584400177
Step 24500, Avg Loss: 0.5815025776624679
Step 25000, Avg Loss: 0.5902935691475868
-----Step 25000, F1 Score: 0.8021671318338532-----
Step 25500, Avg Loss: 0.5879892176389694
Step 26000, Avg Loss: 0.5951767399907112
Step 26500, Avg Loss: 0.5770009518861771
Step 27000, Avg Loss: 0.5866852464675903
Step 27500, Avg Loss: 0.5723925878405571
Step 28000, Avg Loss: 0.573945918083191
Step 28500, Avg Loss: 0.5869149792790412
Step 29000, Avg Loss: 0.5875555686950683
Step 29500, Avg Loss: 0.5734931641817093
Step 30000, Avg Loss: 0.5988189781904221
-----Step 30000, F1 Score: 0.8237762971512512-----
Step 30500, Avg Loss: 0.5714372782111168
Step 31000, Avg Loss: 0.5964570460319519
Step 31500, Avg Loss: 0.5869756731390953
Step 32000, Avg Loss: 0.6010741205215454
Step 32500, Avg Loss: 0.5907238699197769
Step 33000, Avg Loss: 0.6006404414772988
Step 33500, Avg Loss: 0.5966116207838058
Step 34000, Avg Loss: 0.5803368100523949
Step 34500, Avg Loss: 0.5767328258752823
Step 35000, Avg Loss: 0.5910669071674347
-----Step 35000, F1 Score: 0.7973746213396163-----
Step 35500, Avg Loss: 0.5757625764608383
Step 36000, Avg Loss: 0.5886339101791381
Step 36500, Avg Loss: 0.5846765399575233
Step 37000, Avg Loss: 0.6092647631764412
Step 37500, Avg Loss: 0.5664687757492065
Step 38000, Avg Loss: 0.5788147478699684
Step 38500, Avg Loss: 0.5836858942508697
Step 39000, Avg Loss: 0.5830487979054451
Step 39500, Avg Loss: 0.5712072343230248
Step 40000, Avg Loss: 0.585852700650692
-----Step 40000, F1 Score: 0.8185045723507262-----
Step 40500, Avg Loss: 0.5977630615234375
Step 41000, Avg Loss: 0.5781194105148315
Step 41500, Avg Loss: 0.5712754069566727
Step 42000, Avg Loss: 0.5910434773564339
Step 42500, Avg Loss: 0.5956445410847664
Step 43000, Avg Loss: 0.575195496737957
Step 43500, Avg Loss: 0.5754129905700683
Step 44000, Avg Loss: 0.577904021024704
Step 44500, Avg Loss: 0.6047346930503845
Step 45000, Avg Loss: 0.583162627518177
-----Step 45000, F1 Score: 0.8114907173459299-----
Step 45500, Avg Loss: 0.5710144793391227
Step 46000, Avg Loss: 0.5846468817591667
Step 46500, Avg Loss: 0.5695629937648773
Step 47000, Avg Loss: 0.5765024210810661
Step 47500, Avg Loss: 0.5927902680039406
Step 48000, Avg Loss: 0.5697953350543976
Step 48500, Avg Loss: 0.6059315773844719
Step 49000, Avg Loss: 0.5752662197351456
Step 49500, Avg Loss: 0.6006387094855309
Step 50000, Avg Loss: 0.5656764977574349
-----Step 50000, F1 Score: 0.8181423611111112-----
Step 50500, Avg Loss: 0.5578599460721015
Step 51000, Avg Loss: 0.5986775626540184
Step 51500, Avg Loss: 0.5734652752876281
Step 52000, Avg Loss: 0.5891564587950706
Step 52500, Avg Loss: 0.5671856128573418
Step 53000, Avg Loss: 0.5712883048653603
Step 53500, Avg Loss: 0.5650036783218384
Step 54000, Avg Loss: 0.5785763791203499
Step 54500, Avg Loss: 0.5741464665532112
Step 55000, Avg Loss: 0.5904481524825096
-----Step 55000, F1 Score: 0.8222306401861572-----
Step 55500, Avg Loss: 0.574983125090599
Step 56000, Avg Loss: 0.5703611622452736
Step 56500, Avg Loss: 0.5767922866940498
Step 57000, Avg Loss: 0.5910062770843506
Step 57500, Avg Loss: 0.5957151419520378
Step 58000, Avg Loss: 0.5692550956606864
Step 58500, Avg Loss: 0.584552974820137
Step 59000, Avg Loss: 0.5871346623301507
Step 59500, Avg Loss: 0.5784007580280304
Step 60000, Avg Loss: 0.5889766769409179
-----Step 60000, F1 Score: 0.8246050638389959-----
Step 60500, Avg Loss: 0.5821740233302116
Step 61000, Avg Loss: 0.5969029787182808
Step 61500, Avg Loss: 0.5797653490900994
Step 62000, Avg Loss: 0.5928567581176758
Step 62500, Avg Loss: 0.5625485250353813
Step 63000, Avg Loss: 0.5785730468630791
Step 63500, Avg Loss: 0.5762630816698074
Step 64000, Avg Loss: 0.5778693507313728
Step 64500, Avg Loss: 0.5696341547369957
Step 65000, Avg Loss: 0.5682976595163345
-----Step 65000, F1 Score: 0.8368607167361588-----
Step 65500, Avg Loss: 0.5849538207650185
Step 66000, Avg Loss: 0.5667761142253875
Step 66500, Avg Loss: 0.5796133562922478
Step 67000, Avg Loss: 0.5846168262958527
Step 67500, Avg Loss: 0.5702186198234558
Step 68000, Avg Loss: 0.5932042929530144
Step 68500, Avg Loss: 0.5716731460690498
Step 69000, Avg Loss: 0.5832247268557549
Step 69500, Avg Loss: 0.5830702157616615
Step 70000, Avg Loss: 0.5794366750121117
-----Step 70000, F1 Score: 0.8289353469124523-----
Step 70500, Avg Loss: 0.5730558694601059
Step 71000, Avg Loss: 0.5735512250065804
Step 71500, Avg Loss: 0.569893172442913
Step 72000, Avg Loss: 0.5730479677319527
Step 72500, Avg Loss: 0.5701094568371773
Step 73000, Avg Loss: 0.5782119545340538
Step 73500, Avg Loss: 0.5659075647592544
Step 74000, Avg Loss: 0.5857665206193924
Step 74500, Avg Loss: 0.5767367743849754
Step 75000, Avg Loss: 0.5730956009030342
-----Step 75000, F1 Score: 0.8334752981260647-----
Step 75500, Avg Loss: 0.5777082960605622
Step 76000, Avg Loss: 0.5716031351089478
Step 76500, Avg Loss: 0.580154424905777
Step 77000, Avg Loss: 0.5754037519693375
Step 77500, Avg Loss: 0.5802048520445824
Step 78000, Avg Loss: 0.5706701653003693
Step 78500, Avg Loss: 0.5829926530718803
Step 79000, Avg Loss: 0.5782954147458077
Step 79500, Avg Loss: 0.5924260236620903
Step 80000, Avg Loss: 0.572886038005352
-----Step 80000, F1 Score: 0.8296726959517657-----
Step 80500, Avg Loss: 0.5836171826124191
Step 81000, Avg Loss: 0.5838574911952019
Step 81500, Avg Loss: 0.5819856327176094
Early stopping triggered.
   inst_id                                               text  predicted_label
0        0  Really sad review as I absolutely loved the fi...              0.0
1        1  Excellent content, perfect for Christians who ...              1.0
2        2  This is an okay book if you need advice on bud...              1.0
3        3  This is one book you can't put down! This book...              1.0
4        4  There were to many names that I had no idenity...              0.0
Text: Great analysis of what is happening to young adult...
Predicted Label: 1.0
Text: It was a good read. A little slow for me at times ...
Predicted Label: 1.0
Text: I liked the Ogre Detective series but this is like...
Predicted Label: 1.0
C:\Users\16979\AppData\Local\Temp\ipykernel_12296\448138506.py:11: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\torch\csrc\utils\tensor_new.cpp:278.)
  word_ids_tensor = torch.tensor([word_ids], dtype=torch.long)
Text: Seriously, what is going on here? Treating other l...
Predicted Label: 1.0
Predicted Label: 1.0
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="RegexpTokenizer" type="ABCMeta" qualifier="abc" value="%3Cclass %27nltk.tokenize.regexp.RegexpTokenizer%27&gt;" isContainer="True" />
<var name="attention_weights" type="Tensor" qualifier="torch" value="tensor%28%5B%5B%5B0.0093%2C 0.0118%2C 0.0088%2C 0.0070%5D%2C%0A         %5B0.0046%2C 0.0879%2C 0.2792%2C 0.0863%5D%2C%0A         %5B0.0374%2C 0.0160%2C 0.0139%2C 0.0731...0%2C 0.0038%5D%2C%0A         %5B0.0739%2C 0.0764%2C 0.0853%2C 0.0072%5D%2C%0A         %5B0.0866%2C 0.1320%2C 0.1848%2C 0.0021%5D%5D%5D%2C grad_fn=%3CSoftmaxBackward0&gt;%29" isContainer="True" shape="(1, 27, 4)" />
<var name="attn" type="ndarray" qualifier="numpy" value="%5B%5B3.8761396e-02 1.4316343e-03 3.5074565e-03 2.0801390e-03%5D%2C %5B2.4591111e-02 5.6007253e-03 6.1986055e-03 3.1265877e-02%5D%2C %5B2.3266392e-02 1.5529494e-03 3.2180738e-02 1.0921432e-02%5D%2C %5B2.7827655e-03 1.0171688e-02 1.4128776e-02 2.5735588e-03%5D%2C %5B1.8277273e-02 4.8935330e-03 7.0923351e-04 1.9113851e-03%5D%2C %5B3.3237633e-01 1.0533698e-02 1.0934884e-01 3.6092749e-04%5D%2C %5B2.4453353e-02 8.3953858e-04 8.5045584e-03 1.3689095e-03%5D%2C %5B8.1114441e-02 2.1813512e-02 3.3395069e-03 1.1676165e-02%5D%2C %5B3.9978933e-02 2.7990532e-03 2.9895086e-02 1.6270466e-02%5D%2C %5B7.2887810e-03 3.5754472e-04 1.7100248e-01 6.4502698e-03%5D%2C %5B3.8761396e-02 1.4316343e-03 3.5074565e-03 2.0801390e-03%5D%2C %5B1.8694693e-02 1.3729646e-02 2.7651500e-03 7.4767978e-03%5D%2C %5B6.7505077e-02 1.6143369e-03 8.6992960e-03 5.2691400e-03%5D%2C %5B7.2196382e-03 5.0290017e-03 1.8445179e-02 5.0763592e-02%5D%2C %5B3.1776860e-02 6.1441433e-02 6.8705566e-02 6.7701474e-02%5D%2C %5B2.4453353e-02 8.3953858e-04 8.5045584e-03 1.3689095e-03%5D%2C %5B2.1151653e-02 2.7802718e-04 6.4917473e-04 9.3950052e-0..." isContainer="True" shape="(22, 4)" />
<var name="avg_loss" type="float" qualifier="builtins" value="0.5819856327176094" />
<var name="batch_size" type="int" qualifier="builtins" value="1" />
<var name="best_f1" type="float64" qualifier="numpy" value="0.8370573902224065" shape="()" />
<var name="dev_data_path" type="str" qualifier="builtins" value="sentiment.dev.csv" />
<var name="dev_dataset" type="TextDataset" qualifier="__main__" value="%3C__main__.TextDataset object at 0x00000232EF22FBC0&gt;" isContainer="True" shape="20000" />
<var name="dev_f1" type="float64" qualifier="numpy" value="0.8180815876515987" shape="()" />
<var name="dev_list" type="list" qualifier="builtins" value="%5B%28%5B  96   96  193    4 7609   62   71   27  234   64  329   11   96    1%2C  629  314 7041 1811 1900 1018  177   96  104    4  105  106 4116   11%2C  264   11    1 1693  992   13 6499%5D%2C array%280%29%29%2C %28%5B   96   288     7  1160    71     3  1056   223   281    83 16366  2101%2C   268   607   140     7  1283    24 10093  1475    96 19270    98   951%2C 11996  2253   727   398     7    70    96     7 16366   781  2101   268%2C     7  3551    58    77  6499%5D%2C array%280%29%29%2C %28%5B  96    1   18 1818   27    0   21   96   15   88 5047   61    0   36%2C   61   96   13  104  190 4549   98   40   83 1712   61   96 1601   96%2C   96  551  200   81 1903    7   21  307   96 1043   96  772  200  172%2C   11  671 2278   96   96 1594   47   33 3211   15 3408  268    7  117%2C   24   33 5050%5D%2C array%281%29%29%2C %28%5B  96  193    4   18 1288   13  742 3822  862   96 3545 4912   77  128%2C 1236  884   96  128 3472  200  719 1755%5D%2C array%280%29%29%2C %28%5B  96  124  310  288    0   21   96    1  310   64   33 4288    6   96%2C  408  409 1695  151   62   11 ..." isContainer="True" shape="20000" />
<var name="dev_loader" type="DataLoader" qualifier="torch.utils.data.dataloader" value="%3Ctorch.utils.data.dataloader.DataLoader object at 0x00000232EF4AFBF0&gt;" isContainer="True" shape="20000" />
<var name="device" type="device" qualifier="torch" value="device%28type=%27cpu%27%29" isContainer="True" />
<var name="embedding_size" type="int" qualifier="builtins" value="50" />
<var name="embeddings_file_path" type="str" qualifier="builtins" value="./models/1st_model_embeddings_state_dict.pt" />
<var name="epoch" type="int" qualifier="builtins" value="0" />
<var name="epochs" type="int" qualifier="builtins" value="1" />
<var name="f" type="BufferedReader" qualifier="_io" value="%3C_io.BufferedReader name=%27./models/1st_model_index_to_word.pkl%27&gt;" isContainer="True" />
<var name="f1_scores" type="list" qualifier="builtins" value="%5B0.0%2C 0.21893018717289098%2C 0.29446606870874936%2C 0.5971060666401168%2C 0.48496934781003026%2C 0.6473546826255809%2C 0.7046656760772659%2C 0.6990291262135923%2C 0.7337489897240503%2C 0.7150351734827709%2C 0.7465940054495913%2C 0.749829893399864%2C 0.7700985761226725%2C 0.7603120264885797%2C 0.7680974799224591%2C 0.7579650274460982%2C 0.7954971857410882%2C 0.756486117432863%2C 0.7812174675360254%2C 0.7879639133488197%2C 0.768396679279381%2C 0.7723326799215906%2C 0.7731073573152253%2C 0.7886400873839432%2C 0.7827916505176901%2C 0.8015255045288415%2C 0.7956896551724137%2C 0.8103950103950104%2C 0.8042047143767255%2C 0.7872622733303848%2C 0.8037681622225771%2C 0.7996125699526474%2C 0.7792792792792793%2C 0.7899401728340351%2C 0.8128498927431591%2C 0.8020052827340844%2C 0.783627698345949%2C 0.8064017071218992%2C 0.7953884161405435%2C 0.8190939180802648%2C 0.8084879505224994%2C 0.7983602077070238%2C 0.7869421580155663%2C 0.8042299349240781%2C 0.805939524838013%2C 0.8133961166075869%2C 0.805041653142919%2C 0.8099191259171978%2C 0.8102107577626427%2C 0.8021671318338532%2C 0.792075892857142..." isContainer="True" shape="163" />
<var name="index_to_word" type="dict" qualifier="builtins" value="%7B0%3A %27this%27%2C 1%3A %27was%27%2C 2%3A %27bought%27%2C 3%3A %27as%27%2C 4%3A %27a%27%2C 5%3A %27gift%27%2C 6%3A %27but%27%2C 7%3A %27the%27%2C 8%3A %27person%27%2C 9%3A %27who%27%2C 10%3A %27got%27%2C 11%3A %27it%27%2C 12%3A %27loved%27%2C 13%3A %27and%27%2C 14%3A %27they%27%2C 15%3A %27will%27%2C 16%3A %27use%27%2C 17%3A %27soon%27%2C 18%3A %27very%27%2C 19%3A %27well%27%2C 20%3A %27written%27%2C 21%3A %27book%27%2C 22%3A %27on%27%2C 23%3A %27period%27%2C 24%3A %27of%27%2C 25%3A %27world%27%2C 26%3A %27history%27%2C 27%3A %27with%27%2C 28%3A %27which%27%2C 29%3A %27i%27%2C 30%3A %27am%27%2C 31%3A %27familiar%27%2C 32%3A %27despite%27%2C 33%3A %27my%27%2C 34%3A %27familiarity%27%2C 35%3A %27subject%27%2C 36%3A %27area%27%2C 37%3A %27learned%27%2C 38%3A %27lot%27%2C 39%3A %27new%27%2C 40%3A %27information%27%2C 41%3A %27also%27%2C 42%3A %27one%27%2C 43%3A %27best%27%2C 44%3A %27concise%27%2C 45%3A %27descriptions%27%2C 46%3A %27wwii%27%2C 47%3A %27that%27%2C 48%3A %27have%27%2C 49%3A %27ever%27%2C 50%3A %27read%27%2C 51%3A %27thought%27%2C 52%3A %27provoking%27%2C 53%3A %27hot%27%2C 54%3A %27cross%27%2C 55%3A %27buns%27%2C 56%3A %27contains%27%2C 57%3A %27cast%27%2C 58%3A %27characters%27%2C 59%3A %27you%27%2C 60%3A %27fall%27%2C 61%3A %27in%27%2C 62%3A %27love%27%2C 63%3A %27want%27%2C 64%3A %27to%27%2C 65%3A %27hang%27%2C 66%3A %27out%27%2C 67%3A %27has%27%2C 68%3A %27few%27%2C 69%3A %27different%27%2C 70%3A %27plot%27%2C 71%3A %27story%27%2C 72%3A %27lines%27%2C 73%3A %27intersect%27%2C 74%3A %27unexpected%27%2C 75%3A %27ways%27%2C 76%3A %27stories%27%2C 77%3A %27are%27%2C 78%3A %27full%27%2C 79%3A %27h..." isContainer="True" shape="40547" />
<var name="index_to_word_file" type="str" qualifier="builtins" value="./models/1st_model_index_to_word.pkl" />
<var name="label" type="float" qualifier="builtins" value="1.0" />
<var name="labels" type="Tensor" qualifier="torch" value="tensor%28%5B1.%5D%29" isContainer="True" shape="(1,)" />
<var name="learning_rate" type="float" qualifier="builtins" value="0.001" />
<var name="loss" type="Tensor" qualifier="torch" value="tensor%280.3133%2C grad_fn=%3CBinaryCrossEntropyWithLogitsBackward0&gt;%29" isContainer="True" shape="()" />
<var name="loss_function" type="BCEWithLogitsLoss" qualifier="torch.nn.modules.loss" value="BCEWithLogitsLoss%28%29" isContainer="True" />
<var name="losses" type="list" qualifier="builtins" value="%5B0.7063740156888961%2C 0.6690838242173195%2C 0.6710940192937851%2C 0.6416965731978417%2C 0.664360339820385%2C 0.6408256154060363%2C 0.6219880764484406%2C 0.6262354829907417%2C 0.6182727155685425%2C 0.6229372587800026%2C 0.6173186347484588%2C 0.6325475800037385%2C 0.5887129383683205%2C 0.6063905549049378%2C 0.5964332305192948%2C 0.6053036161065102%2C 0.576331036567688%2C 0.5984818696379661%2C 0.6024626339673996%2C 0.5853106815218926%2C 0.6045066975951194%2C 0.5990895519852638%2C 0.6025713908672333%2C 0.5945930997729302%2C 0.6004578600525856%2C 0.5832919328808784%2C 0.5881819829940796%2C 0.5846521648168563%2C 0.5884763289690018%2C 0.5964366135597229%2C 0.5868490883708%2C 0.5907454125285149%2C 0.6083347199559211%2C 0.5986561837792397%2C 0.5974684547781944%2C 0.5960528343319893%2C 0.5927959544062614%2C 0.5859969104528427%2C 0.6022085729837418%2C 0.5752854390740395%2C 0.5841937635540962%2C 0.5913211702108383%2C 0.6059050390124321%2C 0.5849579461812973%2C 0.5786286098361015%2C 0.5815764282941818%2C 0.5974919819831848%2C 0.5781187584400177%2C 0.5815025776624679%2C 0.5902935691475868%2C 0.58..." isContainer="True" shape="163" />
<var name="max_steps" type="int" qualifier="builtins" value="1000000000" />
<var name="model" type="DocumentAttentionClassifier" qualifier="__main__" value="DocumentAttentionClassifier%28%0A  %28embeddings%29%3A Embedding%2840547%2C 50%29%0A  %28linear%29%3A Linear%28in_features=200%2C out_features=1%2C bias=True%29%0A%29" isContainer="True" />
<var name="negative_samples" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B17160  I liked the Ogre Detective series but this is ...      0%5D %5B186    Seriously%2C what is going on here%3F Treating oth...      0%5D" isContainer="True" shape="(2, 2)" />
<var name="num_heads" type="int" qualifier="builtins" value="4" />
<var name="optimizer" type="AdamW" qualifier="torch.optim.adamw" value="AdamW %28%0AParameter Group 0%0A    amsgrad%3A False%0A    betas%3A %280.9%2C 0.999%29%0A    capturable%3A False%0A    differentiable%3A False%0A    eps%3A 1e-08%0A    foreach%3A None%0A    fused%3A None%0A    lr%3A 0.001%0A    maximize%3A False%0A    weight_decay%3A 0.01%0A%29" isContainer="True" />
<var name="patience" type="int" qualifier="builtins" value="30000" />
<var name="positive_samples" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B13479  Great analysis of what is happening to young a...      1%5D %5B12266  It was a good read. A little slow for me at ti...      1%5D" isContainer="True" shape="(2, 2)" />
<var name="pred" type="float" qualifier="builtins" value="1.0" />
<var name="prediction" type="float" qualifier="builtins" value="1.0" />
<var name="predictions" type="list" qualifier="builtins" value="%5B0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C..." isContainer="True" shape="20000" />
<var name="probability" type="Tensor" qualifier="torch" value="tensor%28%5B0.6481%5D%29" isContainer="True" shape="(1,)" />
<var name="running_loss" type="float" qualifier="builtins" value="0.0" />
<var name="s" type="str" qualifier="builtins" value="%0AI%27m a big fan of his%2C and I have to say that this was a BIG letdown. It features%3A Stilted dialogue%2C no character development%2C no suspense%2C no description of Indian tradition and poor editing.%0A%0AAvoid at all costs.%0A" />
<var name="sample_text" type="str" qualifier="builtins" value="Although this product arrived on time and was nicely packaged%2C I found its quality lacking and performance subpar compared to other brands." />
<var name="selected_samples" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B13479  Great analysis of what is happening to young a...      1%5D %5B12266  It was a good read. A little slow for me at ti...      1%5D %5B17160  I liked the Ogre Detective series but this is ...      0%5D %5B186    Seriously%2C what is going on here%3F Treating oth...      0%5D" isContainer="True" shape="(4, 2)" />
<var name="sent_dev_df" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B0      Picturing Perfect is a sappy love story with l...      0%5D %5B1      Seems like the same story as any other series ...      0%5D %5B2      I was very pleased with this book. I will be t...      1%5D %5B3      It is a very light and rather silly novel. The...      0%5D %5B4      I did not like this book. It was not to my tas...      0%5D %5B...                                                  ...    ...%5D %5B19995  Great content%2C the story is fantastic%2C but sho...      1%5D %5B19996  Typical book club book... Incest%2C child abuse%2C...      0%5D %5B19997  Fascinating book. Shorter than most Russell Ba...      1%5D %5B19998  This book is not well-organized%2C which is impo...      0%5D %5B19999  CAN WE CALL THIS A CLASSIC OF THE GENRE%3F I THI...      1%5D %5B%5D" isContainer="True" shape="(20000, 2)" />
<var name="sent_test_df" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27inst_id%27%2C %27text%27%2C %27predicted_label%27%5D %5B0            0  Really sad review as I absolutely loved the fi...   %5D %5B1            1  Excellent content%2C perfect for Christians who ...   %5D %5B2            2  This is an okay book if you need advice on bud...   %5D %5B3            3  This is one book you can%27t put down%21 This book...   %5D %5B4            4  There were to many names that I had no idenity...   %5D %5B...        ...                                                ...   %5D %5B19995    19995  I found this book to be a very entertaining an...   %5D %5B19996    19996  Wow%2C what a Middle School%21 Read this book your...   %5D %5B19997    19997  Not what I expected. Not enough about circular...   %5D %5B19998    19998  I like Joanne Fluke%27s mystery series starring ...   %5D %5B19999    19999  Grow some chickens%2C improve your land%2C make al...   %5D %5B%5D %5B0                  0.0  %5D %5B1                  1.0  %5D %5B2                  1.0  %5D %5B3                  1.0  %5D %5B4                  0.0  %5D %5B...                ...  %5D %5B19995         ..." isContainer="True" shape="(20000, 3)" />
<var name="sent_train_df" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B0       It was what I needed. There was no markings or...      1%5D %5B1       A cute little book. My wife gets the family wa...      1%5D %5B2       I bought these for 40.00 and for the price I j...      0%5D %5B3       It was interesting and enjoyable reading. Shor...      1%5D %5B4       A perfect ending to an amazing story. This was...      1%5D %5B...                                                   ...    ...%5D %5B159995  After reading every book Stephen King has to o...      1%5D %5B159996  Baby boomers who are experiencing %22aging eyeba...      0%5D %5B159997  Must read%2C must have%2C must read again. This bo...      1%5D %5B159998  Dr. Chopra%27s books are always enlightening and...      1%5D %5B159999  Boooring%21%21 Just enough to keep you intrigued f...      0%5D %5B%5D" isContainer="True" shape="(160000, 2)" />
<var name="step" type="int" qualifier="builtins" value="81499" />
<var name="steps_since_improvement" type="int" qualifier="builtins" value="30000" />
<var name="test_data" type="list" qualifier="builtins" value="%5Btensor%28%5B   96%2C   885%2C   626%2C     3%2C    96%2C  1132%2C    12%2C     7%2C   285%2C    21%2C%0A           96%2C    21%2C     1%2C  4050%2C     4%2C  6499...8504%2C  7595%2C     7%2C%0A         2087%2C   762%2C     7%2C   727%2C    42%2C   335%2C   385%2C   514%2C    98%2C   629%2C%0A          102%2C    13%2C   450%5D%29%2C tensor%28%5B  96%2C 1669%2C 1427%2C   98%2C   96%2C    9%2C   77%2C  207%2C 2651%2C  314%2C  804%2C   24%2C%0A           7%2C   96%2C   13%2C   86%2C 1887%2C   61%2C    7%2C  693%5D%29%2C tensor%28%5B   96%2C   193%2C   314%2C  4921%2C    21%2C   335%2C    59%2C   661%2C   633%2C    22%2C%0A         8229%2C    13%2C  3966%2C    96%2C   360%2C   345...  719%2C    96%2C   309%2C   497%2C    94%2C   719%2C  1105%2C%0A           59%2C    80%2C    32%2C     7%2C   269%2C   154%2C 20119%2C    64%2C     7%2C  2881%5D%29%2C tensor%28%5B  96%2C  193%2C   42%2C   21%2C   59%2C   92%2C  200%2C  506%2C  108%2C   96%2C   21%2C   15%2C%0A          80%2C   59%2C  218%2C   13%2C 8965%2C   59%2C   ...7%2C    4%2C  768%2C   13%2C%0A        3576%2C  677%2C   86%2C  678%2C   64%2C  287%2C  193%2C  537%2C  265%2C   96%2C  151%2C  329%2C%0A           0%2C  679%2C   21%5D%29%2C tensor%28%5B  96%2C  336%2C   64%2C  141%2C  352%2C   47%2C   96%2C  104%2C  204%2C   96%2C   27%2C   61%2C%0A       ..." isContainer="True" shape="20000" />
<var name="test_data_path" type="str" qualifier="builtins" value="sentiment.test.csv" />
<var name="test_list" type="list" qualifier="builtins" value="%5Btensor%28%5B   96%2C   885%2C   626%2C     3%2C    96%2C  1132%2C    12%2C     7%2C   285%2C    21%2C%0A           96%2C    21%2C     1%2C  4050%2C     4%2C  6499...8504%2C  7595%2C     7%2C%0A         2087%2C   762%2C     7%2C   727%2C    42%2C   335%2C   385%2C   514%2C    98%2C   629%2C%0A          102%2C    13%2C   450%5D%29%2C tensor%28%5B  96%2C 1669%2C 1427%2C   98%2C   96%2C    9%2C   77%2C  207%2C 2651%2C  314%2C  804%2C   24%2C%0A           7%2C   96%2C   13%2C   86%2C 1887%2C   61%2C    7%2C  693%5D%29%2C tensor%28%5B   96%2C   193%2C   314%2C  4921%2C    21%2C   335%2C    59%2C   661%2C   633%2C    22%2C%0A         8229%2C    13%2C  3966%2C    96%2C   360%2C   345...  719%2C    96%2C   309%2C   497%2C    94%2C   719%2C  1105%2C%0A           59%2C    80%2C    32%2C     7%2C   269%2C   154%2C 20119%2C    64%2C     7%2C  2881%5D%29%2C tensor%28%5B  96%2C  193%2C   42%2C   21%2C   59%2C   92%2C  200%2C  506%2C  108%2C   96%2C   21%2C   15%2C%0A          80%2C   59%2C  218%2C   13%2C 8965%2C   59%2C   ...7%2C    4%2C  768%2C   13%2C%0A        3576%2C  677%2C   86%2C  678%2C   64%2C  287%2C  193%2C  537%2C  265%2C   96%2C  151%2C  329%2C%0A           0%2C  679%2C   21%5D%29%2C tensor%28%5B  96%2C  336%2C   64%2C  141%2C  352%2C   47%2C   96%2C  104%2C  204%2C   96%2C   27%2C   61%2C%0A       ..." isContainer="True" shape="20000" />
<var name="test_output" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27inst_id%27%2C %27predicted_label%27%5D %5B0            0              0.0%5D %5B1            1              1.0%5D %5B2            2              1.0%5D %5B3            3              1.0%5D %5B4            4              0.0%5D %5B...        ...              ...%5D %5B19995    19995              1.0%5D %5B19996    19996              1.0%5D %5B19997    19997              0.0%5D %5B19998    19998              1.0%5D %5B19999    19999              1.0%5D %5B%5D" isContainer="True" shape="(20000, 2)" />
<var name="text" type="str" qualifier="builtins" value="Seriously%2C what is going on here%3F Treating other living creatures with respect will be the downfall of mankind%3F I doubt it. Treating each other with no respect will." />
<var name="texts" type="list" qualifier="builtins" value="%5B%27Great analysis of what is happening to young adults today. Not a blame or political book.%27%2C %22It was a good read. A little slow for me at times but I still kept reading. I wish it wouldn%27t have taken so long to get to the plot.%22%2C %27I liked the Ogre Detective series but this is like it was written by a different person. The plot is just so improbable as ju...ith this series. I read the run up for some of the sequels and it seems like more of the same. Reads like a young adult novel.%27%2C %27Seriously%2C what is going on here%3F Treating other living creatures with respect will be the downfall of mankind%3F I doubt it. Treating each other with no respect will.%27%5D" isContainer="True" shape="4" />
<var name="tokenizer" type="RegexpTokenizer" qualifier="nltk.tokenize.regexp" value="RegexpTokenizer%28pattern=%27%5C%5Cw%2B%27%2C gaps=False%2C discard_empty=True%2C flags=re.UNICODE%7Cre.MULTILINE%7Cre.DOTALL%29" isContainer="True" />
<var name="tokens" type="list" qualifier="builtins" value="%5B%27%3CUNK&gt;%27%2C %27this%27%2C %27product%27%2C %27arrived%27%2C %27on%27%2C %27time%27%2C %27and%27%2C %27was%27%2C %27nicely%27%2C %27packaged%27%2C %27%3CUNK&gt;%27%2C %27found%27%2C %27its%27%2C %27quality%27%2C %27lacking%27%2C %27and%27%2C %27performance%27%2C %27subpar%27%2C %27compared%27%2C %27to%27%2C %27other%27%2C %27brands%27%5D" isContainer="True" shape="22" />
<var name="train_data_path" type="str" qualifier="builtins" value="sentiment.train.csv" />
<var name="train_dataset" type="TextDataset" qualifier="__main__" value="%3C__main__.TextDataset object at 0x00000232F2734410&gt;" isContainer="True" shape="160000" />
<var name="train_list" type="list" qualifier="builtins" value="%5B%28%5B   96     1   287    96   248    96     1   204 16850   291   110    24%2C    47    96   193   306    64    50    13    93%5D%2C array%281%29%29%2C %28%5B  96  884  234   21   96 1191 2472    7  693 1931 1926  268   96   96%2C   85 1688   96   21   67    7 1160  884 1578%5D%2C array%281%29%29%2C %28%5B  96    2  320   98 3569 7030   13   98    7  366   96  128 5745   14%2C  151   88  105 9655   96   88   96  123   59 1956  320   59  175   11%2C   15  128   88   96  140  105 9655 5834%5D%2C array%280%29%29%2C %28%5B  96    1  358   13  333  341   96   76 1775   83   96  241 1635 3070%2C   24   96   13 1196  729   61  305   95   96   76 1426   48    4  699%2C  117   96  115    4  486   24   96   96  356   76   96   62%5D%2C array%281%29%29%2C %28%5B  96 1427 1233   64  314  679   71   96    1  314 1131 1554 1555   98%2C  265 1905   96    1 7419   98 3204   87  310 1588  335   14  151  539%2C  232  287   14 1905  249    0    1    4  615  710   96   12   11%5D%2C array%281%29%29%2C %28%5B   96    64    88   314  1774  3195    24   345    24    96    26    96%2C    13  1178   341    ..." isContainer="True" shape="160000" />
<var name="train_loader" type="DataLoader" qualifier="torch.utils.data.dataloader" value="%3Ctorch.utils.data.dataloader.DataLoader object at 0x00000232F2735D00&gt;" isContainer="True" shape="160000" />
<var name="vocab_size" type="int" qualifier="builtins" value="40547" />
<var name="word_ids" type="Tensor" qualifier="torch" value="tensor%28%5B  96%2C  345%2C 8879%2C 1977%2C  385%2C 1364%2C   80%2C 4134%2C   24%2C 1105%2C  680%2C   19%2C%0A          13%2C   96%2C   96%2C   96%2C   94%2C   61%2C    0%2C   21%2C   13%2C   61%2C   96%2C   24%2C%0A          96%2C   96%2C  180%5D%29" isContainer="True" shape="(27,)" />
<var name="word_to_index" type="dict" qualifier="builtins" value="%7B%270%27%3A 6860%2C %2700%27%3A 7030%2C %27000%27%3A 7717%2C %27001%27%3A 38825%2C %27007%27%3A 28099%2C %2700am%27%3A 25993%2C %2701%27%3A 24762%2C %2702%27%3A 29846%2C %2703%27%3A 11089%2C %27039%27%3A 38140%2C %2704%27%3A 8057%2C %2705%27%3A 32280%2C %2706%27%3A 30353%2C %2707%27%3A 7063%2C %2708%27%3A 24586%2C %2709%27%3A 22275%2C %270f%27%3A 37971%2C %271%27%3A 793%2C %2710%27%3A 1684%2C %27100%27%3A 870%2C %271000%27%3A 10968%2C %2710000%27%3A 31123%2C %271000s%27%3A 20833%2C %271000x%27%3A 33996%2C %271001%27%3A 7910%2C %27100k%27%3A 39109%2C %27100s%27%3A 25367%2C %27100th%27%3A 879%2C %27101%27%3A 7005%2C %27101st%27%3A 26963%2C %27102%27%3A 29336%2C %27103%27%3A 31073%2C %27104%27%3A 31072%2C %27105%27%3A 27289%2C %27106%27%3A 11911%2C %271066%27%3A 34895%2C %27107%27%3A 733%2C %27108%27%3A 15245%2C %27109%27%3A 34772%2C %2710k%27%3A 16506%2C %2710th%27%3A 24530%2C %2710x%27%3A 22765%2C %2710yr%27%3A 28921%2C %2711%27%3A 3831%2C %27110%27%3A 18961%2C %271100%27%3A 36651%2C %27111%27%3A 18962%2C %27112%27%3A 11145%2C %27113%27%3A 32771%2C %27114%27%3A 24557%2C %27115%27%3A 15244%2C %27116%27%3A 19634%2C %27117%27%3A 39597%2C %27118%27%3A 21937%2C %27119%27%3A 38487%2C %2711pm%27%3A 25792%2C %2711th%27%3A 10687%2C %2712%27%3A 1681%2C %27120%27%3A 14299%2C %271200%27%3A 13958%2C %27121%27%3A 33184%2C %27122%27%3A 38431%2C %27123%27%3A 18402%2C %27124%27%3A 39041%2C %27125%27%3A 25024%2C %27126%27%3A 39242%2C %27127%27%3A 35211%2C %27128%27%3A 37280%2C %27129%27%3A 39683%2C %2712th%27%3A 10890%2C %2712yr%27%3A 17641%2C %2713%27%3A 3671%2C %27130%27..." isContainer="True" shape="40547" />
<var name="word_to_index_file" type="str" qualifier="builtins" value="./models/1st_model_word_to_index.pkl" />
</xml>
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="RegexpTokenizer" type="ABCMeta" qualifier="abc" value="%3Cclass %27nltk.tokenize.regexp.RegexpTokenizer%27&gt;" isContainer="True" />
<var name="attention_weights" type="Tensor" qualifier="torch" value="tensor%28%5B%5B%5B0.0093%2C 0.0118%2C 0.0088%2C 0.0070%5D%2C%0A         %5B0.0046%2C 0.0879%2C 0.2792%2C 0.0863%5D%2C%0A         %5B0.0374%2C 0.0160%2C 0.0139%2C 0.0731...0%2C 0.0038%5D%2C%0A         %5B0.0739%2C 0.0764%2C 0.0853%2C 0.0072%5D%2C%0A         %5B0.0866%2C 0.1320%2C 0.1848%2C 0.0021%5D%5D%5D%2C grad_fn=%3CSoftmaxBackward0&gt;%29" isContainer="True" shape="(1, 27, 4)" />
<var name="attn" type="ndarray" qualifier="numpy" value="%5B%5B3.8761396e-02 1.4316343e-03 3.5074565e-03 2.0801390e-03%5D%2C %5B2.4591111e-02 5.6007253e-03 6.1986055e-03 3.1265877e-02%5D%2C %5B2.3266392e-02 1.5529494e-03 3.2180738e-02 1.0921432e-02%5D%2C %5B2.7827655e-03 1.0171688e-02 1.4128776e-02 2.5735588e-03%5D%2C %5B1.8277273e-02 4.8935330e-03 7.0923351e-04 1.9113851e-03%5D%2C %5B3.3237633e-01 1.0533698e-02 1.0934884e-01 3.6092749e-04%5D%2C %5B2.4453353e-02 8.3953858e-04 8.5045584e-03 1.3689095e-03%5D%2C %5B8.1114441e-02 2.1813512e-02 3.3395069e-03 1.1676165e-02%5D%2C %5B3.9978933e-02 2.7990532e-03 2.9895086e-02 1.6270466e-02%5D%2C %5B7.2887810e-03 3.5754472e-04 1.7100248e-01 6.4502698e-03%5D%2C %5B3.8761396e-02 1.4316343e-03 3.5074565e-03 2.0801390e-03%5D%2C %5B1.8694693e-02 1.3729646e-02 2.7651500e-03 7.4767978e-03%5D%2C %5B6.7505077e-02 1.6143369e-03 8.6992960e-03 5.2691400e-03%5D%2C %5B7.2196382e-03 5.0290017e-03 1.8445179e-02 5.0763592e-02%5D%2C %5B3.1776860e-02 6.1441433e-02 6.8705566e-02 6.7701474e-02%5D%2C %5B2.4453353e-02 8.3953858e-04 8.5045584e-03 1.3689095e-03%5D%2C %5B2.1151653e-02 2.7802718e-04 6.4917473e-04 9.3950052e-0..." isContainer="True" shape="(22, 4)" />
<var name="avg_loss" type="float" qualifier="builtins" value="0.5819856327176094" />
<var name="batch_size" type="int" qualifier="builtins" value="1" />
<var name="best_f1" type="float64" qualifier="numpy" value="0.8370573902224065" shape="()" />
<var name="dev_data_path" type="str" qualifier="builtins" value="sentiment.dev.csv" />
<var name="dev_dataset" type="TextDataset" qualifier="__main__" value="%3C__main__.TextDataset object at 0x00000232EF22FBC0&gt;" isContainer="True" shape="20000" />
<var name="dev_f1" type="float64" qualifier="numpy" value="0.8180815876515987" shape="()" />
<var name="dev_list" type="list" qualifier="builtins" value="%5B%28%5B  96   96  193    4 7609   62   71   27  234   64  329   11   96    1%2C  629  314 7041 1811 1900 1018  177   96  104    4  105  106 4116   11%2C  264   11    1 1693  992   13 6499%5D%2C array%280%29%29%2C %28%5B   96   288     7  1160    71     3  1056   223   281    83 16366  2101%2C   268   607   140     7  1283    24 10093  1475    96 19270    98   951%2C 11996  2253   727   398     7    70    96     7 16366   781  2101   268%2C     7  3551    58    77  6499%5D%2C array%280%29%29%2C %28%5B  96    1   18 1818   27    0   21   96   15   88 5047   61    0   36%2C   61   96   13  104  190 4549   98   40   83 1712   61   96 1601   96%2C   96  551  200   81 1903    7   21  307   96 1043   96  772  200  172%2C   11  671 2278   96   96 1594   47   33 3211   15 3408  268    7  117%2C   24   33 5050%5D%2C array%281%29%29%2C %28%5B  96  193    4   18 1288   13  742 3822  862   96 3545 4912   77  128%2C 1236  884   96  128 3472  200  719 1755%5D%2C array%280%29%29%2C %28%5B  96  124  310  288    0   21   96    1  310   64   33 4288    6   96%2C  408  409 1695  151   62   11 ..." isContainer="True" shape="20000" />
<var name="dev_loader" type="DataLoader" qualifier="torch.utils.data.dataloader" value="%3Ctorch.utils.data.dataloader.DataLoader object at 0x00000232EF4AFBF0&gt;" isContainer="True" shape="20000" />
<var name="device" type="device" qualifier="torch" value="device%28type=%27cpu%27%29" isContainer="True" />
<var name="embedding_size" type="int" qualifier="builtins" value="50" />
<var name="embeddings_file_path" type="str" qualifier="builtins" value="./models/1st_model_embeddings_state_dict.pt" />
<var name="epoch" type="int" qualifier="builtins" value="0" />
<var name="epochs" type="int" qualifier="builtins" value="1" />
<var name="f" type="BufferedReader" qualifier="_io" value="%3C_io.BufferedReader name=%27./models/1st_model_index_to_word.pkl%27&gt;" isContainer="True" />
<var name="f1_scores" type="list" qualifier="builtins" value="%5B0.0%2C 0.21893018717289098%2C 0.29446606870874936%2C 0.5971060666401168%2C 0.48496934781003026%2C 0.6473546826255809%2C 0.7046656760772659%2C 0.6990291262135923%2C 0.7337489897240503%2C 0.7150351734827709%2C 0.7465940054495913%2C 0.749829893399864%2C 0.7700985761226725%2C 0.7603120264885797%2C 0.7680974799224591%2C 0.7579650274460982%2C 0.7954971857410882%2C 0.756486117432863%2C 0.7812174675360254%2C 0.7879639133488197%2C 0.768396679279381%2C 0.7723326799215906%2C 0.7731073573152253%2C 0.7886400873839432%2C 0.7827916505176901%2C 0.8015255045288415%2C 0.7956896551724137%2C 0.8103950103950104%2C 0.8042047143767255%2C 0.7872622733303848%2C 0.8037681622225771%2C 0.7996125699526474%2C 0.7792792792792793%2C 0.7899401728340351%2C 0.8128498927431591%2C 0.8020052827340844%2C 0.783627698345949%2C 0.8064017071218992%2C 0.7953884161405435%2C 0.8190939180802648%2C 0.8084879505224994%2C 0.7983602077070238%2C 0.7869421580155663%2C 0.8042299349240781%2C 0.805939524838013%2C 0.8133961166075869%2C 0.805041653142919%2C 0.8099191259171978%2C 0.8102107577626427%2C 0.8021671318338532%2C 0.792075892857142..." isContainer="True" shape="163" />
<var name="index_to_word" type="dict" qualifier="builtins" value="%7B0%3A %27this%27%2C 1%3A %27was%27%2C 2%3A %27bought%27%2C 3%3A %27as%27%2C 4%3A %27a%27%2C 5%3A %27gift%27%2C 6%3A %27but%27%2C 7%3A %27the%27%2C 8%3A %27person%27%2C 9%3A %27who%27%2C 10%3A %27got%27%2C 11%3A %27it%27%2C 12%3A %27loved%27%2C 13%3A %27and%27%2C 14%3A %27they%27%2C 15%3A %27will%27%2C 16%3A %27use%27%2C 17%3A %27soon%27%2C 18%3A %27very%27%2C 19%3A %27well%27%2C 20%3A %27written%27%2C 21%3A %27book%27%2C 22%3A %27on%27%2C 23%3A %27period%27%2C 24%3A %27of%27%2C 25%3A %27world%27%2C 26%3A %27history%27%2C 27%3A %27with%27%2C 28%3A %27which%27%2C 29%3A %27i%27%2C 30%3A %27am%27%2C 31%3A %27familiar%27%2C 32%3A %27despite%27%2C 33%3A %27my%27%2C 34%3A %27familiarity%27%2C 35%3A %27subject%27%2C 36%3A %27area%27%2C 37%3A %27learned%27%2C 38%3A %27lot%27%2C 39%3A %27new%27%2C 40%3A %27information%27%2C 41%3A %27also%27%2C 42%3A %27one%27%2C 43%3A %27best%27%2C 44%3A %27concise%27%2C 45%3A %27descriptions%27%2C 46%3A %27wwii%27%2C 47%3A %27that%27%2C 48%3A %27have%27%2C 49%3A %27ever%27%2C 50%3A %27read%27%2C 51%3A %27thought%27%2C 52%3A %27provoking%27%2C 53%3A %27hot%27%2C 54%3A %27cross%27%2C 55%3A %27buns%27%2C 56%3A %27contains%27%2C 57%3A %27cast%27%2C 58%3A %27characters%27%2C 59%3A %27you%27%2C 60%3A %27fall%27%2C 61%3A %27in%27%2C 62%3A %27love%27%2C 63%3A %27want%27%2C 64%3A %27to%27%2C 65%3A %27hang%27%2C 66%3A %27out%27%2C 67%3A %27has%27%2C 68%3A %27few%27%2C 69%3A %27different%27%2C 70%3A %27plot%27%2C 71%3A %27story%27%2C 72%3A %27lines%27%2C 73%3A %27intersect%27%2C 74%3A %27unexpected%27%2C 75%3A %27ways%27%2C 76%3A %27stories%27%2C 77%3A %27are%27%2C 78%3A %27full%27%2C 79%3A %27h..." isContainer="True" shape="40547" />
<var name="index_to_word_file" type="str" qualifier="builtins" value="./models/1st_model_index_to_word.pkl" />
<var name="label" type="float" qualifier="builtins" value="1.0" />
<var name="labels" type="Tensor" qualifier="torch" value="tensor%28%5B1.%5D%29" isContainer="True" shape="(1,)" />
<var name="learning_rate" type="float" qualifier="builtins" value="0.001" />
<var name="loss" type="Tensor" qualifier="torch" value="tensor%280.3133%2C grad_fn=%3CBinaryCrossEntropyWithLogitsBackward0&gt;%29" isContainer="True" shape="()" />
<var name="loss_function" type="BCEWithLogitsLoss" qualifier="torch.nn.modules.loss" value="BCEWithLogitsLoss%28%29" isContainer="True" />
<var name="losses" type="list" qualifier="builtins" value="%5B0.7063740156888961%2C 0.6690838242173195%2C 0.6710940192937851%2C 0.6416965731978417%2C 0.664360339820385%2C 0.6408256154060363%2C 0.6219880764484406%2C 0.6262354829907417%2C 0.6182727155685425%2C 0.6229372587800026%2C 0.6173186347484588%2C 0.6325475800037385%2C 0.5887129383683205%2C 0.6063905549049378%2C 0.5964332305192948%2C 0.6053036161065102%2C 0.576331036567688%2C 0.5984818696379661%2C 0.6024626339673996%2C 0.5853106815218926%2C 0.6045066975951194%2C 0.5990895519852638%2C 0.6025713908672333%2C 0.5945930997729302%2C 0.6004578600525856%2C 0.5832919328808784%2C 0.5881819829940796%2C 0.5846521648168563%2C 0.5884763289690018%2C 0.5964366135597229%2C 0.5868490883708%2C 0.5907454125285149%2C 0.6083347199559211%2C 0.5986561837792397%2C 0.5974684547781944%2C 0.5960528343319893%2C 0.5927959544062614%2C 0.5859969104528427%2C 0.6022085729837418%2C 0.5752854390740395%2C 0.5841937635540962%2C 0.5913211702108383%2C 0.6059050390124321%2C 0.5849579461812973%2C 0.5786286098361015%2C 0.5815764282941818%2C 0.5974919819831848%2C 0.5781187584400177%2C 0.5815025776624679%2C 0.5902935691475868%2C 0.58..." isContainer="True" shape="163" />
<var name="max_steps" type="int" qualifier="builtins" value="1000000000" />
<var name="model" type="DocumentAttentionClassifier" qualifier="__main__" value="DocumentAttentionClassifier%28%0A  %28embeddings%29%3A Embedding%2840547%2C 50%29%0A  %28linear%29%3A Linear%28in_features=200%2C out_features=1%2C bias=True%29%0A%29" isContainer="True" />
<var name="negative_samples" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B17160  I liked the Ogre Detective series but this is ...      0%5D %5B186    Seriously%2C what is going on here%3F Treating oth...      0%5D" isContainer="True" shape="(2, 2)" />
<var name="num_heads" type="int" qualifier="builtins" value="4" />
<var name="optimizer" type="AdamW" qualifier="torch.optim.adamw" value="AdamW %28%0AParameter Group 0%0A    amsgrad%3A False%0A    betas%3A %280.9%2C 0.999%29%0A    capturable%3A False%0A    differentiable%3A False%0A    eps%3A 1e-08%0A    foreach%3A None%0A    fused%3A None%0A    lr%3A 0.001%0A    maximize%3A False%0A    weight_decay%3A 0.01%0A%29" isContainer="True" />
<var name="patience" type="int" qualifier="builtins" value="30000" />
<var name="positive_samples" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B13479  Great analysis of what is happening to young a...      1%5D %5B12266  It was a good read. A little slow for me at ti...      1%5D" isContainer="True" shape="(2, 2)" />
<var name="pred" type="float" qualifier="builtins" value="1.0" />
<var name="prediction" type="float" qualifier="builtins" value="1.0" />
<var name="predictions" type="list" qualifier="builtins" value="%5B0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C..." isContainer="True" shape="20000" />
<var name="probability" type="Tensor" qualifier="torch" value="tensor%28%5B0.6481%5D%29" isContainer="True" shape="(1,)" />
<var name="running_loss" type="float" qualifier="builtins" value="0.0" />
<var name="s" type="str" qualifier="builtins" value="%0AI%27m a big fan of his%2C and I have to say that this was a BIG letdown. It features%3A Stilted dialogue%2C no character development%2C no suspense%2C no description of Indian tradition and poor editing.%0A%0AAvoid at all costs.%0A" />
<var name="sample_text" type="str" qualifier="builtins" value="Although this product arrived on time and was nicely packaged%2C I found its quality lacking and performance subpar compared to other brands." />
<var name="selected_samples" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B13479  Great analysis of what is happening to young a...      1%5D %5B12266  It was a good read. A little slow for me at ti...      1%5D %5B17160  I liked the Ogre Detective series but this is ...      0%5D %5B186    Seriously%2C what is going on here%3F Treating oth...      0%5D" isContainer="True" shape="(4, 2)" />
<var name="sent_dev_df" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B0      Picturing Perfect is a sappy love story with l...      0%5D %5B1      Seems like the same story as any other series ...      0%5D %5B2      I was very pleased with this book. I will be t...      1%5D %5B3      It is a very light and rather silly novel. The...      0%5D %5B4      I did not like this book. It was not to my tas...      0%5D %5B...                                                  ...    ...%5D %5B19995  Great content%2C the story is fantastic%2C but sho...      1%5D %5B19996  Typical book club book... Incest%2C child abuse%2C...      0%5D %5B19997  Fascinating book. Shorter than most Russell Ba...      1%5D %5B19998  This book is not well-organized%2C which is impo...      0%5D %5B19999  CAN WE CALL THIS A CLASSIC OF THE GENRE%3F I THI...      1%5D %5B%5D" isContainer="True" shape="(20000, 2)" />
<var name="sent_test_df" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27inst_id%27%2C %27text%27%2C %27predicted_label%27%5D %5B0            0  Really sad review as I absolutely loved the fi...   %5D %5B1            1  Excellent content%2C perfect for Christians who ...   %5D %5B2            2  This is an okay book if you need advice on bud...   %5D %5B3            3  This is one book you can%27t put down%21 This book...   %5D %5B4            4  There were to many names that I had no idenity...   %5D %5B...        ...                                                ...   %5D %5B19995    19995  I found this book to be a very entertaining an...   %5D %5B19996    19996  Wow%2C what a Middle School%21 Read this book your...   %5D %5B19997    19997  Not what I expected. Not enough about circular...   %5D %5B19998    19998  I like Joanne Fluke%27s mystery series starring ...   %5D %5B19999    19999  Grow some chickens%2C improve your land%2C make al...   %5D %5B%5D %5B0                  0.0  %5D %5B1                  1.0  %5D %5B2                  1.0  %5D %5B3                  1.0  %5D %5B4                  0.0  %5D %5B...                ...  %5D %5B19995         ..." isContainer="True" shape="(20000, 3)" />
<var name="sent_train_df" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B0       It was what I needed. There was no markings or...      1%5D %5B1       A cute little book. My wife gets the family wa...      1%5D %5B2       I bought these for 40.00 and for the price I j...      0%5D %5B3       It was interesting and enjoyable reading. Shor...      1%5D %5B4       A perfect ending to an amazing story. This was...      1%5D %5B...                                                   ...    ...%5D %5B159995  After reading every book Stephen King has to o...      1%5D %5B159996  Baby boomers who are experiencing %22aging eyeba...      0%5D %5B159997  Must read%2C must have%2C must read again. This bo...      1%5D %5B159998  Dr. Chopra%27s books are always enlightening and...      1%5D %5B159999  Boooring%21%21 Just enough to keep you intrigued f...      0%5D %5B%5D" isContainer="True" shape="(160000, 2)" />
<var name="step" type="int" qualifier="builtins" value="81499" />
<var name="steps_since_improvement" type="int" qualifier="builtins" value="30000" />
<var name="test_data" type="list" qualifier="builtins" value="%5Btensor%28%5B   96%2C   885%2C   626%2C     3%2C    96%2C  1132%2C    12%2C     7%2C   285%2C    21%2C%0A           96%2C    21%2C     1%2C  4050%2C     4%2C  6499...8504%2C  7595%2C     7%2C%0A         2087%2C   762%2C     7%2C   727%2C    42%2C   335%2C   385%2C   514%2C    98%2C   629%2C%0A          102%2C    13%2C   450%5D%29%2C tensor%28%5B  96%2C 1669%2C 1427%2C   98%2C   96%2C    9%2C   77%2C  207%2C 2651%2C  314%2C  804%2C   24%2C%0A           7%2C   96%2C   13%2C   86%2C 1887%2C   61%2C    7%2C  693%5D%29%2C tensor%28%5B   96%2C   193%2C   314%2C  4921%2C    21%2C   335%2C    59%2C   661%2C   633%2C    22%2C%0A         8229%2C    13%2C  3966%2C    96%2C   360%2C   345...  719%2C    96%2C   309%2C   497%2C    94%2C   719%2C  1105%2C%0A           59%2C    80%2C    32%2C     7%2C   269%2C   154%2C 20119%2C    64%2C     7%2C  2881%5D%29%2C tensor%28%5B  96%2C  193%2C   42%2C   21%2C   59%2C   92%2C  200%2C  506%2C  108%2C   96%2C   21%2C   15%2C%0A          80%2C   59%2C  218%2C   13%2C 8965%2C   59%2C   ...7%2C    4%2C  768%2C   13%2C%0A        3576%2C  677%2C   86%2C  678%2C   64%2C  287%2C  193%2C  537%2C  265%2C   96%2C  151%2C  329%2C%0A           0%2C  679%2C   21%5D%29%2C tensor%28%5B  96%2C  336%2C   64%2C  141%2C  352%2C   47%2C   96%2C  104%2C  204%2C   96%2C   27%2C   61%2C%0A       ..." isContainer="True" shape="20000" />
<var name="test_data_path" type="str" qualifier="builtins" value="sentiment.test.csv" />
<var name="test_list" type="list" qualifier="builtins" value="%5Btensor%28%5B   96%2C   885%2C   626%2C     3%2C    96%2C  1132%2C    12%2C     7%2C   285%2C    21%2C%0A           96%2C    21%2C     1%2C  4050%2C     4%2C  6499...8504%2C  7595%2C     7%2C%0A         2087%2C   762%2C     7%2C   727%2C    42%2C   335%2C   385%2C   514%2C    98%2C   629%2C%0A          102%2C    13%2C   450%5D%29%2C tensor%28%5B  96%2C 1669%2C 1427%2C   98%2C   96%2C    9%2C   77%2C  207%2C 2651%2C  314%2C  804%2C   24%2C%0A           7%2C   96%2C   13%2C   86%2C 1887%2C   61%2C    7%2C  693%5D%29%2C tensor%28%5B   96%2C   193%2C   314%2C  4921%2C    21%2C   335%2C    59%2C   661%2C   633%2C    22%2C%0A         8229%2C    13%2C  3966%2C    96%2C   360%2C   345...  719%2C    96%2C   309%2C   497%2C    94%2C   719%2C  1105%2C%0A           59%2C    80%2C    32%2C     7%2C   269%2C   154%2C 20119%2C    64%2C     7%2C  2881%5D%29%2C tensor%28%5B  96%2C  193%2C   42%2C   21%2C   59%2C   92%2C  200%2C  506%2C  108%2C   96%2C   21%2C   15%2C%0A          80%2C   59%2C  218%2C   13%2C 8965%2C   59%2C   ...7%2C    4%2C  768%2C   13%2C%0A        3576%2C  677%2C   86%2C  678%2C   64%2C  287%2C  193%2C  537%2C  265%2C   96%2C  151%2C  329%2C%0A           0%2C  679%2C   21%5D%29%2C tensor%28%5B  96%2C  336%2C   64%2C  141%2C  352%2C   47%2C   96%2C  104%2C  204%2C   96%2C   27%2C   61%2C%0A       ..." isContainer="True" shape="20000" />
<var name="test_output" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27inst_id%27%2C %27predicted_label%27%5D %5B0            0              0.0%5D %5B1            1              1.0%5D %5B2            2              1.0%5D %5B3            3              1.0%5D %5B4            4              0.0%5D %5B...        ...              ...%5D %5B19995    19995              1.0%5D %5B19996    19996              1.0%5D %5B19997    19997              0.0%5D %5B19998    19998              1.0%5D %5B19999    19999              1.0%5D %5B%5D" isContainer="True" shape="(20000, 2)" />
<var name="text" type="str" qualifier="builtins" value="Seriously%2C what is going on here%3F Treating other living creatures with respect will be the downfall of mankind%3F I doubt it. Treating each other with no respect will." />
<var name="texts" type="list" qualifier="builtins" value="%5B%27Great analysis of what is happening to young adults today. Not a blame or political book.%27%2C %22It was a good read. A little slow for me at times but I still kept reading. I wish it wouldn%27t have taken so long to get to the plot.%22%2C %27I liked the Ogre Detective series but this is like it was written by a different person. The plot is just so improbable as ju...ith this series. I read the run up for some of the sequels and it seems like more of the same. Reads like a young adult novel.%27%2C %27Seriously%2C what is going on here%3F Treating other living creatures with respect will be the downfall of mankind%3F I doubt it. Treating each other with no respect will.%27%5D" isContainer="True" shape="4" />
<var name="tokenizer" type="RegexpTokenizer" qualifier="nltk.tokenize.regexp" value="RegexpTokenizer%28pattern=%27%5C%5Cw%2B%27%2C gaps=False%2C discard_empty=True%2C flags=re.UNICODE%7Cre.MULTILINE%7Cre.DOTALL%29" isContainer="True" />
<var name="tokens" type="list" qualifier="builtins" value="%5B%27%3CUNK&gt;%27%2C %27this%27%2C %27product%27%2C %27arrived%27%2C %27on%27%2C %27time%27%2C %27and%27%2C %27was%27%2C %27nicely%27%2C %27packaged%27%2C %27%3CUNK&gt;%27%2C %27found%27%2C %27its%27%2C %27quality%27%2C %27lacking%27%2C %27and%27%2C %27performance%27%2C %27subpar%27%2C %27compared%27%2C %27to%27%2C %27other%27%2C %27brands%27%5D" isContainer="True" shape="22" />
<var name="train_data_path" type="str" qualifier="builtins" value="sentiment.train.csv" />
<var name="train_dataset" type="TextDataset" qualifier="__main__" value="%3C__main__.TextDataset object at 0x00000232F2734410&gt;" isContainer="True" shape="160000" />
<var name="train_list" type="list" qualifier="builtins" value="%5B%28%5B   96     1   287    96   248    96     1   204 16850   291   110    24%2C    47    96   193   306    64    50    13    93%5D%2C array%281%29%29%2C %28%5B  96  884  234   21   96 1191 2472    7  693 1931 1926  268   96   96%2C   85 1688   96   21   67    7 1160  884 1578%5D%2C array%281%29%29%2C %28%5B  96    2  320   98 3569 7030   13   98    7  366   96  128 5745   14%2C  151   88  105 9655   96   88   96  123   59 1956  320   59  175   11%2C   15  128   88   96  140  105 9655 5834%5D%2C array%280%29%29%2C %28%5B  96    1  358   13  333  341   96   76 1775   83   96  241 1635 3070%2C   24   96   13 1196  729   61  305   95   96   76 1426   48    4  699%2C  117   96  115    4  486   24   96   96  356   76   96   62%5D%2C array%281%29%29%2C %28%5B  96 1427 1233   64  314  679   71   96    1  314 1131 1554 1555   98%2C  265 1905   96    1 7419   98 3204   87  310 1588  335   14  151  539%2C  232  287   14 1905  249    0    1    4  615  710   96   12   11%5D%2C array%281%29%29%2C %28%5B   96    64    88   314  1774  3195    24   345    24    96    26    96%2C    13  1178   341    ..." isContainer="True" shape="160000" />
<var name="train_loader" type="DataLoader" qualifier="torch.utils.data.dataloader" value="%3Ctorch.utils.data.dataloader.DataLoader object at 0x00000232F2735D00&gt;" isContainer="True" shape="160000" />
<var name="vocab_size" type="int" qualifier="builtins" value="40547" />
<var name="word_ids" type="Tensor" qualifier="torch" value="tensor%28%5B  96%2C  345%2C 8879%2C 1977%2C  385%2C 1364%2C   80%2C 4134%2C   24%2C 1105%2C  680%2C   19%2C%0A          13%2C   96%2C   96%2C   96%2C   94%2C   61%2C    0%2C   21%2C   13%2C   61%2C   96%2C   24%2C%0A          96%2C   96%2C  180%5D%29" isContainer="True" shape="(27,)" />
<var name="word_to_index" type="dict" qualifier="builtins" value="%7B%270%27%3A 6860%2C %2700%27%3A 7030%2C %27000%27%3A 7717%2C %27001%27%3A 38825%2C %27007%27%3A 28099%2C %2700am%27%3A 25993%2C %2701%27%3A 24762%2C %2702%27%3A 29846%2C %2703%27%3A 11089%2C %27039%27%3A 38140%2C %2704%27%3A 8057%2C %2705%27%3A 32280%2C %2706%27%3A 30353%2C %2707%27%3A 7063%2C %2708%27%3A 24586%2C %2709%27%3A 22275%2C %270f%27%3A 37971%2C %271%27%3A 793%2C %2710%27%3A 1684%2C %27100%27%3A 870%2C %271000%27%3A 10968%2C %2710000%27%3A 31123%2C %271000s%27%3A 20833%2C %271000x%27%3A 33996%2C %271001%27%3A 7910%2C %27100k%27%3A 39109%2C %27100s%27%3A 25367%2C %27100th%27%3A 879%2C %27101%27%3A 7005%2C %27101st%27%3A 26963%2C %27102%27%3A 29336%2C %27103%27%3A 31073%2C %27104%27%3A 31072%2C %27105%27%3A 27289%2C %27106%27%3A 11911%2C %271066%27%3A 34895%2C %27107%27%3A 733%2C %27108%27%3A 15245%2C %27109%27%3A 34772%2C %2710k%27%3A 16506%2C %2710th%27%3A 24530%2C %2710x%27%3A 22765%2C %2710yr%27%3A 28921%2C %2711%27%3A 3831%2C %27110%27%3A 18961%2C %271100%27%3A 36651%2C %27111%27%3A 18962%2C %27112%27%3A 11145%2C %27113%27%3A 32771%2C %27114%27%3A 24557%2C %27115%27%3A 15244%2C %27116%27%3A 19634%2C %27117%27%3A 39597%2C %27118%27%3A 21937%2C %27119%27%3A 38487%2C %2711pm%27%3A 25792%2C %2711th%27%3A 10687%2C %2712%27%3A 1681%2C %27120%27%3A 14299%2C %271200%27%3A 13958%2C %27121%27%3A 33184%2C %27122%27%3A 38431%2C %27123%27%3A 18402%2C %27124%27%3A 39041%2C %27125%27%3A 25024%2C %27126%27%3A 39242%2C %27127%27%3A 35211%2C %27128%27%3A 37280%2C %27129%27%3A 39683%2C %2712th%27%3A 10890%2C %2712yr%27%3A 17641%2C %2713%27%3A 3671%2C %27130%27..." isContainer="True" shape="40547" />
<var name="word_to_index_file" type="str" qualifier="builtins" value="./models/1st_model_word_to_index.pkl" />
</xml>
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="RegexpTokenizer" type="ABCMeta" qualifier="abc" value="%3Cclass %27nltk.tokenize.regexp.RegexpTokenizer%27&gt;" isContainer="True" />
<var name="attention_weights" type="Tensor" qualifier="torch" value="tensor%28%5B%5B%5B0.0093%2C 0.0118%2C 0.0088%2C 0.0070%5D%2C%0A         %5B0.0046%2C 0.0879%2C 0.2792%2C 0.0863%5D%2C%0A         %5B0.0374%2C 0.0160%2C 0.0139%2C 0.0731...0%2C 0.0038%5D%2C%0A         %5B0.0739%2C 0.0764%2C 0.0853%2C 0.0072%5D%2C%0A         %5B0.0866%2C 0.1320%2C 0.1848%2C 0.0021%5D%5D%5D%2C grad_fn=%3CSoftmaxBackward0&gt;%29" isContainer="True" shape="(1, 27, 4)" />
<var name="attn" type="ndarray" qualifier="numpy" value="%5B%5B3.8761396e-02 1.4316343e-03 3.5074565e-03 2.0801390e-03%5D%2C %5B2.4591111e-02 5.6007253e-03 6.1986055e-03 3.1265877e-02%5D%2C %5B2.3266392e-02 1.5529494e-03 3.2180738e-02 1.0921432e-02%5D%2C %5B2.7827655e-03 1.0171688e-02 1.4128776e-02 2.5735588e-03%5D%2C %5B1.8277273e-02 4.8935330e-03 7.0923351e-04 1.9113851e-03%5D%2C %5B3.3237633e-01 1.0533698e-02 1.0934884e-01 3.6092749e-04%5D%2C %5B2.4453353e-02 8.3953858e-04 8.5045584e-03 1.3689095e-03%5D%2C %5B8.1114441e-02 2.1813512e-02 3.3395069e-03 1.1676165e-02%5D%2C %5B3.9978933e-02 2.7990532e-03 2.9895086e-02 1.6270466e-02%5D%2C %5B7.2887810e-03 3.5754472e-04 1.7100248e-01 6.4502698e-03%5D%2C %5B3.8761396e-02 1.4316343e-03 3.5074565e-03 2.0801390e-03%5D%2C %5B1.8694693e-02 1.3729646e-02 2.7651500e-03 7.4767978e-03%5D%2C %5B6.7505077e-02 1.6143369e-03 8.6992960e-03 5.2691400e-03%5D%2C %5B7.2196382e-03 5.0290017e-03 1.8445179e-02 5.0763592e-02%5D%2C %5B3.1776860e-02 6.1441433e-02 6.8705566e-02 6.7701474e-02%5D%2C %5B2.4453353e-02 8.3953858e-04 8.5045584e-03 1.3689095e-03%5D%2C %5B2.1151653e-02 2.7802718e-04 6.4917473e-04 9.3950052e-0..." isContainer="True" shape="(22, 4)" />
<var name="avg_loss" type="float" qualifier="builtins" value="0.5819856327176094" />
<var name="batch_size" type="int" qualifier="builtins" value="1" />
<var name="best_f1" type="float64" qualifier="numpy" value="0.8370573902224065" shape="()" />
<var name="dev_data_path" type="str" qualifier="builtins" value="sentiment.dev.csv" />
<var name="dev_dataset" type="TextDataset" qualifier="__main__" value="%3C__main__.TextDataset object at 0x00000232EF22FBC0&gt;" isContainer="True" shape="20000" />
<var name="dev_f1" type="float64" qualifier="numpy" value="0.8180815876515987" shape="()" />
<var name="dev_list" type="list" qualifier="builtins" value="%5B%28%5B  96   96  193    4 7609   62   71   27  234   64  329   11   96    1%2C  629  314 7041 1811 1900 1018  177   96  104    4  105  106 4116   11%2C  264   11    1 1693  992   13 6499%5D%2C array%280%29%29%2C %28%5B   96   288     7  1160    71     3  1056   223   281    83 16366  2101%2C   268   607   140     7  1283    24 10093  1475    96 19270    98   951%2C 11996  2253   727   398     7    70    96     7 16366   781  2101   268%2C     7  3551    58    77  6499%5D%2C array%280%29%29%2C %28%5B  96    1   18 1818   27    0   21   96   15   88 5047   61    0   36%2C   61   96   13  104  190 4549   98   40   83 1712   61   96 1601   96%2C   96  551  200   81 1903    7   21  307   96 1043   96  772  200  172%2C   11  671 2278   96   96 1594   47   33 3211   15 3408  268    7  117%2C   24   33 5050%5D%2C array%281%29%29%2C %28%5B  96  193    4   18 1288   13  742 3822  862   96 3545 4912   77  128%2C 1236  884   96  128 3472  200  719 1755%5D%2C array%280%29%29%2C %28%5B  96  124  310  288    0   21   96    1  310   64   33 4288    6   96%2C  408  409 1695  151   62   11 ..." isContainer="True" shape="20000" />
<var name="dev_loader" type="DataLoader" qualifier="torch.utils.data.dataloader" value="%3Ctorch.utils.data.dataloader.DataLoader object at 0x00000232EF4AFBF0&gt;" isContainer="True" shape="20000" />
<var name="device" type="device" qualifier="torch" value="device%28type=%27cpu%27%29" isContainer="True" />
<var name="embedding_size" type="int" qualifier="builtins" value="50" />
<var name="embeddings_file_path" type="str" qualifier="builtins" value="./models/1st_model_embeddings_state_dict.pt" />
<var name="epoch" type="int" qualifier="builtins" value="0" />
<var name="epochs" type="int" qualifier="builtins" value="1" />
<var name="f" type="BufferedReader" qualifier="_io" value="%3C_io.BufferedReader name=%27./models/1st_model_index_to_word.pkl%27&gt;" isContainer="True" />
<var name="f1_scores" type="list" qualifier="builtins" value="%5B0.0%2C 0.21893018717289098%2C 0.29446606870874936%2C 0.5971060666401168%2C 0.48496934781003026%2C 0.6473546826255809%2C 0.7046656760772659%2C 0.6990291262135923%2C 0.7337489897240503%2C 0.7150351734827709%2C 0.7465940054495913%2C 0.749829893399864%2C 0.7700985761226725%2C 0.7603120264885797%2C 0.7680974799224591%2C 0.7579650274460982%2C 0.7954971857410882%2C 0.756486117432863%2C 0.7812174675360254%2C 0.7879639133488197%2C 0.768396679279381%2C 0.7723326799215906%2C 0.7731073573152253%2C 0.7886400873839432%2C 0.7827916505176901%2C 0.8015255045288415%2C 0.7956896551724137%2C 0.8103950103950104%2C 0.8042047143767255%2C 0.7872622733303848%2C 0.8037681622225771%2C 0.7996125699526474%2C 0.7792792792792793%2C 0.7899401728340351%2C 0.8128498927431591%2C 0.8020052827340844%2C 0.783627698345949%2C 0.8064017071218992%2C 0.7953884161405435%2C 0.8190939180802648%2C 0.8084879505224994%2C 0.7983602077070238%2C 0.7869421580155663%2C 0.8042299349240781%2C 0.805939524838013%2C 0.8133961166075869%2C 0.805041653142919%2C 0.8099191259171978%2C 0.8102107577626427%2C 0.8021671318338532%2C 0.792075892857142..." isContainer="True" shape="163" />
<var name="index_to_word" type="dict" qualifier="builtins" value="%7B0%3A %27this%27%2C 1%3A %27was%27%2C 2%3A %27bought%27%2C 3%3A %27as%27%2C 4%3A %27a%27%2C 5%3A %27gift%27%2C 6%3A %27but%27%2C 7%3A %27the%27%2C 8%3A %27person%27%2C 9%3A %27who%27%2C 10%3A %27got%27%2C 11%3A %27it%27%2C 12%3A %27loved%27%2C 13%3A %27and%27%2C 14%3A %27they%27%2C 15%3A %27will%27%2C 16%3A %27use%27%2C 17%3A %27soon%27%2C 18%3A %27very%27%2C 19%3A %27well%27%2C 20%3A %27written%27%2C 21%3A %27book%27%2C 22%3A %27on%27%2C 23%3A %27period%27%2C 24%3A %27of%27%2C 25%3A %27world%27%2C 26%3A %27history%27%2C 27%3A %27with%27%2C 28%3A %27which%27%2C 29%3A %27i%27%2C 30%3A %27am%27%2C 31%3A %27familiar%27%2C 32%3A %27despite%27%2C 33%3A %27my%27%2C 34%3A %27familiarity%27%2C 35%3A %27subject%27%2C 36%3A %27area%27%2C 37%3A %27learned%27%2C 38%3A %27lot%27%2C 39%3A %27new%27%2C 40%3A %27information%27%2C 41%3A %27also%27%2C 42%3A %27one%27%2C 43%3A %27best%27%2C 44%3A %27concise%27%2C 45%3A %27descriptions%27%2C 46%3A %27wwii%27%2C 47%3A %27that%27%2C 48%3A %27have%27%2C 49%3A %27ever%27%2C 50%3A %27read%27%2C 51%3A %27thought%27%2C 52%3A %27provoking%27%2C 53%3A %27hot%27%2C 54%3A %27cross%27%2C 55%3A %27buns%27%2C 56%3A %27contains%27%2C 57%3A %27cast%27%2C 58%3A %27characters%27%2C 59%3A %27you%27%2C 60%3A %27fall%27%2C 61%3A %27in%27%2C 62%3A %27love%27%2C 63%3A %27want%27%2C 64%3A %27to%27%2C 65%3A %27hang%27%2C 66%3A %27out%27%2C 67%3A %27has%27%2C 68%3A %27few%27%2C 69%3A %27different%27%2C 70%3A %27plot%27%2C 71%3A %27story%27%2C 72%3A %27lines%27%2C 73%3A %27intersect%27%2C 74%3A %27unexpected%27%2C 75%3A %27ways%27%2C 76%3A %27stories%27%2C 77%3A %27are%27%2C 78%3A %27full%27%2C 79%3A %27h..." isContainer="True" shape="40547" />
<var name="index_to_word_file" type="str" qualifier="builtins" value="./models/1st_model_index_to_word.pkl" />
<var name="label" type="float" qualifier="builtins" value="1.0" />
<var name="labels" type="Tensor" qualifier="torch" value="tensor%28%5B1.%5D%29" isContainer="True" shape="(1,)" />
<var name="learning_rate" type="float" qualifier="builtins" value="0.001" />
<var name="loss" type="Tensor" qualifier="torch" value="tensor%280.3133%2C grad_fn=%3CBinaryCrossEntropyWithLogitsBackward0&gt;%29" isContainer="True" shape="()" />
<var name="loss_function" type="BCEWithLogitsLoss" qualifier="torch.nn.modules.loss" value="BCEWithLogitsLoss%28%29" isContainer="True" />
<var name="losses" type="list" qualifier="builtins" value="%5B0.7063740156888961%2C 0.6690838242173195%2C 0.6710940192937851%2C 0.6416965731978417%2C 0.664360339820385%2C 0.6408256154060363%2C 0.6219880764484406%2C 0.6262354829907417%2C 0.6182727155685425%2C 0.6229372587800026%2C 0.6173186347484588%2C 0.6325475800037385%2C 0.5887129383683205%2C 0.6063905549049378%2C 0.5964332305192948%2C 0.6053036161065102%2C 0.576331036567688%2C 0.5984818696379661%2C 0.6024626339673996%2C 0.5853106815218926%2C 0.6045066975951194%2C 0.5990895519852638%2C 0.6025713908672333%2C 0.5945930997729302%2C 0.6004578600525856%2C 0.5832919328808784%2C 0.5881819829940796%2C 0.5846521648168563%2C 0.5884763289690018%2C 0.5964366135597229%2C 0.5868490883708%2C 0.5907454125285149%2C 0.6083347199559211%2C 0.5986561837792397%2C 0.5974684547781944%2C 0.5960528343319893%2C 0.5927959544062614%2C 0.5859969104528427%2C 0.6022085729837418%2C 0.5752854390740395%2C 0.5841937635540962%2C 0.5913211702108383%2C 0.6059050390124321%2C 0.5849579461812973%2C 0.5786286098361015%2C 0.5815764282941818%2C 0.5974919819831848%2C 0.5781187584400177%2C 0.5815025776624679%2C 0.5902935691475868%2C 0.58..." isContainer="True" shape="163" />
<var name="max_steps" type="int" qualifier="builtins" value="1000000000" />
<var name="model" type="DocumentAttentionClassifier" qualifier="__main__" value="DocumentAttentionClassifier%28%0A  %28embeddings%29%3A Embedding%2840547%2C 50%29%0A  %28linear%29%3A Linear%28in_features=200%2C out_features=1%2C bias=True%29%0A%29" isContainer="True" />
<var name="negative_samples" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B17160  I liked the Ogre Detective series but this is ...      0%5D %5B186    Seriously%2C what is going on here%3F Treating oth...      0%5D" isContainer="True" shape="(2, 2)" />
<var name="num_heads" type="int" qualifier="builtins" value="4" />
<var name="optimizer" type="AdamW" qualifier="torch.optim.adamw" value="AdamW %28%0AParameter Group 0%0A    amsgrad%3A False%0A    betas%3A %280.9%2C 0.999%29%0A    capturable%3A False%0A    differentiable%3A False%0A    eps%3A 1e-08%0A    foreach%3A None%0A    fused%3A None%0A    lr%3A 0.001%0A    maximize%3A False%0A    weight_decay%3A 0.01%0A%29" isContainer="True" />
<var name="patience" type="int" qualifier="builtins" value="30000" />
<var name="positive_samples" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B13479  Great analysis of what is happening to young a...      1%5D %5B12266  It was a good read. A little slow for me at ti...      1%5D" isContainer="True" shape="(2, 2)" />
<var name="pred" type="float" qualifier="builtins" value="1.0" />
<var name="prediction" type="float" qualifier="builtins" value="1.0" />
<var name="predictions" type="list" qualifier="builtins" value="%5B0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C..." isContainer="True" shape="20000" />
<var name="probability" type="Tensor" qualifier="torch" value="tensor%28%5B0.6481%5D%29" isContainer="True" shape="(1,)" />
<var name="running_loss" type="float" qualifier="builtins" value="0.0" />
<var name="s" type="str" qualifier="builtins" value="%0AI%27m a big fan of his%2C and I have to say that this was a BIG letdown. It features%3A Stilted dialogue%2C no character development%2C no suspense%2C no description of Indian tradition and poor editing.%0A%0AAvoid at all costs.%0A" />
<var name="sample_text" type="str" qualifier="builtins" value="Although this product arrived on time and was nicely packaged%2C I found its quality lacking and performance subpar compared to other brands." />
<var name="selected_samples" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B13479  Great analysis of what is happening to young a...      1%5D %5B12266  It was a good read. A little slow for me at ti...      1%5D %5B17160  I liked the Ogre Detective series but this is ...      0%5D %5B186    Seriously%2C what is going on here%3F Treating oth...      0%5D" isContainer="True" shape="(4, 2)" />
<var name="sent_dev_df" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B0      Picturing Perfect is a sappy love story with l...      0%5D %5B1      Seems like the same story as any other series ...      0%5D %5B2      I was very pleased with this book. I will be t...      1%5D %5B3      It is a very light and rather silly novel. The...      0%5D %5B4      I did not like this book. It was not to my tas...      0%5D %5B...                                                  ...    ...%5D %5B19995  Great content%2C the story is fantastic%2C but sho...      1%5D %5B19996  Typical book club book... Incest%2C child abuse%2C...      0%5D %5B19997  Fascinating book. Shorter than most Russell Ba...      1%5D %5B19998  This book is not well-organized%2C which is impo...      0%5D %5B19999  CAN WE CALL THIS A CLASSIC OF THE GENRE%3F I THI...      1%5D %5B%5D" isContainer="True" shape="(20000, 2)" />
<var name="sent_test_df" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27inst_id%27%2C %27text%27%2C %27predicted_label%27%5D %5B0            0  Really sad review as I absolutely loved the fi...   %5D %5B1            1  Excellent content%2C perfect for Christians who ...   %5D %5B2            2  This is an okay book if you need advice on bud...   %5D %5B3            3  This is one book you can%27t put down%21 This book...   %5D %5B4            4  There were to many names that I had no idenity...   %5D %5B...        ...                                                ...   %5D %5B19995    19995  I found this book to be a very entertaining an...   %5D %5B19996    19996  Wow%2C what a Middle School%21 Read this book your...   %5D %5B19997    19997  Not what I expected. Not enough about circular...   %5D %5B19998    19998  I like Joanne Fluke%27s mystery series starring ...   %5D %5B19999    19999  Grow some chickens%2C improve your land%2C make al...   %5D %5B%5D %5B0                  0.0  %5D %5B1                  1.0  %5D %5B2                  1.0  %5D %5B3                  1.0  %5D %5B4                  0.0  %5D %5B...                ...  %5D %5B19995         ..." isContainer="True" shape="(20000, 3)" />
<var name="sent_train_df" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B0       It was what I needed. There was no markings or...      1%5D %5B1       A cute little book. My wife gets the family wa...      1%5D %5B2       I bought these for 40.00 and for the price I j...      0%5D %5B3       It was interesting and enjoyable reading. Shor...      1%5D %5B4       A perfect ending to an amazing story. This was...      1%5D %5B...                                                   ...    ...%5D %5B159995  After reading every book Stephen King has to o...      1%5D %5B159996  Baby boomers who are experiencing %22aging eyeba...      0%5D %5B159997  Must read%2C must have%2C must read again. This bo...      1%5D %5B159998  Dr. Chopra%27s books are always enlightening and...      1%5D %5B159999  Boooring%21%21 Just enough to keep you intrigued f...      0%5D %5B%5D" isContainer="True" shape="(160000, 2)" />
<var name="step" type="int" qualifier="builtins" value="81499" />
<var name="steps_since_improvement" type="int" qualifier="builtins" value="30000" />
<var name="test_data" type="list" qualifier="builtins" value="%5Btensor%28%5B   96%2C   885%2C   626%2C     3%2C    96%2C  1132%2C    12%2C     7%2C   285%2C    21%2C%0A           96%2C    21%2C     1%2C  4050%2C     4%2C  6499...8504%2C  7595%2C     7%2C%0A         2087%2C   762%2C     7%2C   727%2C    42%2C   335%2C   385%2C   514%2C    98%2C   629%2C%0A          102%2C    13%2C   450%5D%29%2C tensor%28%5B  96%2C 1669%2C 1427%2C   98%2C   96%2C    9%2C   77%2C  207%2C 2651%2C  314%2C  804%2C   24%2C%0A           7%2C   96%2C   13%2C   86%2C 1887%2C   61%2C    7%2C  693%5D%29%2C tensor%28%5B   96%2C   193%2C   314%2C  4921%2C    21%2C   335%2C    59%2C   661%2C   633%2C    22%2C%0A         8229%2C    13%2C  3966%2C    96%2C   360%2C   345...  719%2C    96%2C   309%2C   497%2C    94%2C   719%2C  1105%2C%0A           59%2C    80%2C    32%2C     7%2C   269%2C   154%2C 20119%2C    64%2C     7%2C  2881%5D%29%2C tensor%28%5B  96%2C  193%2C   42%2C   21%2C   59%2C   92%2C  200%2C  506%2C  108%2C   96%2C   21%2C   15%2C%0A          80%2C   59%2C  218%2C   13%2C 8965%2C   59%2C   ...7%2C    4%2C  768%2C   13%2C%0A        3576%2C  677%2C   86%2C  678%2C   64%2C  287%2C  193%2C  537%2C  265%2C   96%2C  151%2C  329%2C%0A           0%2C  679%2C   21%5D%29%2C tensor%28%5B  96%2C  336%2C   64%2C  141%2C  352%2C   47%2C   96%2C  104%2C  204%2C   96%2C   27%2C   61%2C%0A       ..." isContainer="True" shape="20000" />
<var name="test_data_path" type="str" qualifier="builtins" value="sentiment.test.csv" />
<var name="test_list" type="list" qualifier="builtins" value="%5Btensor%28%5B   96%2C   885%2C   626%2C     3%2C    96%2C  1132%2C    12%2C     7%2C   285%2C    21%2C%0A           96%2C    21%2C     1%2C  4050%2C     4%2C  6499...8504%2C  7595%2C     7%2C%0A         2087%2C   762%2C     7%2C   727%2C    42%2C   335%2C   385%2C   514%2C    98%2C   629%2C%0A          102%2C    13%2C   450%5D%29%2C tensor%28%5B  96%2C 1669%2C 1427%2C   98%2C   96%2C    9%2C   77%2C  207%2C 2651%2C  314%2C  804%2C   24%2C%0A           7%2C   96%2C   13%2C   86%2C 1887%2C   61%2C    7%2C  693%5D%29%2C tensor%28%5B   96%2C   193%2C   314%2C  4921%2C    21%2C   335%2C    59%2C   661%2C   633%2C    22%2C%0A         8229%2C    13%2C  3966%2C    96%2C   360%2C   345...  719%2C    96%2C   309%2C   497%2C    94%2C   719%2C  1105%2C%0A           59%2C    80%2C    32%2C     7%2C   269%2C   154%2C 20119%2C    64%2C     7%2C  2881%5D%29%2C tensor%28%5B  96%2C  193%2C   42%2C   21%2C   59%2C   92%2C  200%2C  506%2C  108%2C   96%2C   21%2C   15%2C%0A          80%2C   59%2C  218%2C   13%2C 8965%2C   59%2C   ...7%2C    4%2C  768%2C   13%2C%0A        3576%2C  677%2C   86%2C  678%2C   64%2C  287%2C  193%2C  537%2C  265%2C   96%2C  151%2C  329%2C%0A           0%2C  679%2C   21%5D%29%2C tensor%28%5B  96%2C  336%2C   64%2C  141%2C  352%2C   47%2C   96%2C  104%2C  204%2C   96%2C   27%2C   61%2C%0A       ..." isContainer="True" shape="20000" />
<var name="test_output" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27inst_id%27%2C %27predicted_label%27%5D %5B0            0              0.0%5D %5B1            1              1.0%5D %5B2            2              1.0%5D %5B3            3              1.0%5D %5B4            4              0.0%5D %5B...        ...              ...%5D %5B19995    19995              1.0%5D %5B19996    19996              1.0%5D %5B19997    19997              0.0%5D %5B19998    19998              1.0%5D %5B19999    19999              1.0%5D %5B%5D" isContainer="True" shape="(20000, 2)" />
<var name="text" type="str" qualifier="builtins" value="Seriously%2C what is going on here%3F Treating other living creatures with respect will be the downfall of mankind%3F I doubt it. Treating each other with no respect will." />
<var name="texts" type="list" qualifier="builtins" value="%5B%27Great analysis of what is happening to young adults today. Not a blame or political book.%27%2C %22It was a good read. A little slow for me at times but I still kept reading. I wish it wouldn%27t have taken so long to get to the plot.%22%2C %27I liked the Ogre Detective series but this is like it was written by a different person. The plot is just so improbable as ju...ith this series. I read the run up for some of the sequels and it seems like more of the same. Reads like a young adult novel.%27%2C %27Seriously%2C what is going on here%3F Treating other living creatures with respect will be the downfall of mankind%3F I doubt it. Treating each other with no respect will.%27%5D" isContainer="True" shape="4" />
<var name="tokenizer" type="RegexpTokenizer" qualifier="nltk.tokenize.regexp" value="RegexpTokenizer%28pattern=%27%5C%5Cw%2B%27%2C gaps=False%2C discard_empty=True%2C flags=re.UNICODE%7Cre.MULTILINE%7Cre.DOTALL%29" isContainer="True" />
<var name="tokens" type="list" qualifier="builtins" value="%5B%27%3CUNK&gt;%27%2C %27this%27%2C %27product%27%2C %27arrived%27%2C %27on%27%2C %27time%27%2C %27and%27%2C %27was%27%2C %27nicely%27%2C %27packaged%27%2C %27%3CUNK&gt;%27%2C %27found%27%2C %27its%27%2C %27quality%27%2C %27lacking%27%2C %27and%27%2C %27performance%27%2C %27subpar%27%2C %27compared%27%2C %27to%27%2C %27other%27%2C %27brands%27%5D" isContainer="True" shape="22" />
<var name="train_data_path" type="str" qualifier="builtins" value="sentiment.train.csv" />
<var name="train_dataset" type="TextDataset" qualifier="__main__" value="%3C__main__.TextDataset object at 0x00000232F2734410&gt;" isContainer="True" shape="160000" />
<var name="train_list" type="list" qualifier="builtins" value="%5B%28%5B   96     1   287    96   248    96     1   204 16850   291   110    24%2C    47    96   193   306    64    50    13    93%5D%2C array%281%29%29%2C %28%5B  96  884  234   21   96 1191 2472    7  693 1931 1926  268   96   96%2C   85 1688   96   21   67    7 1160  884 1578%5D%2C array%281%29%29%2C %28%5B  96    2  320   98 3569 7030   13   98    7  366   96  128 5745   14%2C  151   88  105 9655   96   88   96  123   59 1956  320   59  175   11%2C   15  128   88   96  140  105 9655 5834%5D%2C array%280%29%29%2C %28%5B  96    1  358   13  333  341   96   76 1775   83   96  241 1635 3070%2C   24   96   13 1196  729   61  305   95   96   76 1426   48    4  699%2C  117   96  115    4  486   24   96   96  356   76   96   62%5D%2C array%281%29%29%2C %28%5B  96 1427 1233   64  314  679   71   96    1  314 1131 1554 1555   98%2C  265 1905   96    1 7419   98 3204   87  310 1588  335   14  151  539%2C  232  287   14 1905  249    0    1    4  615  710   96   12   11%5D%2C array%281%29%29%2C %28%5B   96    64    88   314  1774  3195    24   345    24    96    26    96%2C    13  1178   341    ..." isContainer="True" shape="160000" />
<var name="train_loader" type="DataLoader" qualifier="torch.utils.data.dataloader" value="%3Ctorch.utils.data.dataloader.DataLoader object at 0x00000232F2735D00&gt;" isContainer="True" shape="160000" />
<var name="vocab_size" type="int" qualifier="builtins" value="40547" />
<var name="word_ids" type="Tensor" qualifier="torch" value="tensor%28%5B  96%2C  345%2C 8879%2C 1977%2C  385%2C 1364%2C   80%2C 4134%2C   24%2C 1105%2C  680%2C   19%2C%0A          13%2C   96%2C   96%2C   96%2C   94%2C   61%2C    0%2C   21%2C   13%2C   61%2C   96%2C   24%2C%0A          96%2C   96%2C  180%5D%29" isContainer="True" shape="(27,)" />
<var name="word_to_index" type="dict" qualifier="builtins" value="%7B%270%27%3A 6860%2C %2700%27%3A 7030%2C %27000%27%3A 7717%2C %27001%27%3A 38825%2C %27007%27%3A 28099%2C %2700am%27%3A 25993%2C %2701%27%3A 24762%2C %2702%27%3A 29846%2C %2703%27%3A 11089%2C %27039%27%3A 38140%2C %2704%27%3A 8057%2C %2705%27%3A 32280%2C %2706%27%3A 30353%2C %2707%27%3A 7063%2C %2708%27%3A 24586%2C %2709%27%3A 22275%2C %270f%27%3A 37971%2C %271%27%3A 793%2C %2710%27%3A 1684%2C %27100%27%3A 870%2C %271000%27%3A 10968%2C %2710000%27%3A 31123%2C %271000s%27%3A 20833%2C %271000x%27%3A 33996%2C %271001%27%3A 7910%2C %27100k%27%3A 39109%2C %27100s%27%3A 25367%2C %27100th%27%3A 879%2C %27101%27%3A 7005%2C %27101st%27%3A 26963%2C %27102%27%3A 29336%2C %27103%27%3A 31073%2C %27104%27%3A 31072%2C %27105%27%3A 27289%2C %27106%27%3A 11911%2C %271066%27%3A 34895%2C %27107%27%3A 733%2C %27108%27%3A 15245%2C %27109%27%3A 34772%2C %2710k%27%3A 16506%2C %2710th%27%3A 24530%2C %2710x%27%3A 22765%2C %2710yr%27%3A 28921%2C %2711%27%3A 3831%2C %27110%27%3A 18961%2C %271100%27%3A 36651%2C %27111%27%3A 18962%2C %27112%27%3A 11145%2C %27113%27%3A 32771%2C %27114%27%3A 24557%2C %27115%27%3A 15244%2C %27116%27%3A 19634%2C %27117%27%3A 39597%2C %27118%27%3A 21937%2C %27119%27%3A 38487%2C %2711pm%27%3A 25792%2C %2711th%27%3A 10687%2C %2712%27%3A 1681%2C %27120%27%3A 14299%2C %271200%27%3A 13958%2C %27121%27%3A 33184%2C %27122%27%3A 38431%2C %27123%27%3A 18402%2C %27124%27%3A 39041%2C %27125%27%3A 25024%2C %27126%27%3A 39242%2C %27127%27%3A 35211%2C %27128%27%3A 37280%2C %27129%27%3A 39683%2C %2712th%27%3A 10890%2C %2712yr%27%3A 17641%2C %2713%27%3A 3671%2C %27130%27..." isContainer="True" shape="40547" />
<var name="word_to_index_file" type="str" qualifier="builtins" value="./models/1st_model_word_to_index.pkl" />
</xml>
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="RegexpTokenizer" type="ABCMeta" qualifier="abc" value="%3Cclass %27nltk.tokenize.regexp.RegexpTokenizer%27&gt;" isContainer="True" />
<var name="attention_weights" type="Tensor" qualifier="torch" value="tensor%28%5B%5B%5B0.0093%2C 0.0118%2C 0.0088%2C 0.0070%5D%2C%0A         %5B0.0046%2C 0.0879%2C 0.2792%2C 0.0863%5D%2C%0A         %5B0.0374%2C 0.0160%2C 0.0139%2C 0.0731...0%2C 0.0038%5D%2C%0A         %5B0.0739%2C 0.0764%2C 0.0853%2C 0.0072%5D%2C%0A         %5B0.0866%2C 0.1320%2C 0.1848%2C 0.0021%5D%5D%5D%2C grad_fn=%3CSoftmaxBackward0&gt;%29" isContainer="True" shape="(1, 27, 4)" />
<var name="attn" type="ndarray" qualifier="numpy" value="%5B%5B3.8761396e-02 1.4316343e-03 3.5074565e-03 2.0801390e-03%5D%2C %5B2.4591111e-02 5.6007253e-03 6.1986055e-03 3.1265877e-02%5D%2C %5B2.3266392e-02 1.5529494e-03 3.2180738e-02 1.0921432e-02%5D%2C %5B2.7827655e-03 1.0171688e-02 1.4128776e-02 2.5735588e-03%5D%2C %5B1.8277273e-02 4.8935330e-03 7.0923351e-04 1.9113851e-03%5D%2C %5B3.3237633e-01 1.0533698e-02 1.0934884e-01 3.6092749e-04%5D%2C %5B2.4453353e-02 8.3953858e-04 8.5045584e-03 1.3689095e-03%5D%2C %5B8.1114441e-02 2.1813512e-02 3.3395069e-03 1.1676165e-02%5D%2C %5B3.9978933e-02 2.7990532e-03 2.9895086e-02 1.6270466e-02%5D%2C %5B7.2887810e-03 3.5754472e-04 1.7100248e-01 6.4502698e-03%5D%2C %5B3.8761396e-02 1.4316343e-03 3.5074565e-03 2.0801390e-03%5D%2C %5B1.8694693e-02 1.3729646e-02 2.7651500e-03 7.4767978e-03%5D%2C %5B6.7505077e-02 1.6143369e-03 8.6992960e-03 5.2691400e-03%5D%2C %5B7.2196382e-03 5.0290017e-03 1.8445179e-02 5.0763592e-02%5D%2C %5B3.1776860e-02 6.1441433e-02 6.8705566e-02 6.7701474e-02%5D%2C %5B2.4453353e-02 8.3953858e-04 8.5045584e-03 1.3689095e-03%5D%2C %5B2.1151653e-02 2.7802718e-04 6.4917473e-04 9.3950052e-0..." isContainer="True" shape="(22, 4)" />
<var name="avg_loss" type="float" qualifier="builtins" value="0.5819856327176094" />
<var name="batch_size" type="int" qualifier="builtins" value="1" />
<var name="best_f1" type="float64" qualifier="numpy" value="0.8370573902224065" shape="()" />
<var name="dev_data_path" type="str" qualifier="builtins" value="sentiment.dev.csv" />
<var name="dev_dataset" type="TextDataset" qualifier="__main__" value="%3C__main__.TextDataset object at 0x00000232EF22FBC0&gt;" isContainer="True" shape="20000" />
<var name="dev_f1" type="float64" qualifier="numpy" value="0.8180815876515987" shape="()" />
<var name="dev_list" type="list" qualifier="builtins" value="%5B%28%5B  96   96  193    4 7609   62   71   27  234   64  329   11   96    1%2C  629  314 7041 1811 1900 1018  177   96  104    4  105  106 4116   11%2C  264   11    1 1693  992   13 6499%5D%2C array%280%29%29%2C %28%5B   96   288     7  1160    71     3  1056   223   281    83 16366  2101%2C   268   607   140     7  1283    24 10093  1475    96 19270    98   951%2C 11996  2253   727   398     7    70    96     7 16366   781  2101   268%2C     7  3551    58    77  6499%5D%2C array%280%29%29%2C %28%5B  96    1   18 1818   27    0   21   96   15   88 5047   61    0   36%2C   61   96   13  104  190 4549   98   40   83 1712   61   96 1601   96%2C   96  551  200   81 1903    7   21  307   96 1043   96  772  200  172%2C   11  671 2278   96   96 1594   47   33 3211   15 3408  268    7  117%2C   24   33 5050%5D%2C array%281%29%29%2C %28%5B  96  193    4   18 1288   13  742 3822  862   96 3545 4912   77  128%2C 1236  884   96  128 3472  200  719 1755%5D%2C array%280%29%29%2C %28%5B  96  124  310  288    0   21   96    1  310   64   33 4288    6   96%2C  408  409 1695  151   62   11 ..." isContainer="True" shape="20000" />
<var name="dev_loader" type="DataLoader" qualifier="torch.utils.data.dataloader" value="%3Ctorch.utils.data.dataloader.DataLoader object at 0x00000232EF4AFBF0&gt;" isContainer="True" shape="20000" />
<var name="device" type="device" qualifier="torch" value="device%28type=%27cpu%27%29" isContainer="True" />
<var name="embedding_size" type="int" qualifier="builtins" value="50" />
<var name="embeddings_file_path" type="str" qualifier="builtins" value="./models/1st_model_embeddings_state_dict.pt" />
<var name="epoch" type="int" qualifier="builtins" value="0" />
<var name="epochs" type="int" qualifier="builtins" value="1" />
<var name="f" type="BufferedReader" qualifier="_io" value="%3C_io.BufferedReader name=%27./models/1st_model_index_to_word.pkl%27&gt;" isContainer="True" />
<var name="f1_scores" type="list" qualifier="builtins" value="%5B0.0%2C 0.21893018717289098%2C 0.29446606870874936%2C 0.5971060666401168%2C 0.48496934781003026%2C 0.6473546826255809%2C 0.7046656760772659%2C 0.6990291262135923%2C 0.7337489897240503%2C 0.7150351734827709%2C 0.7465940054495913%2C 0.749829893399864%2C 0.7700985761226725%2C 0.7603120264885797%2C 0.7680974799224591%2C 0.7579650274460982%2C 0.7954971857410882%2C 0.756486117432863%2C 0.7812174675360254%2C 0.7879639133488197%2C 0.768396679279381%2C 0.7723326799215906%2C 0.7731073573152253%2C 0.7886400873839432%2C 0.7827916505176901%2C 0.8015255045288415%2C 0.7956896551724137%2C 0.8103950103950104%2C 0.8042047143767255%2C 0.7872622733303848%2C 0.8037681622225771%2C 0.7996125699526474%2C 0.7792792792792793%2C 0.7899401728340351%2C 0.8128498927431591%2C 0.8020052827340844%2C 0.783627698345949%2C 0.8064017071218992%2C 0.7953884161405435%2C 0.8190939180802648%2C 0.8084879505224994%2C 0.7983602077070238%2C 0.7869421580155663%2C 0.8042299349240781%2C 0.805939524838013%2C 0.8133961166075869%2C 0.805041653142919%2C 0.8099191259171978%2C 0.8102107577626427%2C 0.8021671318338532%2C 0.792075892857142..." isContainer="True" shape="163" />
<var name="index_to_word" type="dict" qualifier="builtins" value="%7B0%3A %27this%27%2C 1%3A %27was%27%2C 2%3A %27bought%27%2C 3%3A %27as%27%2C 4%3A %27a%27%2C 5%3A %27gift%27%2C 6%3A %27but%27%2C 7%3A %27the%27%2C 8%3A %27person%27%2C 9%3A %27who%27%2C 10%3A %27got%27%2C 11%3A %27it%27%2C 12%3A %27loved%27%2C 13%3A %27and%27%2C 14%3A %27they%27%2C 15%3A %27will%27%2C 16%3A %27use%27%2C 17%3A %27soon%27%2C 18%3A %27very%27%2C 19%3A %27well%27%2C 20%3A %27written%27%2C 21%3A %27book%27%2C 22%3A %27on%27%2C 23%3A %27period%27%2C 24%3A %27of%27%2C 25%3A %27world%27%2C 26%3A %27history%27%2C 27%3A %27with%27%2C 28%3A %27which%27%2C 29%3A %27i%27%2C 30%3A %27am%27%2C 31%3A %27familiar%27%2C 32%3A %27despite%27%2C 33%3A %27my%27%2C 34%3A %27familiarity%27%2C 35%3A %27subject%27%2C 36%3A %27area%27%2C 37%3A %27learned%27%2C 38%3A %27lot%27%2C 39%3A %27new%27%2C 40%3A %27information%27%2C 41%3A %27also%27%2C 42%3A %27one%27%2C 43%3A %27best%27%2C 44%3A %27concise%27%2C 45%3A %27descriptions%27%2C 46%3A %27wwii%27%2C 47%3A %27that%27%2C 48%3A %27have%27%2C 49%3A %27ever%27%2C 50%3A %27read%27%2C 51%3A %27thought%27%2C 52%3A %27provoking%27%2C 53%3A %27hot%27%2C 54%3A %27cross%27%2C 55%3A %27buns%27%2C 56%3A %27contains%27%2C 57%3A %27cast%27%2C 58%3A %27characters%27%2C 59%3A %27you%27%2C 60%3A %27fall%27%2C 61%3A %27in%27%2C 62%3A %27love%27%2C 63%3A %27want%27%2C 64%3A %27to%27%2C 65%3A %27hang%27%2C 66%3A %27out%27%2C 67%3A %27has%27%2C 68%3A %27few%27%2C 69%3A %27different%27%2C 70%3A %27plot%27%2C 71%3A %27story%27%2C 72%3A %27lines%27%2C 73%3A %27intersect%27%2C 74%3A %27unexpected%27%2C 75%3A %27ways%27%2C 76%3A %27stories%27%2C 77%3A %27are%27%2C 78%3A %27full%27%2C 79%3A %27h..." isContainer="True" shape="40547" />
<var name="index_to_word_file" type="str" qualifier="builtins" value="./models/1st_model_index_to_word.pkl" />
<var name="label" type="float" qualifier="builtins" value="1.0" />
<var name="labels" type="Tensor" qualifier="torch" value="tensor%28%5B1.%5D%29" isContainer="True" shape="(1,)" />
<var name="learning_rate" type="float" qualifier="builtins" value="0.001" />
<var name="loss" type="Tensor" qualifier="torch" value="tensor%280.3133%2C grad_fn=%3CBinaryCrossEntropyWithLogitsBackward0&gt;%29" isContainer="True" shape="()" />
<var name="loss_function" type="BCEWithLogitsLoss" qualifier="torch.nn.modules.loss" value="BCEWithLogitsLoss%28%29" isContainer="True" />
<var name="losses" type="list" qualifier="builtins" value="%5B0.7063740156888961%2C 0.6690838242173195%2C 0.6710940192937851%2C 0.6416965731978417%2C 0.664360339820385%2C 0.6408256154060363%2C 0.6219880764484406%2C 0.6262354829907417%2C 0.6182727155685425%2C 0.6229372587800026%2C 0.6173186347484588%2C 0.6325475800037385%2C 0.5887129383683205%2C 0.6063905549049378%2C 0.5964332305192948%2C 0.6053036161065102%2C 0.576331036567688%2C 0.5984818696379661%2C 0.6024626339673996%2C 0.5853106815218926%2C 0.6045066975951194%2C 0.5990895519852638%2C 0.6025713908672333%2C 0.5945930997729302%2C 0.6004578600525856%2C 0.5832919328808784%2C 0.5881819829940796%2C 0.5846521648168563%2C 0.5884763289690018%2C 0.5964366135597229%2C 0.5868490883708%2C 0.5907454125285149%2C 0.6083347199559211%2C 0.5986561837792397%2C 0.5974684547781944%2C 0.5960528343319893%2C 0.5927959544062614%2C 0.5859969104528427%2C 0.6022085729837418%2C 0.5752854390740395%2C 0.5841937635540962%2C 0.5913211702108383%2C 0.6059050390124321%2C 0.5849579461812973%2C 0.5786286098361015%2C 0.5815764282941818%2C 0.5974919819831848%2C 0.5781187584400177%2C 0.5815025776624679%2C 0.5902935691475868%2C 0.58..." isContainer="True" shape="163" />
<var name="max_steps" type="int" qualifier="builtins" value="1000000000" />
<var name="model" type="DocumentAttentionClassifier" qualifier="__main__" value="DocumentAttentionClassifier%28%0A  %28embeddings%29%3A Embedding%2840547%2C 50%29%0A  %28linear%29%3A Linear%28in_features=200%2C out_features=1%2C bias=True%29%0A%29" isContainer="True" />
<var name="negative_samples" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B17160  I liked the Ogre Detective series but this is ...      0%5D %5B186    Seriously%2C what is going on here%3F Treating oth...      0%5D" isContainer="True" shape="(2, 2)" />
<var name="num_heads" type="int" qualifier="builtins" value="4" />
<var name="optimizer" type="AdamW" qualifier="torch.optim.adamw" value="AdamW %28%0AParameter Group 0%0A    amsgrad%3A False%0A    betas%3A %280.9%2C 0.999%29%0A    capturable%3A False%0A    differentiable%3A False%0A    eps%3A 1e-08%0A    foreach%3A None%0A    fused%3A None%0A    lr%3A 0.001%0A    maximize%3A False%0A    weight_decay%3A 0.01%0A%29" isContainer="True" />
<var name="patience" type="int" qualifier="builtins" value="30000" />
<var name="positive_samples" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B13479  Great analysis of what is happening to young a...      1%5D %5B12266  It was a good read. A little slow for me at ti...      1%5D" isContainer="True" shape="(2, 2)" />
<var name="pred" type="float" qualifier="builtins" value="1.0" />
<var name="prediction" type="float" qualifier="builtins" value="1.0" />
<var name="predictions" type="list" qualifier="builtins" value="%5B0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C..." isContainer="True" shape="20000" />
<var name="probability" type="Tensor" qualifier="torch" value="tensor%28%5B0.6481%5D%29" isContainer="True" shape="(1,)" />
<var name="running_loss" type="float" qualifier="builtins" value="0.0" />
<var name="s" type="str" qualifier="builtins" value="%0AI%27m a big fan of his%2C and I have to say that this was a BIG letdown. It features%3A Stilted dialogue%2C no character development%2C no suspense%2C no description of Indian tradition and poor editing.%0A%0AAvoid at all costs.%0A" />
<var name="sample_text" type="str" qualifier="builtins" value="Although this product arrived on time and was nicely packaged%2C I found its quality lacking and performance subpar compared to other brands." />
<var name="selected_samples" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B13479  Great analysis of what is happening to young a...      1%5D %5B12266  It was a good read. A little slow for me at ti...      1%5D %5B17160  I liked the Ogre Detective series but this is ...      0%5D %5B186    Seriously%2C what is going on here%3F Treating oth...      0%5D" isContainer="True" shape="(4, 2)" />
<var name="sent_dev_df" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B0      Picturing Perfect is a sappy love story with l...      0%5D %5B1      Seems like the same story as any other series ...      0%5D %5B2      I was very pleased with this book. I will be t...      1%5D %5B3      It is a very light and rather silly novel. The...      0%5D %5B4      I did not like this book. It was not to my tas...      0%5D %5B...                                                  ...    ...%5D %5B19995  Great content%2C the story is fantastic%2C but sho...      1%5D %5B19996  Typical book club book... Incest%2C child abuse%2C...      0%5D %5B19997  Fascinating book. Shorter than most Russell Ba...      1%5D %5B19998  This book is not well-organized%2C which is impo...      0%5D %5B19999  CAN WE CALL THIS A CLASSIC OF THE GENRE%3F I THI...      1%5D %5B%5D" isContainer="True" shape="(20000, 2)" />
<var name="sent_test_df" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27inst_id%27%2C %27text%27%2C %27predicted_label%27%5D %5B0            0  Really sad review as I absolutely loved the fi...   %5D %5B1            1  Excellent content%2C perfect for Christians who ...   %5D %5B2            2  This is an okay book if you need advice on bud...   %5D %5B3            3  This is one book you can%27t put down%21 This book...   %5D %5B4            4  There were to many names that I had no idenity...   %5D %5B...        ...                                                ...   %5D %5B19995    19995  I found this book to be a very entertaining an...   %5D %5B19996    19996  Wow%2C what a Middle School%21 Read this book your...   %5D %5B19997    19997  Not what I expected. Not enough about circular...   %5D %5B19998    19998  I like Joanne Fluke%27s mystery series starring ...   %5D %5B19999    19999  Grow some chickens%2C improve your land%2C make al...   %5D %5B%5D %5B0                  0.0  %5D %5B1                  1.0  %5D %5B2                  1.0  %5D %5B3                  1.0  %5D %5B4                  0.0  %5D %5B...                ...  %5D %5B19995         ..." isContainer="True" shape="(20000, 3)" />
<var name="sent_train_df" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B0       It was what I needed. There was no markings or...      1%5D %5B1       A cute little book. My wife gets the family wa...      1%5D %5B2       I bought these for 40.00 and for the price I j...      0%5D %5B3       It was interesting and enjoyable reading. Shor...      1%5D %5B4       A perfect ending to an amazing story. This was...      1%5D %5B...                                                   ...    ...%5D %5B159995  After reading every book Stephen King has to o...      1%5D %5B159996  Baby boomers who are experiencing %22aging eyeba...      0%5D %5B159997  Must read%2C must have%2C must read again. This bo...      1%5D %5B159998  Dr. Chopra%27s books are always enlightening and...      1%5D %5B159999  Boooring%21%21 Just enough to keep you intrigued f...      0%5D %5B%5D" isContainer="True" shape="(160000, 2)" />
<var name="step" type="int" qualifier="builtins" value="81499" />
<var name="steps_since_improvement" type="int" qualifier="builtins" value="30000" />
<var name="test_data" type="list" qualifier="builtins" value="%5Btensor%28%5B   96%2C   885%2C   626%2C     3%2C    96%2C  1132%2C    12%2C     7%2C   285%2C    21%2C%0A           96%2C    21%2C     1%2C  4050%2C     4%2C  6499...8504%2C  7595%2C     7%2C%0A         2087%2C   762%2C     7%2C   727%2C    42%2C   335%2C   385%2C   514%2C    98%2C   629%2C%0A          102%2C    13%2C   450%5D%29%2C tensor%28%5B  96%2C 1669%2C 1427%2C   98%2C   96%2C    9%2C   77%2C  207%2C 2651%2C  314%2C  804%2C   24%2C%0A           7%2C   96%2C   13%2C   86%2C 1887%2C   61%2C    7%2C  693%5D%29%2C tensor%28%5B   96%2C   193%2C   314%2C  4921%2C    21%2C   335%2C    59%2C   661%2C   633%2C    22%2C%0A         8229%2C    13%2C  3966%2C    96%2C   360%2C   345...  719%2C    96%2C   309%2C   497%2C    94%2C   719%2C  1105%2C%0A           59%2C    80%2C    32%2C     7%2C   269%2C   154%2C 20119%2C    64%2C     7%2C  2881%5D%29%2C tensor%28%5B  96%2C  193%2C   42%2C   21%2C   59%2C   92%2C  200%2C  506%2C  108%2C   96%2C   21%2C   15%2C%0A          80%2C   59%2C  218%2C   13%2C 8965%2C   59%2C   ...7%2C    4%2C  768%2C   13%2C%0A        3576%2C  677%2C   86%2C  678%2C   64%2C  287%2C  193%2C  537%2C  265%2C   96%2C  151%2C  329%2C%0A           0%2C  679%2C   21%5D%29%2C tensor%28%5B  96%2C  336%2C   64%2C  141%2C  352%2C   47%2C   96%2C  104%2C  204%2C   96%2C   27%2C   61%2C%0A       ..." isContainer="True" shape="20000" />
<var name="test_data_path" type="str" qualifier="builtins" value="sentiment.test.csv" />
<var name="test_list" type="list" qualifier="builtins" value="%5Btensor%28%5B   96%2C   885%2C   626%2C     3%2C    96%2C  1132%2C    12%2C     7%2C   285%2C    21%2C%0A           96%2C    21%2C     1%2C  4050%2C     4%2C  6499...8504%2C  7595%2C     7%2C%0A         2087%2C   762%2C     7%2C   727%2C    42%2C   335%2C   385%2C   514%2C    98%2C   629%2C%0A          102%2C    13%2C   450%5D%29%2C tensor%28%5B  96%2C 1669%2C 1427%2C   98%2C   96%2C    9%2C   77%2C  207%2C 2651%2C  314%2C  804%2C   24%2C%0A           7%2C   96%2C   13%2C   86%2C 1887%2C   61%2C    7%2C  693%5D%29%2C tensor%28%5B   96%2C   193%2C   314%2C  4921%2C    21%2C   335%2C    59%2C   661%2C   633%2C    22%2C%0A         8229%2C    13%2C  3966%2C    96%2C   360%2C   345...  719%2C    96%2C   309%2C   497%2C    94%2C   719%2C  1105%2C%0A           59%2C    80%2C    32%2C     7%2C   269%2C   154%2C 20119%2C    64%2C     7%2C  2881%5D%29%2C tensor%28%5B  96%2C  193%2C   42%2C   21%2C   59%2C   92%2C  200%2C  506%2C  108%2C   96%2C   21%2C   15%2C%0A          80%2C   59%2C  218%2C   13%2C 8965%2C   59%2C   ...7%2C    4%2C  768%2C   13%2C%0A        3576%2C  677%2C   86%2C  678%2C   64%2C  287%2C  193%2C  537%2C  265%2C   96%2C  151%2C  329%2C%0A           0%2C  679%2C   21%5D%29%2C tensor%28%5B  96%2C  336%2C   64%2C  141%2C  352%2C   47%2C   96%2C  104%2C  204%2C   96%2C   27%2C   61%2C%0A       ..." isContainer="True" shape="20000" />
<var name="test_output" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27inst_id%27%2C %27predicted_label%27%5D %5B0            0              0.0%5D %5B1            1              1.0%5D %5B2            2              1.0%5D %5B3            3              1.0%5D %5B4            4              0.0%5D %5B...        ...              ...%5D %5B19995    19995              1.0%5D %5B19996    19996              1.0%5D %5B19997    19997              0.0%5D %5B19998    19998              1.0%5D %5B19999    19999              1.0%5D %5B%5D" isContainer="True" shape="(20000, 2)" />
<var name="text" type="str" qualifier="builtins" value="Seriously%2C what is going on here%3F Treating other living creatures with respect will be the downfall of mankind%3F I doubt it. Treating each other with no respect will." />
<var name="texts" type="list" qualifier="builtins" value="%5B%27Great analysis of what is happening to young adults today. Not a blame or political book.%27%2C %22It was a good read. A little slow for me at times but I still kept reading. I wish it wouldn%27t have taken so long to get to the plot.%22%2C %27I liked the Ogre Detective series but this is like it was written by a different person. The plot is just so improbable as ju...ith this series. I read the run up for some of the sequels and it seems like more of the same. Reads like a young adult novel.%27%2C %27Seriously%2C what is going on here%3F Treating other living creatures with respect will be the downfall of mankind%3F I doubt it. Treating each other with no respect will.%27%5D" isContainer="True" shape="4" />
<var name="tokenizer" type="RegexpTokenizer" qualifier="nltk.tokenize.regexp" value="RegexpTokenizer%28pattern=%27%5C%5Cw%2B%27%2C gaps=False%2C discard_empty=True%2C flags=re.UNICODE%7Cre.MULTILINE%7Cre.DOTALL%29" isContainer="True" />
<var name="tokens" type="list" qualifier="builtins" value="%5B%27%3CUNK&gt;%27%2C %27this%27%2C %27product%27%2C %27arrived%27%2C %27on%27%2C %27time%27%2C %27and%27%2C %27was%27%2C %27nicely%27%2C %27packaged%27%2C %27%3CUNK&gt;%27%2C %27found%27%2C %27its%27%2C %27quality%27%2C %27lacking%27%2C %27and%27%2C %27performance%27%2C %27subpar%27%2C %27compared%27%2C %27to%27%2C %27other%27%2C %27brands%27%5D" isContainer="True" shape="22" />
<var name="train_data_path" type="str" qualifier="builtins" value="sentiment.train.csv" />
<var name="train_dataset" type="TextDataset" qualifier="__main__" value="%3C__main__.TextDataset object at 0x00000232F2734410&gt;" isContainer="True" shape="160000" />
<var name="train_list" type="list" qualifier="builtins" value="%5B%28%5B   96     1   287    96   248    96     1   204 16850   291   110    24%2C    47    96   193   306    64    50    13    93%5D%2C array%281%29%29%2C %28%5B  96  884  234   21   96 1191 2472    7  693 1931 1926  268   96   96%2C   85 1688   96   21   67    7 1160  884 1578%5D%2C array%281%29%29%2C %28%5B  96    2  320   98 3569 7030   13   98    7  366   96  128 5745   14%2C  151   88  105 9655   96   88   96  123   59 1956  320   59  175   11%2C   15  128   88   96  140  105 9655 5834%5D%2C array%280%29%29%2C %28%5B  96    1  358   13  333  341   96   76 1775   83   96  241 1635 3070%2C   24   96   13 1196  729   61  305   95   96   76 1426   48    4  699%2C  117   96  115    4  486   24   96   96  356   76   96   62%5D%2C array%281%29%29%2C %28%5B  96 1427 1233   64  314  679   71   96    1  314 1131 1554 1555   98%2C  265 1905   96    1 7419   98 3204   87  310 1588  335   14  151  539%2C  232  287   14 1905  249    0    1    4  615  710   96   12   11%5D%2C array%281%29%29%2C %28%5B   96    64    88   314  1774  3195    24   345    24    96    26    96%2C    13  1178   341    ..." isContainer="True" shape="160000" />
<var name="train_loader" type="DataLoader" qualifier="torch.utils.data.dataloader" value="%3Ctorch.utils.data.dataloader.DataLoader object at 0x00000232F2735D00&gt;" isContainer="True" shape="160000" />
<var name="vocab_size" type="int" qualifier="builtins" value="40547" />
<var name="word_ids" type="Tensor" qualifier="torch" value="tensor%28%5B  96%2C  345%2C 8879%2C 1977%2C  385%2C 1364%2C   80%2C 4134%2C   24%2C 1105%2C  680%2C   19%2C%0A          13%2C   96%2C   96%2C   96%2C   94%2C   61%2C    0%2C   21%2C   13%2C   61%2C   96%2C   24%2C%0A          96%2C   96%2C  180%5D%29" isContainer="True" shape="(27,)" />
<var name="word_to_index" type="dict" qualifier="builtins" value="%7B%270%27%3A 6860%2C %2700%27%3A 7030%2C %27000%27%3A 7717%2C %27001%27%3A 38825%2C %27007%27%3A 28099%2C %2700am%27%3A 25993%2C %2701%27%3A 24762%2C %2702%27%3A 29846%2C %2703%27%3A 11089%2C %27039%27%3A 38140%2C %2704%27%3A 8057%2C %2705%27%3A 32280%2C %2706%27%3A 30353%2C %2707%27%3A 7063%2C %2708%27%3A 24586%2C %2709%27%3A 22275%2C %270f%27%3A 37971%2C %271%27%3A 793%2C %2710%27%3A 1684%2C %27100%27%3A 870%2C %271000%27%3A 10968%2C %2710000%27%3A 31123%2C %271000s%27%3A 20833%2C %271000x%27%3A 33996%2C %271001%27%3A 7910%2C %27100k%27%3A 39109%2C %27100s%27%3A 25367%2C %27100th%27%3A 879%2C %27101%27%3A 7005%2C %27101st%27%3A 26963%2C %27102%27%3A 29336%2C %27103%27%3A 31073%2C %27104%27%3A 31072%2C %27105%27%3A 27289%2C %27106%27%3A 11911%2C %271066%27%3A 34895%2C %27107%27%3A 733%2C %27108%27%3A 15245%2C %27109%27%3A 34772%2C %2710k%27%3A 16506%2C %2710th%27%3A 24530%2C %2710x%27%3A 22765%2C %2710yr%27%3A 28921%2C %2711%27%3A 3831%2C %27110%27%3A 18961%2C %271100%27%3A 36651%2C %27111%27%3A 18962%2C %27112%27%3A 11145%2C %27113%27%3A 32771%2C %27114%27%3A 24557%2C %27115%27%3A 15244%2C %27116%27%3A 19634%2C %27117%27%3A 39597%2C %27118%27%3A 21937%2C %27119%27%3A 38487%2C %2711pm%27%3A 25792%2C %2711th%27%3A 10687%2C %2712%27%3A 1681%2C %27120%27%3A 14299%2C %271200%27%3A 13958%2C %27121%27%3A 33184%2C %27122%27%3A 38431%2C %27123%27%3A 18402%2C %27124%27%3A 39041%2C %27125%27%3A 25024%2C %27126%27%3A 39242%2C %27127%27%3A 35211%2C %27128%27%3A 37280%2C %27129%27%3A 39683%2C %2712th%27%3A 10890%2C %2712yr%27%3A 17641%2C %2713%27%3A 3671%2C %27130%27..." isContainer="True" shape="40547" />
<var name="word_to_index_file" type="str" qualifier="builtins" value="./models/1st_model_word_to_index.pkl" />
</xml>
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="RegexpTokenizer" type="ABCMeta" qualifier="abc" value="%3Cclass %27nltk.tokenize.regexp.RegexpTokenizer%27&gt;" isContainer="True" />
<var name="attention_weights" type="Tensor" qualifier="torch" value="tensor%28%5B%5B%5B0.0093%2C 0.0118%2C 0.0088%2C 0.0070%5D%2C%0A         %5B0.0046%2C 0.0879%2C 0.2792%2C 0.0863%5D%2C%0A         %5B0.0374%2C 0.0160%2C 0.0139%2C 0.0731...0%2C 0.0038%5D%2C%0A         %5B0.0739%2C 0.0764%2C 0.0853%2C 0.0072%5D%2C%0A         %5B0.0866%2C 0.1320%2C 0.1848%2C 0.0021%5D%5D%5D%2C grad_fn=%3CSoftmaxBackward0&gt;%29" isContainer="True" shape="(1, 27, 4)" />
<var name="attn" type="ndarray" qualifier="numpy" value="%5B%5B3.8761396e-02 1.4316343e-03 3.5074565e-03 2.0801390e-03%5D%2C %5B2.4591111e-02 5.6007253e-03 6.1986055e-03 3.1265877e-02%5D%2C %5B2.3266392e-02 1.5529494e-03 3.2180738e-02 1.0921432e-02%5D%2C %5B2.7827655e-03 1.0171688e-02 1.4128776e-02 2.5735588e-03%5D%2C %5B1.8277273e-02 4.8935330e-03 7.0923351e-04 1.9113851e-03%5D%2C %5B3.3237633e-01 1.0533698e-02 1.0934884e-01 3.6092749e-04%5D%2C %5B2.4453353e-02 8.3953858e-04 8.5045584e-03 1.3689095e-03%5D%2C %5B8.1114441e-02 2.1813512e-02 3.3395069e-03 1.1676165e-02%5D%2C %5B3.9978933e-02 2.7990532e-03 2.9895086e-02 1.6270466e-02%5D%2C %5B7.2887810e-03 3.5754472e-04 1.7100248e-01 6.4502698e-03%5D%2C %5B3.8761396e-02 1.4316343e-03 3.5074565e-03 2.0801390e-03%5D%2C %5B1.8694693e-02 1.3729646e-02 2.7651500e-03 7.4767978e-03%5D%2C %5B6.7505077e-02 1.6143369e-03 8.6992960e-03 5.2691400e-03%5D%2C %5B7.2196382e-03 5.0290017e-03 1.8445179e-02 5.0763592e-02%5D%2C %5B3.1776860e-02 6.1441433e-02 6.8705566e-02 6.7701474e-02%5D%2C %5B2.4453353e-02 8.3953858e-04 8.5045584e-03 1.3689095e-03%5D%2C %5B2.1151653e-02 2.7802718e-04 6.4917473e-04 9.3950052e-0..." isContainer="True" shape="(22, 4)" />
<var name="avg_loss" type="float" qualifier="builtins" value="0.5819856327176094" />
<var name="batch_size" type="int" qualifier="builtins" value="1" />
<var name="best_f1" type="float64" qualifier="numpy" value="0.8370573902224065" shape="()" />
<var name="dev_data_path" type="str" qualifier="builtins" value="sentiment.dev.csv" />
<var name="dev_dataset" type="TextDataset" qualifier="__main__" value="%3C__main__.TextDataset object at 0x00000232EF22FBC0&gt;" isContainer="True" shape="20000" />
<var name="dev_f1" type="float64" qualifier="numpy" value="0.8180815876515987" shape="()" />
<var name="dev_list" type="list" qualifier="builtins" value="%5B%28%5B  96   96  193    4 7609   62   71   27  234   64  329   11   96    1%2C  629  314 7041 1811 1900 1018  177   96  104    4  105  106 4116   11%2C  264   11    1 1693  992   13 6499%5D%2C array%280%29%29%2C %28%5B   96   288     7  1160    71     3  1056   223   281    83 16366  2101%2C   268   607   140     7  1283    24 10093  1475    96 19270    98   951%2C 11996  2253   727   398     7    70    96     7 16366   781  2101   268%2C     7  3551    58    77  6499%5D%2C array%280%29%29%2C %28%5B  96    1   18 1818   27    0   21   96   15   88 5047   61    0   36%2C   61   96   13  104  190 4549   98   40   83 1712   61   96 1601   96%2C   96  551  200   81 1903    7   21  307   96 1043   96  772  200  172%2C   11  671 2278   96   96 1594   47   33 3211   15 3408  268    7  117%2C   24   33 5050%5D%2C array%281%29%29%2C %28%5B  96  193    4   18 1288   13  742 3822  862   96 3545 4912   77  128%2C 1236  884   96  128 3472  200  719 1755%5D%2C array%280%29%29%2C %28%5B  96  124  310  288    0   21   96    1  310   64   33 4288    6   96%2C  408  409 1695  151   62   11 ..." isContainer="True" shape="20000" />
<var name="dev_loader" type="DataLoader" qualifier="torch.utils.data.dataloader" value="%3Ctorch.utils.data.dataloader.DataLoader object at 0x00000232EF4AFBF0&gt;" isContainer="True" shape="20000" />
<var name="device" type="device" qualifier="torch" value="device%28type=%27cpu%27%29" isContainer="True" />
<var name="embedding_size" type="int" qualifier="builtins" value="50" />
<var name="embeddings_file_path" type="str" qualifier="builtins" value="./models/1st_model_embeddings_state_dict.pt" />
<var name="epoch" type="int" qualifier="builtins" value="0" />
<var name="epochs" type="int" qualifier="builtins" value="1" />
<var name="f" type="BufferedReader" qualifier="_io" value="%3C_io.BufferedReader name=%27./models/1st_model_index_to_word.pkl%27&gt;" isContainer="True" />
<var name="f1_scores" type="list" qualifier="builtins" value="%5B0.0%2C 0.21893018717289098%2C 0.29446606870874936%2C 0.5971060666401168%2C 0.48496934781003026%2C 0.6473546826255809%2C 0.7046656760772659%2C 0.6990291262135923%2C 0.7337489897240503%2C 0.7150351734827709%2C 0.7465940054495913%2C 0.749829893399864%2C 0.7700985761226725%2C 0.7603120264885797%2C 0.7680974799224591%2C 0.7579650274460982%2C 0.7954971857410882%2C 0.756486117432863%2C 0.7812174675360254%2C 0.7879639133488197%2C 0.768396679279381%2C 0.7723326799215906%2C 0.7731073573152253%2C 0.7886400873839432%2C 0.7827916505176901%2C 0.8015255045288415%2C 0.7956896551724137%2C 0.8103950103950104%2C 0.8042047143767255%2C 0.7872622733303848%2C 0.8037681622225771%2C 0.7996125699526474%2C 0.7792792792792793%2C 0.7899401728340351%2C 0.8128498927431591%2C 0.8020052827340844%2C 0.783627698345949%2C 0.8064017071218992%2C 0.7953884161405435%2C 0.8190939180802648%2C 0.8084879505224994%2C 0.7983602077070238%2C 0.7869421580155663%2C 0.8042299349240781%2C 0.805939524838013%2C 0.8133961166075869%2C 0.805041653142919%2C 0.8099191259171978%2C 0.8102107577626427%2C 0.8021671318338532%2C 0.792075892857142..." isContainer="True" shape="163" />
<var name="index_to_word" type="dict" qualifier="builtins" value="%7B0%3A %27this%27%2C 1%3A %27was%27%2C 2%3A %27bought%27%2C 3%3A %27as%27%2C 4%3A %27a%27%2C 5%3A %27gift%27%2C 6%3A %27but%27%2C 7%3A %27the%27%2C 8%3A %27person%27%2C 9%3A %27who%27%2C 10%3A %27got%27%2C 11%3A %27it%27%2C 12%3A %27loved%27%2C 13%3A %27and%27%2C 14%3A %27they%27%2C 15%3A %27will%27%2C 16%3A %27use%27%2C 17%3A %27soon%27%2C 18%3A %27very%27%2C 19%3A %27well%27%2C 20%3A %27written%27%2C 21%3A %27book%27%2C 22%3A %27on%27%2C 23%3A %27period%27%2C 24%3A %27of%27%2C 25%3A %27world%27%2C 26%3A %27history%27%2C 27%3A %27with%27%2C 28%3A %27which%27%2C 29%3A %27i%27%2C 30%3A %27am%27%2C 31%3A %27familiar%27%2C 32%3A %27despite%27%2C 33%3A %27my%27%2C 34%3A %27familiarity%27%2C 35%3A %27subject%27%2C 36%3A %27area%27%2C 37%3A %27learned%27%2C 38%3A %27lot%27%2C 39%3A %27new%27%2C 40%3A %27information%27%2C 41%3A %27also%27%2C 42%3A %27one%27%2C 43%3A %27best%27%2C 44%3A %27concise%27%2C 45%3A %27descriptions%27%2C 46%3A %27wwii%27%2C 47%3A %27that%27%2C 48%3A %27have%27%2C 49%3A %27ever%27%2C 50%3A %27read%27%2C 51%3A %27thought%27%2C 52%3A %27provoking%27%2C 53%3A %27hot%27%2C 54%3A %27cross%27%2C 55%3A %27buns%27%2C 56%3A %27contains%27%2C 57%3A %27cast%27%2C 58%3A %27characters%27%2C 59%3A %27you%27%2C 60%3A %27fall%27%2C 61%3A %27in%27%2C 62%3A %27love%27%2C 63%3A %27want%27%2C 64%3A %27to%27%2C 65%3A %27hang%27%2C 66%3A %27out%27%2C 67%3A %27has%27%2C 68%3A %27few%27%2C 69%3A %27different%27%2C 70%3A %27plot%27%2C 71%3A %27story%27%2C 72%3A %27lines%27%2C 73%3A %27intersect%27%2C 74%3A %27unexpected%27%2C 75%3A %27ways%27%2C 76%3A %27stories%27%2C 77%3A %27are%27%2C 78%3A %27full%27%2C 79%3A %27h..." isContainer="True" shape="40547" />
<var name="index_to_word_file" type="str" qualifier="builtins" value="./models/1st_model_index_to_word.pkl" />
<var name="label" type="float" qualifier="builtins" value="1.0" />
<var name="labels" type="Tensor" qualifier="torch" value="tensor%28%5B1.%5D%29" isContainer="True" shape="(1,)" />
<var name="learning_rate" type="float" qualifier="builtins" value="0.001" />
<var name="loss" type="Tensor" qualifier="torch" value="tensor%280.3133%2C grad_fn=%3CBinaryCrossEntropyWithLogitsBackward0&gt;%29" isContainer="True" shape="()" />
<var name="loss_function" type="BCEWithLogitsLoss" qualifier="torch.nn.modules.loss" value="BCEWithLogitsLoss%28%29" isContainer="True" />
<var name="losses" type="list" qualifier="builtins" value="%5B0.7063740156888961%2C 0.6690838242173195%2C 0.6710940192937851%2C 0.6416965731978417%2C 0.664360339820385%2C 0.6408256154060363%2C 0.6219880764484406%2C 0.6262354829907417%2C 0.6182727155685425%2C 0.6229372587800026%2C 0.6173186347484588%2C 0.6325475800037385%2C 0.5887129383683205%2C 0.6063905549049378%2C 0.5964332305192948%2C 0.6053036161065102%2C 0.576331036567688%2C 0.5984818696379661%2C 0.6024626339673996%2C 0.5853106815218926%2C 0.6045066975951194%2C 0.5990895519852638%2C 0.6025713908672333%2C 0.5945930997729302%2C 0.6004578600525856%2C 0.5832919328808784%2C 0.5881819829940796%2C 0.5846521648168563%2C 0.5884763289690018%2C 0.5964366135597229%2C 0.5868490883708%2C 0.5907454125285149%2C 0.6083347199559211%2C 0.5986561837792397%2C 0.5974684547781944%2C 0.5960528343319893%2C 0.5927959544062614%2C 0.5859969104528427%2C 0.6022085729837418%2C 0.5752854390740395%2C 0.5841937635540962%2C 0.5913211702108383%2C 0.6059050390124321%2C 0.5849579461812973%2C 0.5786286098361015%2C 0.5815764282941818%2C 0.5974919819831848%2C 0.5781187584400177%2C 0.5815025776624679%2C 0.5902935691475868%2C 0.58..." isContainer="True" shape="163" />
<var name="max_steps" type="int" qualifier="builtins" value="1000000000" />
<var name="model" type="DocumentAttentionClassifier" qualifier="__main__" value="DocumentAttentionClassifier%28%0A  %28embeddings%29%3A Embedding%2840547%2C 50%29%0A  %28linear%29%3A Linear%28in_features=200%2C out_features=1%2C bias=True%29%0A%29" isContainer="True" />
<var name="negative_samples" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B17160  I liked the Ogre Detective series but this is ...      0%5D %5B186    Seriously%2C what is going on here%3F Treating oth...      0%5D" isContainer="True" shape="(2, 2)" />
<var name="num_heads" type="int" qualifier="builtins" value="4" />
<var name="optimizer" type="AdamW" qualifier="torch.optim.adamw" value="AdamW %28%0AParameter Group 0%0A    amsgrad%3A False%0A    betas%3A %280.9%2C 0.999%29%0A    capturable%3A False%0A    differentiable%3A False%0A    eps%3A 1e-08%0A    foreach%3A None%0A    fused%3A None%0A    lr%3A 0.001%0A    maximize%3A False%0A    weight_decay%3A 0.01%0A%29" isContainer="True" />
<var name="patience" type="int" qualifier="builtins" value="30000" />
<var name="positive_samples" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B13479  Great analysis of what is happening to young a...      1%5D %5B12266  It was a good read. A little slow for me at ti...      1%5D" isContainer="True" shape="(2, 2)" />
<var name="pred" type="float" qualifier="builtins" value="1.0" />
<var name="prediction" type="float" qualifier="builtins" value="1.0" />
<var name="predictions" type="list" qualifier="builtins" value="%5B0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C..." isContainer="True" shape="20000" />
<var name="probability" type="Tensor" qualifier="torch" value="tensor%28%5B0.6481%5D%29" isContainer="True" shape="(1,)" />
<var name="running_loss" type="float" qualifier="builtins" value="0.0" />
<var name="s" type="str" qualifier="builtins" value="%0AI%27m a big fan of his%2C and I have to say that this was a BIG letdown. It features%3A Stilted dialogue%2C no character development%2C no suspense%2C no description of Indian tradition and poor editing.%0A%0AAvoid at all costs.%0A" />
<var name="sample_text" type="str" qualifier="builtins" value="Although this product arrived on time and was nicely packaged%2C I found its quality lacking and performance subpar compared to other brands." />
<var name="selected_samples" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B13479  Great analysis of what is happening to young a...      1%5D %5B12266  It was a good read. A little slow for me at ti...      1%5D %5B17160  I liked the Ogre Detective series but this is ...      0%5D %5B186    Seriously%2C what is going on here%3F Treating oth...      0%5D" isContainer="True" shape="(4, 2)" />
<var name="sent_dev_df" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B0      Picturing Perfect is a sappy love story with l...      0%5D %5B1      Seems like the same story as any other series ...      0%5D %5B2      I was very pleased with this book. I will be t...      1%5D %5B3      It is a very light and rather silly novel. The...      0%5D %5B4      I did not like this book. It was not to my tas...      0%5D %5B...                                                  ...    ...%5D %5B19995  Great content%2C the story is fantastic%2C but sho...      1%5D %5B19996  Typical book club book... Incest%2C child abuse%2C...      0%5D %5B19997  Fascinating book. Shorter than most Russell Ba...      1%5D %5B19998  This book is not well-organized%2C which is impo...      0%5D %5B19999  CAN WE CALL THIS A CLASSIC OF THE GENRE%3F I THI...      1%5D %5B%5D" isContainer="True" shape="(20000, 2)" />
<var name="sent_test_df" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27inst_id%27%2C %27text%27%2C %27predicted_label%27%5D %5B0            0  Really sad review as I absolutely loved the fi...   %5D %5B1            1  Excellent content%2C perfect for Christians who ...   %5D %5B2            2  This is an okay book if you need advice on bud...   %5D %5B3            3  This is one book you can%27t put down%21 This book...   %5D %5B4            4  There were to many names that I had no idenity...   %5D %5B...        ...                                                ...   %5D %5B19995    19995  I found this book to be a very entertaining an...   %5D %5B19996    19996  Wow%2C what a Middle School%21 Read this book your...   %5D %5B19997    19997  Not what I expected. Not enough about circular...   %5D %5B19998    19998  I like Joanne Fluke%27s mystery series starring ...   %5D %5B19999    19999  Grow some chickens%2C improve your land%2C make al...   %5D %5B%5D %5B0                  0.0  %5D %5B1                  1.0  %5D %5B2                  1.0  %5D %5B3                  1.0  %5D %5B4                  0.0  %5D %5B...                ...  %5D %5B19995         ..." isContainer="True" shape="(20000, 3)" />
<var name="sent_train_df" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B0       It was what I needed. There was no markings or...      1%5D %5B1       A cute little book. My wife gets the family wa...      1%5D %5B2       I bought these for 40.00 and for the price I j...      0%5D %5B3       It was interesting and enjoyable reading. Shor...      1%5D %5B4       A perfect ending to an amazing story. This was...      1%5D %5B...                                                   ...    ...%5D %5B159995  After reading every book Stephen King has to o...      1%5D %5B159996  Baby boomers who are experiencing %22aging eyeba...      0%5D %5B159997  Must read%2C must have%2C must read again. This bo...      1%5D %5B159998  Dr. Chopra%27s books are always enlightening and...      1%5D %5B159999  Boooring%21%21 Just enough to keep you intrigued f...      0%5D %5B%5D" isContainer="True" shape="(160000, 2)" />
<var name="step" type="int" qualifier="builtins" value="81499" />
<var name="steps_since_improvement" type="int" qualifier="builtins" value="30000" />
<var name="test_data" type="list" qualifier="builtins" value="%5Btensor%28%5B   96%2C   885%2C   626%2C     3%2C    96%2C  1132%2C    12%2C     7%2C   285%2C    21%2C%0A           96%2C    21%2C     1%2C  4050%2C     4%2C  6499...8504%2C  7595%2C     7%2C%0A         2087%2C   762%2C     7%2C   727%2C    42%2C   335%2C   385%2C   514%2C    98%2C   629%2C%0A          102%2C    13%2C   450%5D%29%2C tensor%28%5B  96%2C 1669%2C 1427%2C   98%2C   96%2C    9%2C   77%2C  207%2C 2651%2C  314%2C  804%2C   24%2C%0A           7%2C   96%2C   13%2C   86%2C 1887%2C   61%2C    7%2C  693%5D%29%2C tensor%28%5B   96%2C   193%2C   314%2C  4921%2C    21%2C   335%2C    59%2C   661%2C   633%2C    22%2C%0A         8229%2C    13%2C  3966%2C    96%2C   360%2C   345...  719%2C    96%2C   309%2C   497%2C    94%2C   719%2C  1105%2C%0A           59%2C    80%2C    32%2C     7%2C   269%2C   154%2C 20119%2C    64%2C     7%2C  2881%5D%29%2C tensor%28%5B  96%2C  193%2C   42%2C   21%2C   59%2C   92%2C  200%2C  506%2C  108%2C   96%2C   21%2C   15%2C%0A          80%2C   59%2C  218%2C   13%2C 8965%2C   59%2C   ...7%2C    4%2C  768%2C   13%2C%0A        3576%2C  677%2C   86%2C  678%2C   64%2C  287%2C  193%2C  537%2C  265%2C   96%2C  151%2C  329%2C%0A           0%2C  679%2C   21%5D%29%2C tensor%28%5B  96%2C  336%2C   64%2C  141%2C  352%2C   47%2C   96%2C  104%2C  204%2C   96%2C   27%2C   61%2C%0A       ..." isContainer="True" shape="20000" />
<var name="test_data_path" type="str" qualifier="builtins" value="sentiment.test.csv" />
<var name="test_list" type="list" qualifier="builtins" value="%5Btensor%28%5B   96%2C   885%2C   626%2C     3%2C    96%2C  1132%2C    12%2C     7%2C   285%2C    21%2C%0A           96%2C    21%2C     1%2C  4050%2C     4%2C  6499...8504%2C  7595%2C     7%2C%0A         2087%2C   762%2C     7%2C   727%2C    42%2C   335%2C   385%2C   514%2C    98%2C   629%2C%0A          102%2C    13%2C   450%5D%29%2C tensor%28%5B  96%2C 1669%2C 1427%2C   98%2C   96%2C    9%2C   77%2C  207%2C 2651%2C  314%2C  804%2C   24%2C%0A           7%2C   96%2C   13%2C   86%2C 1887%2C   61%2C    7%2C  693%5D%29%2C tensor%28%5B   96%2C   193%2C   314%2C  4921%2C    21%2C   335%2C    59%2C   661%2C   633%2C    22%2C%0A         8229%2C    13%2C  3966%2C    96%2C   360%2C   345...  719%2C    96%2C   309%2C   497%2C    94%2C   719%2C  1105%2C%0A           59%2C    80%2C    32%2C     7%2C   269%2C   154%2C 20119%2C    64%2C     7%2C  2881%5D%29%2C tensor%28%5B  96%2C  193%2C   42%2C   21%2C   59%2C   92%2C  200%2C  506%2C  108%2C   96%2C   21%2C   15%2C%0A          80%2C   59%2C  218%2C   13%2C 8965%2C   59%2C   ...7%2C    4%2C  768%2C   13%2C%0A        3576%2C  677%2C   86%2C  678%2C   64%2C  287%2C  193%2C  537%2C  265%2C   96%2C  151%2C  329%2C%0A           0%2C  679%2C   21%5D%29%2C tensor%28%5B  96%2C  336%2C   64%2C  141%2C  352%2C   47%2C   96%2C  104%2C  204%2C   96%2C   27%2C   61%2C%0A       ..." isContainer="True" shape="20000" />
<var name="test_output" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27inst_id%27%2C %27predicted_label%27%5D %5B0            0              0.0%5D %5B1            1              1.0%5D %5B2            2              1.0%5D %5B3            3              1.0%5D %5B4            4              0.0%5D %5B...        ...              ...%5D %5B19995    19995              1.0%5D %5B19996    19996              1.0%5D %5B19997    19997              0.0%5D %5B19998    19998              1.0%5D %5B19999    19999              1.0%5D %5B%5D" isContainer="True" shape="(20000, 2)" />
<var name="text" type="str" qualifier="builtins" value="Seriously%2C what is going on here%3F Treating other living creatures with respect will be the downfall of mankind%3F I doubt it. Treating each other with no respect will." />
<var name="texts" type="list" qualifier="builtins" value="%5B%27Great analysis of what is happening to young adults today. Not a blame or political book.%27%2C %22It was a good read. A little slow for me at times but I still kept reading. I wish it wouldn%27t have taken so long to get to the plot.%22%2C %27I liked the Ogre Detective series but this is like it was written by a different person. The plot is just so improbable as ju...ith this series. I read the run up for some of the sequels and it seems like more of the same. Reads like a young adult novel.%27%2C %27Seriously%2C what is going on here%3F Treating other living creatures with respect will be the downfall of mankind%3F I doubt it. Treating each other with no respect will.%27%5D" isContainer="True" shape="4" />
<var name="tokenizer" type="RegexpTokenizer" qualifier="nltk.tokenize.regexp" value="RegexpTokenizer%28pattern=%27%5C%5Cw%2B%27%2C gaps=False%2C discard_empty=True%2C flags=re.UNICODE%7Cre.MULTILINE%7Cre.DOTALL%29" isContainer="True" />
<var name="tokens" type="list" qualifier="builtins" value="%5B%27%3CUNK&gt;%27%2C %27this%27%2C %27product%27%2C %27arrived%27%2C %27on%27%2C %27time%27%2C %27and%27%2C %27was%27%2C %27nicely%27%2C %27packaged%27%2C %27%3CUNK&gt;%27%2C %27found%27%2C %27its%27%2C %27quality%27%2C %27lacking%27%2C %27and%27%2C %27performance%27%2C %27subpar%27%2C %27compared%27%2C %27to%27%2C %27other%27%2C %27brands%27%5D" isContainer="True" shape="22" />
<var name="train_data_path" type="str" qualifier="builtins" value="sentiment.train.csv" />
<var name="train_dataset" type="TextDataset" qualifier="__main__" value="%3C__main__.TextDataset object at 0x00000232F2734410&gt;" isContainer="True" shape="160000" />
<var name="train_list" type="list" qualifier="builtins" value="%5B%28%5B   96     1   287    96   248    96     1   204 16850   291   110    24%2C    47    96   193   306    64    50    13    93%5D%2C array%281%29%29%2C %28%5B  96  884  234   21   96 1191 2472    7  693 1931 1926  268   96   96%2C   85 1688   96   21   67    7 1160  884 1578%5D%2C array%281%29%29%2C %28%5B  96    2  320   98 3569 7030   13   98    7  366   96  128 5745   14%2C  151   88  105 9655   96   88   96  123   59 1956  320   59  175   11%2C   15  128   88   96  140  105 9655 5834%5D%2C array%280%29%29%2C %28%5B  96    1  358   13  333  341   96   76 1775   83   96  241 1635 3070%2C   24   96   13 1196  729   61  305   95   96   76 1426   48    4  699%2C  117   96  115    4  486   24   96   96  356   76   96   62%5D%2C array%281%29%29%2C %28%5B  96 1427 1233   64  314  679   71   96    1  314 1131 1554 1555   98%2C  265 1905   96    1 7419   98 3204   87  310 1588  335   14  151  539%2C  232  287   14 1905  249    0    1    4  615  710   96   12   11%5D%2C array%281%29%29%2C %28%5B   96    64    88   314  1774  3195    24   345    24    96    26    96%2C    13  1178   341    ..." isContainer="True" shape="160000" />
<var name="train_loader" type="DataLoader" qualifier="torch.utils.data.dataloader" value="%3Ctorch.utils.data.dataloader.DataLoader object at 0x00000232F2735D00&gt;" isContainer="True" shape="160000" />
<var name="vocab_size" type="int" qualifier="builtins" value="40547" />
<var name="word_ids" type="Tensor" qualifier="torch" value="tensor%28%5B  96%2C  345%2C 8879%2C 1977%2C  385%2C 1364%2C   80%2C 4134%2C   24%2C 1105%2C  680%2C   19%2C%0A          13%2C   96%2C   96%2C   96%2C   94%2C   61%2C    0%2C   21%2C   13%2C   61%2C   96%2C   24%2C%0A          96%2C   96%2C  180%5D%29" isContainer="True" shape="(27,)" />
<var name="word_to_index" type="dict" qualifier="builtins" value="%7B%270%27%3A 6860%2C %2700%27%3A 7030%2C %27000%27%3A 7717%2C %27001%27%3A 38825%2C %27007%27%3A 28099%2C %2700am%27%3A 25993%2C %2701%27%3A 24762%2C %2702%27%3A 29846%2C %2703%27%3A 11089%2C %27039%27%3A 38140%2C %2704%27%3A 8057%2C %2705%27%3A 32280%2C %2706%27%3A 30353%2C %2707%27%3A 7063%2C %2708%27%3A 24586%2C %2709%27%3A 22275%2C %270f%27%3A 37971%2C %271%27%3A 793%2C %2710%27%3A 1684%2C %27100%27%3A 870%2C %271000%27%3A 10968%2C %2710000%27%3A 31123%2C %271000s%27%3A 20833%2C %271000x%27%3A 33996%2C %271001%27%3A 7910%2C %27100k%27%3A 39109%2C %27100s%27%3A 25367%2C %27100th%27%3A 879%2C %27101%27%3A 7005%2C %27101st%27%3A 26963%2C %27102%27%3A 29336%2C %27103%27%3A 31073%2C %27104%27%3A 31072%2C %27105%27%3A 27289%2C %27106%27%3A 11911%2C %271066%27%3A 34895%2C %27107%27%3A 733%2C %27108%27%3A 15245%2C %27109%27%3A 34772%2C %2710k%27%3A 16506%2C %2710th%27%3A 24530%2C %2710x%27%3A 22765%2C %2710yr%27%3A 28921%2C %2711%27%3A 3831%2C %27110%27%3A 18961%2C %271100%27%3A 36651%2C %27111%27%3A 18962%2C %27112%27%3A 11145%2C %27113%27%3A 32771%2C %27114%27%3A 24557%2C %27115%27%3A 15244%2C %27116%27%3A 19634%2C %27117%27%3A 39597%2C %27118%27%3A 21937%2C %27119%27%3A 38487%2C %2711pm%27%3A 25792%2C %2711th%27%3A 10687%2C %2712%27%3A 1681%2C %27120%27%3A 14299%2C %271200%27%3A 13958%2C %27121%27%3A 33184%2C %27122%27%3A 38431%2C %27123%27%3A 18402%2C %27124%27%3A 39041%2C %27125%27%3A 25024%2C %27126%27%3A 39242%2C %27127%27%3A 35211%2C %27128%27%3A 37280%2C %27129%27%3A 39683%2C %2712th%27%3A 10890%2C %2712yr%27%3A 17641%2C %2713%27%3A 3671%2C %27130%27..." isContainer="True" shape="40547" />
<var name="word_to_index_file" type="str" qualifier="builtins" value="./models/1st_model_word_to_index.pkl" />
</xml>
Text: Loved it! When you get to the end of a story and i...
Predicted Label: 1.0
Text: I have read all of Zane's books, this is the funni...
Predicted Label: 1.0
Text: Book was dumb, with weird pictures and bad sayings...
Predicted Label: 1.0
Text: When I first heard about this book I literally tho...
Predicted Label: 1.0
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="RegexpTokenizer" type="ABCMeta" qualifier="abc" value="%3Cclass %27nltk.tokenize.regexp.RegexpTokenizer%27&gt;" isContainer="True" />
<var name="attention_weights" type="Tensor" qualifier="torch" value="tensor%28%5B%5B%5B0.0093%2C 0.0118%2C 0.0088%2C 0.0070%5D%2C%0A         %5B0.0046%2C 0.0879%2C 0.2792%2C 0.0863%5D%2C%0A         %5B0.0374%2C 0.0160%2C 0.0139%2C 0.0731...0%2C 0.0038%5D%2C%0A         %5B0.0739%2C 0.0764%2C 0.0853%2C 0.0072%5D%2C%0A         %5B0.0866%2C 0.1320%2C 0.1848%2C 0.0021%5D%5D%5D%2C grad_fn=%3CSoftmaxBackward0&gt;%29" isContainer="True" shape="(1, 27, 4)" />
<var name="attn" type="ndarray" qualifier="numpy" value="%5B%5B3.12299374e-02 6.82134926e-03 1.92939471e-02 4.58691735e-03%5D%2C %5B3.12299374e-02 6.82134926e-03 1.92939471e-02 4.58691735e-03%5D%2C %5B3.52431810e-03 2.97790039e-02 7.16688950e-03 1.12380218e-02%5D%2C %5B3.57809141e-02 3.00799441e-02 7.48392288e-03 6.05838038e-02%5D%2C %5B4.53295512e-03 1.16170142e-02 3.10207680e-02 9.94101726e-03%5D%2C %5B1.98129825e-02 2.66859327e-02 3.40975039e-02 6.89444244e-02%5D%2C %5B1.77816581e-02 4.04739790e-02 3.44825462e-02 5.30124381e-02%5D%2C %5B3.12299374e-02 6.82134926e-03 1.92939471e-02 4.58691735e-03%5D%2C %5B1.32573051e-02 3.23232114e-02 1.58345148e-01 1.79119706e-02%5D%2C %5B6.13963716e-02 2.24705823e-02 1.30350208e-02 8.99305642e-02%5D%2C %5B1.04593232e-01 1.42156594e-02 2.38560215e-02 2.24886909e-02%5D%2C %5B6.53536469e-02 1.03935473e-01 1.83700752e-02 2.57471241e-02%5D%2C %5B7.02043772e-02 3.78418807e-03 1.14975534e-02 2.33520870e-03%5D%2C %5B1.15178116e-02 1.63595490e-02 2.01911516e-02 1.28223505e-02%5D%2C %5B1.77816581e-02 4.04739790e-02 3.44825462e-02 5.30124381e-02%5D%2C %5B5.73283285e-02 2.95431223e-02 1.19173713e-02 2.566206..." isContainer="True" shape="(28, 4)" />
<var name="avg_loss" type="float" qualifier="builtins" value="0.5819856327176094" />
<var name="batch_size" type="int" qualifier="builtins" value="1" />
<var name="best_f1" type="float64" qualifier="numpy" value="0.8370573902224065" shape="()" />
<var name="dev_data_path" type="str" qualifier="builtins" value="sentiment.dev.csv" />
<var name="dev_dataset" type="TextDataset" qualifier="__main__" value="%3C__main__.TextDataset object at 0x00000232EF22FBC0&gt;" isContainer="True" shape="20000" />
<var name="dev_f1" type="float64" qualifier="numpy" value="0.8180815876515987" shape="()" />
<var name="dev_list" type="list" qualifier="builtins" value="%5B%28%5B  96   96  193    4 7609   62   71   27  234   64  329   11   96    1%2C  629  314 7041 1811 1900 1018  177   96  104    4  105  106 4116   11%2C  264   11    1 1693  992   13 6499%5D%2C array%280%29%29%2C %28%5B   96   288     7  1160    71     3  1056   223   281    83 16366  2101%2C   268   607   140     7  1283    24 10093  1475    96 19270    98   951%2C 11996  2253   727   398     7    70    96     7 16366   781  2101   268%2C     7  3551    58    77  6499%5D%2C array%280%29%29%2C %28%5B  96    1   18 1818   27    0   21   96   15   88 5047   61    0   36%2C   61   96   13  104  190 4549   98   40   83 1712   61   96 1601   96%2C   96  551  200   81 1903    7   21  307   96 1043   96  772  200  172%2C   11  671 2278   96   96 1594   47   33 3211   15 3408  268    7  117%2C   24   33 5050%5D%2C array%281%29%29%2C %28%5B  96  193    4   18 1288   13  742 3822  862   96 3545 4912   77  128%2C 1236  884   96  128 3472  200  719 1755%5D%2C array%280%29%29%2C %28%5B  96  124  310  288    0   21   96    1  310   64   33 4288    6   96%2C  408  409 1695  151   62   11 ..." isContainer="True" shape="20000" />
<var name="dev_loader" type="DataLoader" qualifier="torch.utils.data.dataloader" value="%3Ctorch.utils.data.dataloader.DataLoader object at 0x00000232EF4AFBF0&gt;" isContainer="True" shape="20000" />
<var name="device" type="device" qualifier="torch" value="device%28type=%27cpu%27%29" isContainer="True" />
<var name="embedding_size" type="int" qualifier="builtins" value="50" />
<var name="embeddings_file_path" type="str" qualifier="builtins" value="./models/1st_model_embeddings_state_dict.pt" />
<var name="epoch" type="int" qualifier="builtins" value="0" />
<var name="epochs" type="int" qualifier="builtins" value="1" />
<var name="f" type="BufferedReader" qualifier="_io" value="%3C_io.BufferedReader name=%27./models/1st_model_index_to_word.pkl%27&gt;" isContainer="True" />
<var name="f1_scores" type="list" qualifier="builtins" value="%5B0.0%2C 0.21893018717289098%2C 0.29446606870874936%2C 0.5971060666401168%2C 0.48496934781003026%2C 0.6473546826255809%2C 0.7046656760772659%2C 0.6990291262135923%2C 0.7337489897240503%2C 0.7150351734827709%2C 0.7465940054495913%2C 0.749829893399864%2C 0.7700985761226725%2C 0.7603120264885797%2C 0.7680974799224591%2C 0.7579650274460982%2C 0.7954971857410882%2C 0.756486117432863%2C 0.7812174675360254%2C 0.7879639133488197%2C 0.768396679279381%2C 0.7723326799215906%2C 0.7731073573152253%2C 0.7886400873839432%2C 0.7827916505176901%2C 0.8015255045288415%2C 0.7956896551724137%2C 0.8103950103950104%2C 0.8042047143767255%2C 0.7872622733303848%2C 0.8037681622225771%2C 0.7996125699526474%2C 0.7792792792792793%2C 0.7899401728340351%2C 0.8128498927431591%2C 0.8020052827340844%2C 0.783627698345949%2C 0.8064017071218992%2C 0.7953884161405435%2C 0.8190939180802648%2C 0.8084879505224994%2C 0.7983602077070238%2C 0.7869421580155663%2C 0.8042299349240781%2C 0.805939524838013%2C 0.8133961166075869%2C 0.805041653142919%2C 0.8099191259171978%2C 0.8102107577626427%2C 0.8021671318338532%2C 0.792075892857142..." isContainer="True" shape="163" />
<var name="index_to_word" type="dict" qualifier="builtins" value="%7B0%3A %27this%27%2C 1%3A %27was%27%2C 2%3A %27bought%27%2C 3%3A %27as%27%2C 4%3A %27a%27%2C 5%3A %27gift%27%2C 6%3A %27but%27%2C 7%3A %27the%27%2C 8%3A %27person%27%2C 9%3A %27who%27%2C 10%3A %27got%27%2C 11%3A %27it%27%2C 12%3A %27loved%27%2C 13%3A %27and%27%2C 14%3A %27they%27%2C 15%3A %27will%27%2C 16%3A %27use%27%2C 17%3A %27soon%27%2C 18%3A %27very%27%2C 19%3A %27well%27%2C 20%3A %27written%27%2C 21%3A %27book%27%2C 22%3A %27on%27%2C 23%3A %27period%27%2C 24%3A %27of%27%2C 25%3A %27world%27%2C 26%3A %27history%27%2C 27%3A %27with%27%2C 28%3A %27which%27%2C 29%3A %27i%27%2C 30%3A %27am%27%2C 31%3A %27familiar%27%2C 32%3A %27despite%27%2C 33%3A %27my%27%2C 34%3A %27familiarity%27%2C 35%3A %27subject%27%2C 36%3A %27area%27%2C 37%3A %27learned%27%2C 38%3A %27lot%27%2C 39%3A %27new%27%2C 40%3A %27information%27%2C 41%3A %27also%27%2C 42%3A %27one%27%2C 43%3A %27best%27%2C 44%3A %27concise%27%2C 45%3A %27descriptions%27%2C 46%3A %27wwii%27%2C 47%3A %27that%27%2C 48%3A %27have%27%2C 49%3A %27ever%27%2C 50%3A %27read%27%2C 51%3A %27thought%27%2C 52%3A %27provoking%27%2C 53%3A %27hot%27%2C 54%3A %27cross%27%2C 55%3A %27buns%27%2C 56%3A %27contains%27%2C 57%3A %27cast%27%2C 58%3A %27characters%27%2C 59%3A %27you%27%2C 60%3A %27fall%27%2C 61%3A %27in%27%2C 62%3A %27love%27%2C 63%3A %27want%27%2C 64%3A %27to%27%2C 65%3A %27hang%27%2C 66%3A %27out%27%2C 67%3A %27has%27%2C 68%3A %27few%27%2C 69%3A %27different%27%2C 70%3A %27plot%27%2C 71%3A %27story%27%2C 72%3A %27lines%27%2C 73%3A %27intersect%27%2C 74%3A %27unexpected%27%2C 75%3A %27ways%27%2C 76%3A %27stories%27%2C 77%3A %27are%27%2C 78%3A %27full%27%2C 79%3A %27h..." isContainer="True" shape="40547" />
<var name="index_to_word_file" type="str" qualifier="builtins" value="./models/1st_model_index_to_word.pkl" />
<var name="label" type="float" qualifier="builtins" value="1.0" />
<var name="labels" type="Tensor" qualifier="torch" value="tensor%28%5B1.%5D%29" isContainer="True" shape="(1,)" />
<var name="learning_rate" type="float" qualifier="builtins" value="0.001" />
<var name="loss" type="Tensor" qualifier="torch" value="tensor%280.3133%2C grad_fn=%3CBinaryCrossEntropyWithLogitsBackward0&gt;%29" isContainer="True" shape="()" />
<var name="loss_function" type="BCEWithLogitsLoss" qualifier="torch.nn.modules.loss" value="BCEWithLogitsLoss%28%29" isContainer="True" />
<var name="losses" type="list" qualifier="builtins" value="%5B0.7063740156888961%2C 0.6690838242173195%2C 0.6710940192937851%2C 0.6416965731978417%2C 0.664360339820385%2C 0.6408256154060363%2C 0.6219880764484406%2C 0.6262354829907417%2C 0.6182727155685425%2C 0.6229372587800026%2C 0.6173186347484588%2C 0.6325475800037385%2C 0.5887129383683205%2C 0.6063905549049378%2C 0.5964332305192948%2C 0.6053036161065102%2C 0.576331036567688%2C 0.5984818696379661%2C 0.6024626339673996%2C 0.5853106815218926%2C 0.6045066975951194%2C 0.5990895519852638%2C 0.6025713908672333%2C 0.5945930997729302%2C 0.6004578600525856%2C 0.5832919328808784%2C 0.5881819829940796%2C 0.5846521648168563%2C 0.5884763289690018%2C 0.5964366135597229%2C 0.5868490883708%2C 0.5907454125285149%2C 0.6083347199559211%2C 0.5986561837792397%2C 0.5974684547781944%2C 0.5960528343319893%2C 0.5927959544062614%2C 0.5859969104528427%2C 0.6022085729837418%2C 0.5752854390740395%2C 0.5841937635540962%2C 0.5913211702108383%2C 0.6059050390124321%2C 0.5849579461812973%2C 0.5786286098361015%2C 0.5815764282941818%2C 0.5974919819831848%2C 0.5781187584400177%2C 0.5815025776624679%2C 0.5902935691475868%2C 0.58..." isContainer="True" shape="163" />
<var name="max_steps" type="int" qualifier="builtins" value="1000000000" />
<var name="model" type="DocumentAttentionClassifier" qualifier="__main__" value="DocumentAttentionClassifier%28%0A  %28embeddings%29%3A Embedding%2840547%2C 50%29%0A  %28linear%29%3A Linear%28in_features=200%2C out_features=1%2C bias=True%29%0A%29" isContainer="True" />
<var name="negative_samples" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B2019   Book was dumb%2C with weird pictures and bad say...      0%5D %5B14108  When I first heard about this book I literally...      0%5D" isContainer="True" shape="(2, 2)" />
<var name="num_heads" type="int" qualifier="builtins" value="4" />
<var name="optimizer" type="AdamW" qualifier="torch.optim.adamw" value="AdamW %28%0AParameter Group 0%0A    amsgrad%3A False%0A    betas%3A %280.9%2C 0.999%29%0A    capturable%3A False%0A    differentiable%3A False%0A    eps%3A 1e-08%0A    foreach%3A None%0A    fused%3A None%0A    lr%3A 0.001%0A    maximize%3A False%0A    weight_decay%3A 0.01%0A%29" isContainer="True" />
<var name="patience" type="int" qualifier="builtins" value="30000" />
<var name="positive_samples" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B1076  Loved it%21 When you get to the end of a story a...      1%5D %5B2523  I have read all of Zane%27s books%2C this is the f...      1%5D" isContainer="True" shape="(2, 2)" />
<var name="pred" type="float" qualifier="builtins" value="1.0" />
<var name="prediction" type="float" qualifier="builtins" value="1.0" />
<var name="predictions" type="list" qualifier="builtins" value="%5B0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C..." isContainer="True" shape="20000" />
<var name="probability" type="Tensor" qualifier="torch" value="tensor%28%5B0.6481%5D%29" isContainer="True" shape="(1,)" />
<var name="running_loss" type="float" qualifier="builtins" value="0.0" />
<var name="s" type="str" qualifier="builtins" value="%0AI%27m a big fan of his%2C and I have to say that this was a BIG letdown. It features%3A Stilted dialogue%2C no character development%2C no suspense%2C no description of Indian tradition and poor editing.%0A%0AAvoid at all costs.%0A" />
<var name="sample_text" type="str" qualifier="builtins" value="Although this product arrived on time and was nicely packaged%2C I found its quality lacking and performance subpar compared to other brands." />
<var name="selected_samples" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B1076   Loved it%21 When you get to the end of a story a...      1%5D %5B2523   I have read all of Zane%27s books%2C this is the f...      1%5D %5B2019   Book was dumb%2C with weird pictures and bad say...      0%5D %5B14108  When I first heard about this book I literally...      0%5D" isContainer="True" shape="(4, 2)" />
<var name="sent_dev_df" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B0      Picturing Perfect is a sappy love story with l...      0%5D %5B1      Seems like the same story as any other series ...      0%5D %5B2      I was very pleased with this book. I will be t...      1%5D %5B3      It is a very light and rather silly novel. The...      0%5D %5B4      I did not like this book. It was not to my tas...      0%5D %5B...                                                  ...    ...%5D %5B19995  Great content%2C the story is fantastic%2C but sho...      1%5D %5B19996  Typical book club book... Incest%2C child abuse%2C...      0%5D %5B19997  Fascinating book. Shorter than most Russell Ba...      1%5D %5B19998  This book is not well-organized%2C which is impo...      0%5D %5B19999  CAN WE CALL THIS A CLASSIC OF THE GENRE%3F I THI...      1%5D %5B%5D" isContainer="True" shape="(20000, 2)" />
<var name="sent_test_df" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27inst_id%27%2C %27text%27%2C %27predicted_label%27%5D %5B0            0  Really sad review as I absolutely loved the fi...   %5D %5B1            1  Excellent content%2C perfect for Christians who ...   %5D %5B2            2  This is an okay book if you need advice on bud...   %5D %5B3            3  This is one book you can%27t put down%21 This book...   %5D %5B4            4  There were to many names that I had no idenity...   %5D %5B...        ...                                                ...   %5D %5B19995    19995  I found this book to be a very entertaining an...   %5D %5B19996    19996  Wow%2C what a Middle School%21 Read this book your...   %5D %5B19997    19997  Not what I expected. Not enough about circular...   %5D %5B19998    19998  I like Joanne Fluke%27s mystery series starring ...   %5D %5B19999    19999  Grow some chickens%2C improve your land%2C make al...   %5D %5B%5D %5B0                  0.0  %5D %5B1                  1.0  %5D %5B2                  1.0  %5D %5B3                  1.0  %5D %5B4                  0.0  %5D %5B...                ...  %5D %5B19995         ..." isContainer="True" shape="(20000, 3)" />
<var name="sent_train_df" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B0       It was what I needed. There was no markings or...      1%5D %5B1       A cute little book. My wife gets the family wa...      1%5D %5B2       I bought these for 40.00 and for the price I j...      0%5D %5B3       It was interesting and enjoyable reading. Shor...      1%5D %5B4       A perfect ending to an amazing story. This was...      1%5D %5B...                                                   ...    ...%5D %5B159995  After reading every book Stephen King has to o...      1%5D %5B159996  Baby boomers who are experiencing %22aging eyeba...      0%5D %5B159997  Must read%2C must have%2C must read again. This bo...      1%5D %5B159998  Dr. Chopra%27s books are always enlightening and...      1%5D %5B159999  Boooring%21%21 Just enough to keep you intrigued f...      0%5D %5B%5D" isContainer="True" shape="(160000, 2)" />
<var name="step" type="int" qualifier="builtins" value="81499" />
<var name="steps_since_improvement" type="int" qualifier="builtins" value="30000" />
<var name="test_data" type="list" qualifier="builtins" value="%5Btensor%28%5B   96%2C   885%2C   626%2C     3%2C    96%2C  1132%2C    12%2C     7%2C   285%2C    21%2C%0A           96%2C    21%2C     1%2C  4050%2C     4%2C  6499...8504%2C  7595%2C     7%2C%0A         2087%2C   762%2C     7%2C   727%2C    42%2C   335%2C   385%2C   514%2C    98%2C   629%2C%0A          102%2C    13%2C   450%5D%29%2C tensor%28%5B  96%2C 1669%2C 1427%2C   98%2C   96%2C    9%2C   77%2C  207%2C 2651%2C  314%2C  804%2C   24%2C%0A           7%2C   96%2C   13%2C   86%2C 1887%2C   61%2C    7%2C  693%5D%29%2C tensor%28%5B   96%2C   193%2C   314%2C  4921%2C    21%2C   335%2C    59%2C   661%2C   633%2C    22%2C%0A         8229%2C    13%2C  3966%2C    96%2C   360%2C   345...  719%2C    96%2C   309%2C   497%2C    94%2C   719%2C  1105%2C%0A           59%2C    80%2C    32%2C     7%2C   269%2C   154%2C 20119%2C    64%2C     7%2C  2881%5D%29%2C tensor%28%5B  96%2C  193%2C   42%2C   21%2C   59%2C   92%2C  200%2C  506%2C  108%2C   96%2C   21%2C   15%2C%0A          80%2C   59%2C  218%2C   13%2C 8965%2C   59%2C   ...7%2C    4%2C  768%2C   13%2C%0A        3576%2C  677%2C   86%2C  678%2C   64%2C  287%2C  193%2C  537%2C  265%2C   96%2C  151%2C  329%2C%0A           0%2C  679%2C   21%5D%29%2C tensor%28%5B  96%2C  336%2C   64%2C  141%2C  352%2C   47%2C   96%2C  104%2C  204%2C   96%2C   27%2C   61%2C%0A       ..." isContainer="True" shape="20000" />
<var name="test_data_path" type="str" qualifier="builtins" value="sentiment.test.csv" />
<var name="test_list" type="list" qualifier="builtins" value="%5Btensor%28%5B   96%2C   885%2C   626%2C     3%2C    96%2C  1132%2C    12%2C     7%2C   285%2C    21%2C%0A           96%2C    21%2C     1%2C  4050%2C     4%2C  6499...8504%2C  7595%2C     7%2C%0A         2087%2C   762%2C     7%2C   727%2C    42%2C   335%2C   385%2C   514%2C    98%2C   629%2C%0A          102%2C    13%2C   450%5D%29%2C tensor%28%5B  96%2C 1669%2C 1427%2C   98%2C   96%2C    9%2C   77%2C  207%2C 2651%2C  314%2C  804%2C   24%2C%0A           7%2C   96%2C   13%2C   86%2C 1887%2C   61%2C    7%2C  693%5D%29%2C tensor%28%5B   96%2C   193%2C   314%2C  4921%2C    21%2C   335%2C    59%2C   661%2C   633%2C    22%2C%0A         8229%2C    13%2C  3966%2C    96%2C   360%2C   345...  719%2C    96%2C   309%2C   497%2C    94%2C   719%2C  1105%2C%0A           59%2C    80%2C    32%2C     7%2C   269%2C   154%2C 20119%2C    64%2C     7%2C  2881%5D%29%2C tensor%28%5B  96%2C  193%2C   42%2C   21%2C   59%2C   92%2C  200%2C  506%2C  108%2C   96%2C   21%2C   15%2C%0A          80%2C   59%2C  218%2C   13%2C 8965%2C   59%2C   ...7%2C    4%2C  768%2C   13%2C%0A        3576%2C  677%2C   86%2C  678%2C   64%2C  287%2C  193%2C  537%2C  265%2C   96%2C  151%2C  329%2C%0A           0%2C  679%2C   21%5D%29%2C tensor%28%5B  96%2C  336%2C   64%2C  141%2C  352%2C   47%2C   96%2C  104%2C  204%2C   96%2C   27%2C   61%2C%0A       ..." isContainer="True" shape="20000" />
<var name="test_output" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27inst_id%27%2C %27predicted_label%27%5D %5B0            0              0.0%5D %5B1            1              1.0%5D %5B2            2              1.0%5D %5B3            3              1.0%5D %5B4            4              0.0%5D %5B...        ...              ...%5D %5B19995    19995              1.0%5D %5B19996    19996              1.0%5D %5B19997    19997              0.0%5D %5B19998    19998              1.0%5D %5B19999    19999              1.0%5D %5B%5D" isContainer="True" shape="(20000, 2)" />
<var name="text" type="str" qualifier="builtins" value="When I first heard about this book I literally thought it was a baby book%2C but it was really good book. And any age could read this book." />
<var name="texts" type="list" qualifier="builtins" value="%5B%22Loved it%21 When you get to the end of a story and it makes you sad%2C you know it%27s good.%22%2C %22I have read all of Zane%27s books%2C this is the funniest one yet. It is a must read for anyone looking for a good book to curl u...%2C I would recommend that you go for it and write Shame on it all again. I would be the first at the bookstore to get my copy%21%21%22%2C %27Book was dumb%2C with weird pictures and bad sayings. Even as a pewdiepie fan%2C he could have made this better%27%2C %27When I first heard about this book I literally thought it was a baby book%2C but it was really good book. And any age could read this book.%27%5D" isContainer="True" shape="4" />
<var name="tokenizer" type="RegexpTokenizer" qualifier="nltk.tokenize.regexp" value="RegexpTokenizer%28pattern=%27%5C%5Cw%2B%27%2C gaps=False%2C discard_empty=True%2C flags=re.UNICODE%7Cre.MULTILINE%7Cre.DOTALL%29" isContainer="True" />
<var name="tokens" type="list" qualifier="builtins" value="%5B%27%3CUNK&gt;%27%2C %27%3CUNK&gt;%27%2C %27first%27%2C %27heard%27%2C %27about%27%2C %27this%27%2C %27book%27%2C %27%3CUNK&gt;%27%2C %27literally%27%2C %27thought%27%2C %27it%27%2C %27was%27%2C %27a%27%2C %27baby%27%2C %27book%27%2C %27but%27%2C %27it%27%2C %27was%27%2C %27really%27%2C %27good%27%2C %27book%27%2C %27%3CUNK&gt;%27%2C %27any%27%2C %27age%27%2C %27could%27%2C %27read%27%2C %27this%27%2C %27book%27%5D" isContainer="True" shape="28" />
<var name="train_data_path" type="str" qualifier="builtins" value="sentiment.train.csv" />
<var name="train_dataset" type="TextDataset" qualifier="__main__" value="%3C__main__.TextDataset object at 0x00000232F2734410&gt;" isContainer="True" shape="160000" />
<var name="train_list" type="list" qualifier="builtins" value="%5B%28%5B   96     1   287    96   248    96     1   204 16850   291   110    24%2C    47    96   193   306    64    50    13    93%5D%2C array%281%29%29%2C %28%5B  96  884  234   21   96 1191 2472    7  693 1931 1926  268   96   96%2C   85 1688   96   21   67    7 1160  884 1578%5D%2C array%281%29%29%2C %28%5B  96    2  320   98 3569 7030   13   98    7  366   96  128 5745   14%2C  151   88  105 9655   96   88   96  123   59 1956  320   59  175   11%2C   15  128   88   96  140  105 9655 5834%5D%2C array%280%29%29%2C %28%5B  96    1  358   13  333  341   96   76 1775   83   96  241 1635 3070%2C   24   96   13 1196  729   61  305   95   96   76 1426   48    4  699%2C  117   96  115    4  486   24   96   96  356   76   96   62%5D%2C array%281%29%29%2C %28%5B  96 1427 1233   64  314  679   71   96    1  314 1131 1554 1555   98%2C  265 1905   96    1 7419   98 3204   87  310 1588  335   14  151  539%2C  232  287   14 1905  249    0    1    4  615  710   96   12   11%5D%2C array%281%29%29%2C %28%5B   96    64    88   314  1774  3195    24   345    24    96    26    96%2C    13  1178   341    ..." isContainer="True" shape="160000" />
<var name="train_loader" type="DataLoader" qualifier="torch.utils.data.dataloader" value="%3Ctorch.utils.data.dataloader.DataLoader object at 0x00000232F2735D00&gt;" isContainer="True" shape="160000" />
<var name="vocab_size" type="int" qualifier="builtins" value="40547" />
<var name="word_ids" type="Tensor" qualifier="torch" value="tensor%28%5B  96%2C  345%2C 8879%2C 1977%2C  385%2C 1364%2C   80%2C 4134%2C   24%2C 1105%2C  680%2C   19%2C%0A          13%2C   96%2C   96%2C   96%2C   94%2C   61%2C    0%2C   21%2C   13%2C   61%2C   96%2C   24%2C%0A          96%2C   96%2C  180%5D%29" isContainer="True" shape="(27,)" />
<var name="word_to_index" type="dict" qualifier="builtins" value="%7B%270%27%3A 6860%2C %2700%27%3A 7030%2C %27000%27%3A 7717%2C %27001%27%3A 38825%2C %27007%27%3A 28099%2C %2700am%27%3A 25993%2C %2701%27%3A 24762%2C %2702%27%3A 29846%2C %2703%27%3A 11089%2C %27039%27%3A 38140%2C %2704%27%3A 8057%2C %2705%27%3A 32280%2C %2706%27%3A 30353%2C %2707%27%3A 7063%2C %2708%27%3A 24586%2C %2709%27%3A 22275%2C %270f%27%3A 37971%2C %271%27%3A 793%2C %2710%27%3A 1684%2C %27100%27%3A 870%2C %271000%27%3A 10968%2C %2710000%27%3A 31123%2C %271000s%27%3A 20833%2C %271000x%27%3A 33996%2C %271001%27%3A 7910%2C %27100k%27%3A 39109%2C %27100s%27%3A 25367%2C %27100th%27%3A 879%2C %27101%27%3A 7005%2C %27101st%27%3A 26963%2C %27102%27%3A 29336%2C %27103%27%3A 31073%2C %27104%27%3A 31072%2C %27105%27%3A 27289%2C %27106%27%3A 11911%2C %271066%27%3A 34895%2C %27107%27%3A 733%2C %27108%27%3A 15245%2C %27109%27%3A 34772%2C %2710k%27%3A 16506%2C %2710th%27%3A 24530%2C %2710x%27%3A 22765%2C %2710yr%27%3A 28921%2C %2711%27%3A 3831%2C %27110%27%3A 18961%2C %271100%27%3A 36651%2C %27111%27%3A 18962%2C %27112%27%3A 11145%2C %27113%27%3A 32771%2C %27114%27%3A 24557%2C %27115%27%3A 15244%2C %27116%27%3A 19634%2C %27117%27%3A 39597%2C %27118%27%3A 21937%2C %27119%27%3A 38487%2C %2711pm%27%3A 25792%2C %2711th%27%3A 10687%2C %2712%27%3A 1681%2C %27120%27%3A 14299%2C %271200%27%3A 13958%2C %27121%27%3A 33184%2C %27122%27%3A 38431%2C %27123%27%3A 18402%2C %27124%27%3A 39041%2C %27125%27%3A 25024%2C %27126%27%3A 39242%2C %27127%27%3A 35211%2C %27128%27%3A 37280%2C %27129%27%3A 39683%2C %2712th%27%3A 10890%2C %2712yr%27%3A 17641%2C %2713%27%3A 3671%2C %27130%27..." isContainer="True" shape="40547" />
<var name="word_to_index_file" type="str" qualifier="builtins" value="./models/1st_model_word_to_index.pkl" />
</xml>
Text: We loved it! Lots of room for the kids to write do...
Predicted Label: 1.0, Actual Label: 1
Text: As a non-hunter I was surprised at how helpful the...
Predicted Label: 1.0, Actual Label: 1
Text: This book has so much potential, focusing on a par...
Predicted Label: 1.0, Actual Label: 0
Text: The entire book is Black and white, simply drawn p...
Predicted Label: 1.0, Actual Label: 0
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="RegexpTokenizer" type="ABCMeta" qualifier="abc" value="%3Cclass %27nltk.tokenize.regexp.RegexpTokenizer%27&gt;" isContainer="True" />
<var name="attention_weights" type="Tensor" qualifier="torch" value="tensor%28%5B%5B%5B0.0093%2C 0.0118%2C 0.0088%2C 0.0070%5D%2C%0A         %5B0.0046%2C 0.0879%2C 0.2792%2C 0.0863%5D%2C%0A         %5B0.0374%2C 0.0160%2C 0.0139%2C 0.0731...0%2C 0.0038%5D%2C%0A         %5B0.0739%2C 0.0764%2C 0.0853%2C 0.0072%5D%2C%0A         %5B0.0866%2C 0.1320%2C 0.1848%2C 0.0021%5D%5D%5D%2C grad_fn=%3CSoftmaxBackward0&gt;%29" isContainer="True" shape="(1, 27, 4)" />
<var name="attn" type="ndarray" qualifier="numpy" value="%5B%5B3.5819553e-02 2.4364064e-02 1.9539366e-02 1.2677922e-02%5D%2C %5B1.5266086e-02 7.1922265e-02 1.0675986e-01 3.3083409e-02%5D%2C %5B2.0394892e-02 1.4456239e-01 3.4921158e-02 1.4652270e-01%5D%2C %5B3.7456457e-02 1.1778422e-01 5.1247269e-02 5.4642227e-02%5D%2C %5B3.5819553e-02 2.4364064e-02 1.9539366e-02 1.2677922e-02%5D%2C %5B2.2597438e-02 1.4287570e-02 4.7377251e-02 8.3431574e-03%5D%2C %5B7.1271579e-03 7.1869351e-02 2.9095193e-02 2.5007838e-02%5D%2C %5B3.4644514e-02 1.1241193e-02 9.0697527e-02 4.0280189e-02%5D%2C %5B2.2057965e-01 1.0440748e-01 2.1700677e-01 4.2175192e-02%5D%2C %5B6.0251993e-03 1.3574837e-01 7.1157277e-02 1.5438016e-02%5D%2C %5B7.0102676e-03 1.8362099e-02 3.4320068e-02 1.0424480e-02%5D%2C %5B6.8500713e-02 1.0463662e-01 2.3869852e-02 5.9748497e-02%5D%2C %5B8.0521762e-02 1.3516122e-02 1.1643801e-02 6.4543546e-03%5D%2C %5B1.0201205e-02 8.1838176e-02 1.1488600e-01 4.0553757e-03%5D%2C %5B3.7880978e-01 2.5250493e-02 5.1077690e-02 5.1758045e-01%5D%2C %5B7.0102676e-03 1.8362099e-02 3.4320068e-02 1.0424480e-02%5D%2C %5B1.2215520e-02 1.7483395e-02 4.2541381e-02 4.6377600e-0..." isContainer="True" shape="(17, 4)" />
<var name="avg_loss" type="float" qualifier="builtins" value="0.5819856327176094" />
<var name="batch_size" type="int" qualifier="builtins" value="1" />
<var name="best_f1" type="float64" qualifier="numpy" value="0.8370573902224065" shape="()" />
<var name="dev_data_path" type="str" qualifier="builtins" value="sentiment.dev.csv" />
<var name="dev_dataset" type="TextDataset" qualifier="__main__" value="%3C__main__.TextDataset object at 0x00000232EF22FBC0&gt;" isContainer="True" shape="20000" />
<var name="dev_f1" type="float64" qualifier="numpy" value="0.8180815876515987" shape="()" />
<var name="dev_list" type="list" qualifier="builtins" value="%5B%28%5B  96   96  193    4 7609   62   71   27  234   64  329   11   96    1%2C  629  314 7041 1811 1900 1018  177   96  104    4  105  106 4116   11%2C  264   11    1 1693  992   13 6499%5D%2C array%280%29%29%2C %28%5B   96   288     7  1160    71     3  1056   223   281    83 16366  2101%2C   268   607   140     7  1283    24 10093  1475    96 19270    98   951%2C 11996  2253   727   398     7    70    96     7 16366   781  2101   268%2C     7  3551    58    77  6499%5D%2C array%280%29%29%2C %28%5B  96    1   18 1818   27    0   21   96   15   88 5047   61    0   36%2C   61   96   13  104  190 4549   98   40   83 1712   61   96 1601   96%2C   96  551  200   81 1903    7   21  307   96 1043   96  772  200  172%2C   11  671 2278   96   96 1594   47   33 3211   15 3408  268    7  117%2C   24   33 5050%5D%2C array%281%29%29%2C %28%5B  96  193    4   18 1288   13  742 3822  862   96 3545 4912   77  128%2C 1236  884   96  128 3472  200  719 1755%5D%2C array%280%29%29%2C %28%5B  96  124  310  288    0   21   96    1  310   64   33 4288    6   96%2C  408  409 1695  151   62   11 ..." isContainer="True" shape="20000" />
<var name="dev_loader" type="DataLoader" qualifier="torch.utils.data.dataloader" value="%3Ctorch.utils.data.dataloader.DataLoader object at 0x00000232EF4AFBF0&gt;" isContainer="True" shape="20000" />
<var name="device" type="device" qualifier="torch" value="device%28type=%27cpu%27%29" isContainer="True" />
<var name="embedding_size" type="int" qualifier="builtins" value="50" />
<var name="embeddings_file_path" type="str" qualifier="builtins" value="./models/1st_model_embeddings_state_dict.pt" />
<var name="epoch" type="int" qualifier="builtins" value="0" />
<var name="epochs" type="int" qualifier="builtins" value="1" />
<var name="f" type="BufferedReader" qualifier="_io" value="%3C_io.BufferedReader name=%27./models/1st_model_index_to_word.pkl%27&gt;" isContainer="True" />
<var name="f1_scores" type="list" qualifier="builtins" value="%5B0.0%2C 0.21893018717289098%2C 0.29446606870874936%2C 0.5971060666401168%2C 0.48496934781003026%2C 0.6473546826255809%2C 0.7046656760772659%2C 0.6990291262135923%2C 0.7337489897240503%2C 0.7150351734827709%2C 0.7465940054495913%2C 0.749829893399864%2C 0.7700985761226725%2C 0.7603120264885797%2C 0.7680974799224591%2C 0.7579650274460982%2C 0.7954971857410882%2C 0.756486117432863%2C 0.7812174675360254%2C 0.7879639133488197%2C 0.768396679279381%2C 0.7723326799215906%2C 0.7731073573152253%2C 0.7886400873839432%2C 0.7827916505176901%2C 0.8015255045288415%2C 0.7956896551724137%2C 0.8103950103950104%2C 0.8042047143767255%2C 0.7872622733303848%2C 0.8037681622225771%2C 0.7996125699526474%2C 0.7792792792792793%2C 0.7899401728340351%2C 0.8128498927431591%2C 0.8020052827340844%2C 0.783627698345949%2C 0.8064017071218992%2C 0.7953884161405435%2C 0.8190939180802648%2C 0.8084879505224994%2C 0.7983602077070238%2C 0.7869421580155663%2C 0.8042299349240781%2C 0.805939524838013%2C 0.8133961166075869%2C 0.805041653142919%2C 0.8099191259171978%2C 0.8102107577626427%2C 0.8021671318338532%2C 0.792075892857142..." isContainer="True" shape="163" />
<var name="i" type="int" qualifier="builtins" value="3" />
<var name="index_to_word" type="dict" qualifier="builtins" value="%7B0%3A %27this%27%2C 1%3A %27was%27%2C 2%3A %27bought%27%2C 3%3A %27as%27%2C 4%3A %27a%27%2C 5%3A %27gift%27%2C 6%3A %27but%27%2C 7%3A %27the%27%2C 8%3A %27person%27%2C 9%3A %27who%27%2C 10%3A %27got%27%2C 11%3A %27it%27%2C 12%3A %27loved%27%2C 13%3A %27and%27%2C 14%3A %27they%27%2C 15%3A %27will%27%2C 16%3A %27use%27%2C 17%3A %27soon%27%2C 18%3A %27very%27%2C 19%3A %27well%27%2C 20%3A %27written%27%2C 21%3A %27book%27%2C 22%3A %27on%27%2C 23%3A %27period%27%2C 24%3A %27of%27%2C 25%3A %27world%27%2C 26%3A %27history%27%2C 27%3A %27with%27%2C 28%3A %27which%27%2C 29%3A %27i%27%2C 30%3A %27am%27%2C 31%3A %27familiar%27%2C 32%3A %27despite%27%2C 33%3A %27my%27%2C 34%3A %27familiarity%27%2C 35%3A %27subject%27%2C 36%3A %27area%27%2C 37%3A %27learned%27%2C 38%3A %27lot%27%2C 39%3A %27new%27%2C 40%3A %27information%27%2C 41%3A %27also%27%2C 42%3A %27one%27%2C 43%3A %27best%27%2C 44%3A %27concise%27%2C 45%3A %27descriptions%27%2C 46%3A %27wwii%27%2C 47%3A %27that%27%2C 48%3A %27have%27%2C 49%3A %27ever%27%2C 50%3A %27read%27%2C 51%3A %27thought%27%2C 52%3A %27provoking%27%2C 53%3A %27hot%27%2C 54%3A %27cross%27%2C 55%3A %27buns%27%2C 56%3A %27contains%27%2C 57%3A %27cast%27%2C 58%3A %27characters%27%2C 59%3A %27you%27%2C 60%3A %27fall%27%2C 61%3A %27in%27%2C 62%3A %27love%27%2C 63%3A %27want%27%2C 64%3A %27to%27%2C 65%3A %27hang%27%2C 66%3A %27out%27%2C 67%3A %27has%27%2C 68%3A %27few%27%2C 69%3A %27different%27%2C 70%3A %27plot%27%2C 71%3A %27story%27%2C 72%3A %27lines%27%2C 73%3A %27intersect%27%2C 74%3A %27unexpected%27%2C 75%3A %27ways%27%2C 76%3A %27stories%27%2C 77%3A %27are%27%2C 78%3A %27full%27%2C 79%3A %27h..." isContainer="True" shape="40547" />
<var name="index_to_word_file" type="str" qualifier="builtins" value="./models/1st_model_index_to_word.pkl" />
<var name="label" type="float" qualifier="builtins" value="1.0" />
<var name="labels" type="list" qualifier="builtins" value="%5B1%2C 1%2C 0%2C 0%5D" isContainer="True" shape="4" />
<var name="learning_rate" type="float" qualifier="builtins" value="0.001" />
<var name="loss" type="Tensor" qualifier="torch" value="tensor%280.3133%2C grad_fn=%3CBinaryCrossEntropyWithLogitsBackward0&gt;%29" isContainer="True" shape="()" />
<var name="loss_function" type="BCEWithLogitsLoss" qualifier="torch.nn.modules.loss" value="BCEWithLogitsLoss%28%29" isContainer="True" />
<var name="losses" type="list" qualifier="builtins" value="%5B0.7063740156888961%2C 0.6690838242173195%2C 0.6710940192937851%2C 0.6416965731978417%2C 0.664360339820385%2C 0.6408256154060363%2C 0.6219880764484406%2C 0.6262354829907417%2C 0.6182727155685425%2C 0.6229372587800026%2C 0.6173186347484588%2C 0.6325475800037385%2C 0.5887129383683205%2C 0.6063905549049378%2C 0.5964332305192948%2C 0.6053036161065102%2C 0.576331036567688%2C 0.5984818696379661%2C 0.6024626339673996%2C 0.5853106815218926%2C 0.6045066975951194%2C 0.5990895519852638%2C 0.6025713908672333%2C 0.5945930997729302%2C 0.6004578600525856%2C 0.5832919328808784%2C 0.5881819829940796%2C 0.5846521648168563%2C 0.5884763289690018%2C 0.5964366135597229%2C 0.5868490883708%2C 0.5907454125285149%2C 0.6083347199559211%2C 0.5986561837792397%2C 0.5974684547781944%2C 0.5960528343319893%2C 0.5927959544062614%2C 0.5859969104528427%2C 0.6022085729837418%2C 0.5752854390740395%2C 0.5841937635540962%2C 0.5913211702108383%2C 0.6059050390124321%2C 0.5849579461812973%2C 0.5786286098361015%2C 0.5815764282941818%2C 0.5974919819831848%2C 0.5781187584400177%2C 0.5815025776624679%2C 0.5902935691475868%2C 0.58..." isContainer="True" shape="163" />
<var name="max_steps" type="int" qualifier="builtins" value="1000000000" />
<var name="model" type="DocumentAttentionClassifier" qualifier="__main__" value="DocumentAttentionClassifier%28%0A  %28embeddings%29%3A Embedding%2840547%2C 50%29%0A  %28linear%29%3A Linear%28in_features=200%2C out_features=1%2C bias=True%29%0A%29" isContainer="True" />
<var name="negative_samples" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B7291   This book has so much potential%2C focusing on a...      0%5D %5B15765  The entire book is Black and white%2C simply dra...      0%5D" isContainer="True" shape="(2, 2)" />
<var name="num_heads" type="int" qualifier="builtins" value="4" />
<var name="optimizer" type="AdamW" qualifier="torch.optim.adamw" value="AdamW %28%0AParameter Group 0%0A    amsgrad%3A False%0A    betas%3A %280.9%2C 0.999%29%0A    capturable%3A False%0A    differentiable%3A False%0A    eps%3A 1e-08%0A    foreach%3A None%0A    fused%3A None%0A    lr%3A 0.001%0A    maximize%3A False%0A    weight_decay%3A 0.01%0A%29" isContainer="True" />
<var name="patience" type="int" qualifier="builtins" value="30000" />
<var name="positive_samples" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B726   We loved it%21 Lots of room for the kids to writ...      1%5D %5B5711  As a non-hunter I was surprised at how helpful...      1%5D" isContainer="True" shape="(2, 2)" />
<var name="pre_label" type="float" qualifier="builtins" value="1.0" />
<var name="pred" type="float" qualifier="builtins" value="1.0" />
<var name="prediction" type="float" qualifier="builtins" value="1.0" />
<var name="predictions" type="list" qualifier="builtins" value="%5B0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C..." isContainer="True" shape="20000" />
<var name="probability" type="Tensor" qualifier="torch" value="tensor%28%5B0.6481%5D%29" isContainer="True" shape="(1,)" />
<var name="running_loss" type="float" qualifier="builtins" value="0.0" />
<var name="s" type="str" qualifier="builtins" value="%0AI%27m a big fan of his%2C and I have to say that this was a BIG letdown. It features%3A Stilted dialogue%2C no character development%2C no suspense%2C no description of Indian tradition and poor editing.%0A%0AAvoid at all costs.%0A" />
<var name="sample_text" type="str" qualifier="builtins" value="Although this product arrived on time and was nicely packaged%2C I found its quality lacking and performance subpar compared to other brands." />
<var name="selected_samples" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B726    We loved it%21 Lots of room for the kids to writ...      1%5D %5B5711   As a non-hunter I was surprised at how helpful...      1%5D %5B7291   This book has so much potential%2C focusing on a...      0%5D %5B15765  The entire book is Black and white%2C simply dra...      0%5D" isContainer="True" shape="(4, 2)" />
<var name="sent_dev_df" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B0      Picturing Perfect is a sappy love story with l...      0%5D %5B1      Seems like the same story as any other series ...      0%5D %5B2      I was very pleased with this book. I will be t...      1%5D %5B3      It is a very light and rather silly novel. The...      0%5D %5B4      I did not like this book. It was not to my tas...      0%5D %5B...                                                  ...    ...%5D %5B19995  Great content%2C the story is fantastic%2C but sho...      1%5D %5B19996  Typical book club book... Incest%2C child abuse%2C...      0%5D %5B19997  Fascinating book. Shorter than most Russell Ba...      1%5D %5B19998  This book is not well-organized%2C which is impo...      0%5D %5B19999  CAN WE CALL THIS A CLASSIC OF THE GENRE%3F I THI...      1%5D %5B%5D" isContainer="True" shape="(20000, 2)" />
<var name="sent_test_df" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27inst_id%27%2C %27text%27%2C %27predicted_label%27%5D %5B0            0  Really sad review as I absolutely loved the fi...   %5D %5B1            1  Excellent content%2C perfect for Christians who ...   %5D %5B2            2  This is an okay book if you need advice on bud...   %5D %5B3            3  This is one book you can%27t put down%21 This book...   %5D %5B4            4  There were to many names that I had no idenity...   %5D %5B...        ...                                                ...   %5D %5B19995    19995  I found this book to be a very entertaining an...   %5D %5B19996    19996  Wow%2C what a Middle School%21 Read this book your...   %5D %5B19997    19997  Not what I expected. Not enough about circular...   %5D %5B19998    19998  I like Joanne Fluke%27s mystery series starring ...   %5D %5B19999    19999  Grow some chickens%2C improve your land%2C make al...   %5D %5B%5D %5B0                  0.0  %5D %5B1                  1.0  %5D %5B2                  1.0  %5D %5B3                  1.0  %5D %5B4                  0.0  %5D %5B...                ...  %5D %5B19995         ..." isContainer="True" shape="(20000, 3)" />
<var name="sent_train_df" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B0       It was what I needed. There was no markings or...      1%5D %5B1       A cute little book. My wife gets the family wa...      1%5D %5B2       I bought these for 40.00 and for the price I j...      0%5D %5B3       It was interesting and enjoyable reading. Shor...      1%5D %5B4       A perfect ending to an amazing story. This was...      1%5D %5B...                                                   ...    ...%5D %5B159995  After reading every book Stephen King has to o...      1%5D %5B159996  Baby boomers who are experiencing %22aging eyeba...      0%5D %5B159997  Must read%2C must have%2C must read again. This bo...      1%5D %5B159998  Dr. Chopra%27s books are always enlightening and...      1%5D %5B159999  Boooring%21%21 Just enough to keep you intrigued f...      0%5D %5B%5D" isContainer="True" shape="(160000, 2)" />
<var name="step" type="int" qualifier="builtins" value="81499" />
<var name="steps_since_improvement" type="int" qualifier="builtins" value="30000" />
<var name="test_data" type="list" qualifier="builtins" value="%5Btensor%28%5B   96%2C   885%2C   626%2C     3%2C    96%2C  1132%2C    12%2C     7%2C   285%2C    21%2C%0A           96%2C    21%2C     1%2C  4050%2C     4%2C  6499...8504%2C  7595%2C     7%2C%0A         2087%2C   762%2C     7%2C   727%2C    42%2C   335%2C   385%2C   514%2C    98%2C   629%2C%0A          102%2C    13%2C   450%5D%29%2C tensor%28%5B  96%2C 1669%2C 1427%2C   98%2C   96%2C    9%2C   77%2C  207%2C 2651%2C  314%2C  804%2C   24%2C%0A           7%2C   96%2C   13%2C   86%2C 1887%2C   61%2C    7%2C  693%5D%29%2C tensor%28%5B   96%2C   193%2C   314%2C  4921%2C    21%2C   335%2C    59%2C   661%2C   633%2C    22%2C%0A         8229%2C    13%2C  3966%2C    96%2C   360%2C   345...  719%2C    96%2C   309%2C   497%2C    94%2C   719%2C  1105%2C%0A           59%2C    80%2C    32%2C     7%2C   269%2C   154%2C 20119%2C    64%2C     7%2C  2881%5D%29%2C tensor%28%5B  96%2C  193%2C   42%2C   21%2C   59%2C   92%2C  200%2C  506%2C  108%2C   96%2C   21%2C   15%2C%0A          80%2C   59%2C  218%2C   13%2C 8965%2C   59%2C   ...7%2C    4%2C  768%2C   13%2C%0A        3576%2C  677%2C   86%2C  678%2C   64%2C  287%2C  193%2C  537%2C  265%2C   96%2C  151%2C  329%2C%0A           0%2C  679%2C   21%5D%29%2C tensor%28%5B  96%2C  336%2C   64%2C  141%2C  352%2C   47%2C   96%2C  104%2C  204%2C   96%2C   27%2C   61%2C%0A       ..." isContainer="True" shape="20000" />
<var name="test_data_path" type="str" qualifier="builtins" value="sentiment.test.csv" />
<var name="test_list" type="list" qualifier="builtins" value="%5Btensor%28%5B   96%2C   885%2C   626%2C     3%2C    96%2C  1132%2C    12%2C     7%2C   285%2C    21%2C%0A           96%2C    21%2C     1%2C  4050%2C     4%2C  6499...8504%2C  7595%2C     7%2C%0A         2087%2C   762%2C     7%2C   727%2C    42%2C   335%2C   385%2C   514%2C    98%2C   629%2C%0A          102%2C    13%2C   450%5D%29%2C tensor%28%5B  96%2C 1669%2C 1427%2C   98%2C   96%2C    9%2C   77%2C  207%2C 2651%2C  314%2C  804%2C   24%2C%0A           7%2C   96%2C   13%2C   86%2C 1887%2C   61%2C    7%2C  693%5D%29%2C tensor%28%5B   96%2C   193%2C   314%2C  4921%2C    21%2C   335%2C    59%2C   661%2C   633%2C    22%2C%0A         8229%2C    13%2C  3966%2C    96%2C   360%2C   345...  719%2C    96%2C   309%2C   497%2C    94%2C   719%2C  1105%2C%0A           59%2C    80%2C    32%2C     7%2C   269%2C   154%2C 20119%2C    64%2C     7%2C  2881%5D%29%2C tensor%28%5B  96%2C  193%2C   42%2C   21%2C   59%2C   92%2C  200%2C  506%2C  108%2C   96%2C   21%2C   15%2C%0A          80%2C   59%2C  218%2C   13%2C 8965%2C   59%2C   ...7%2C    4%2C  768%2C   13%2C%0A        3576%2C  677%2C   86%2C  678%2C   64%2C  287%2C  193%2C  537%2C  265%2C   96%2C  151%2C  329%2C%0A           0%2C  679%2C   21%5D%29%2C tensor%28%5B  96%2C  336%2C   64%2C  141%2C  352%2C   47%2C   96%2C  104%2C  204%2C   96%2C   27%2C   61%2C%0A       ..." isContainer="True" shape="20000" />
<var name="test_output" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27inst_id%27%2C %27predicted_label%27%5D %5B0            0              0.0%5D %5B1            1              1.0%5D %5B2            2              1.0%5D %5B3            3              1.0%5D %5B4            4              0.0%5D %5B...        ...              ...%5D %5B19995    19995              1.0%5D %5B19996    19996              1.0%5D %5B19997    19997              0.0%5D %5B19998    19998              1.0%5D %5B19999    19999              1.0%5D %5B%5D" isContainer="True" shape="(20000, 2)" />
<var name="text" type="str" qualifier="builtins" value="When I first heard about this book I literally thought it was a baby book%2C but it was really good book. And any age could read this book." />
<var name="texts" type="list" qualifier="builtins" value="%5B%27We loved it%21 Lots of room for the kids to write down thier favorite things. We will keep this forever.%27%2C %27As a non-hunter I was surprised at how helpful the hunting analogies were to my decision making processes. I highly recommend this book to all aspiring entrepreneurs and ambitious sales people.%27%2C %27This book has so much potential%2C focusing on a part of American history which many people know so little about. The problem i... and sacrifices the narrative to this purpose. The final chapters are the only part of the story that truly engage the reader.%27%2C %27The entire book is Black and white%2C simply drawn pictures of just a large pile of objects.%27%5D" isContainer="True" shape="4" />
<var name="tokenizer" type="RegexpTokenizer" qualifier="nltk.tokenize.regexp" value="RegexpTokenizer%28pattern=%27%5C%5Cw%2B%27%2C gaps=False%2C discard_empty=True%2C flags=re.UNICODE%7Cre.MULTILINE%7Cre.DOTALL%29" isContainer="True" />
<var name="tokens" type="list" qualifier="builtins" value="%5B%27%3CUNK&gt;%27%2C %27entire%27%2C %27book%27%2C %27is%27%2C %27%3CUNK&gt;%27%2C %27and%27%2C %27white%27%2C %27simply%27%2C %27drawn%27%2C %27pictures%27%2C %27of%27%2C %27just%27%2C %27a%27%2C %27large%27%2C %27pile%27%2C %27of%27%2C %27objects%27%5D" isContainer="True" shape="17" />
<var name="train_data_path" type="str" qualifier="builtins" value="sentiment.train.csv" />
<var name="train_dataset" type="TextDataset" qualifier="__main__" value="%3C__main__.TextDataset object at 0x00000232F2734410&gt;" isContainer="True" shape="160000" />
<var name="train_list" type="list" qualifier="builtins" value="%5B%28%5B   96     1   287    96   248    96     1   204 16850   291   110    24%2C    47    96   193   306    64    50    13    93%5D%2C array%281%29%29%2C %28%5B  96  884  234   21   96 1191 2472    7  693 1931 1926  268   96   96%2C   85 1688   96   21   67    7 1160  884 1578%5D%2C array%281%29%29%2C %28%5B  96    2  320   98 3569 7030   13   98    7  366   96  128 5745   14%2C  151   88  105 9655   96   88   96  123   59 1956  320   59  175   11%2C   15  128   88   96  140  105 9655 5834%5D%2C array%280%29%29%2C %28%5B  96    1  358   13  333  341   96   76 1775   83   96  241 1635 3070%2C   24   96   13 1196  729   61  305   95   96   76 1426   48    4  699%2C  117   96  115    4  486   24   96   96  356   76   96   62%5D%2C array%281%29%29%2C %28%5B  96 1427 1233   64  314  679   71   96    1  314 1131 1554 1555   98%2C  265 1905   96    1 7419   98 3204   87  310 1588  335   14  151  539%2C  232  287   14 1905  249    0    1    4  615  710   96   12   11%5D%2C array%281%29%29%2C %28%5B   96    64    88   314  1774  3195    24   345    24    96    26    96%2C    13  1178   341    ..." isContainer="True" shape="160000" />
<var name="train_loader" type="DataLoader" qualifier="torch.utils.data.dataloader" value="%3Ctorch.utils.data.dataloader.DataLoader object at 0x00000232F2735D00&gt;" isContainer="True" shape="160000" />
<var name="vocab_size" type="int" qualifier="builtins" value="40547" />
<var name="word_ids" type="Tensor" qualifier="torch" value="tensor%28%5B  96%2C  345%2C 8879%2C 1977%2C  385%2C 1364%2C   80%2C 4134%2C   24%2C 1105%2C  680%2C   19%2C%0A          13%2C   96%2C   96%2C   96%2C   94%2C   61%2C    0%2C   21%2C   13%2C   61%2C   96%2C   24%2C%0A          96%2C   96%2C  180%5D%29" isContainer="True" shape="(27,)" />
<var name="word_to_index" type="dict" qualifier="builtins" value="%7B%270%27%3A 6860%2C %2700%27%3A 7030%2C %27000%27%3A 7717%2C %27001%27%3A 38825%2C %27007%27%3A 28099%2C %2700am%27%3A 25993%2C %2701%27%3A 24762%2C %2702%27%3A 29846%2C %2703%27%3A 11089%2C %27039%27%3A 38140%2C %2704%27%3A 8057%2C %2705%27%3A 32280%2C %2706%27%3A 30353%2C %2707%27%3A 7063%2C %2708%27%3A 24586%2C %2709%27%3A 22275%2C %270f%27%3A 37971%2C %271%27%3A 793%2C %2710%27%3A 1684%2C %27100%27%3A 870%2C %271000%27%3A 10968%2C %2710000%27%3A 31123%2C %271000s%27%3A 20833%2C %271000x%27%3A 33996%2C %271001%27%3A 7910%2C %27100k%27%3A 39109%2C %27100s%27%3A 25367%2C %27100th%27%3A 879%2C %27101%27%3A 7005%2C %27101st%27%3A 26963%2C %27102%27%3A 29336%2C %27103%27%3A 31073%2C %27104%27%3A 31072%2C %27105%27%3A 27289%2C %27106%27%3A 11911%2C %271066%27%3A 34895%2C %27107%27%3A 733%2C %27108%27%3A 15245%2C %27109%27%3A 34772%2C %2710k%27%3A 16506%2C %2710th%27%3A 24530%2C %2710x%27%3A 22765%2C %2710yr%27%3A 28921%2C %2711%27%3A 3831%2C %27110%27%3A 18961%2C %271100%27%3A 36651%2C %27111%27%3A 18962%2C %27112%27%3A 11145%2C %27113%27%3A 32771%2C %27114%27%3A 24557%2C %27115%27%3A 15244%2C %27116%27%3A 19634%2C %27117%27%3A 39597%2C %27118%27%3A 21937%2C %27119%27%3A 38487%2C %2711pm%27%3A 25792%2C %2711th%27%3A 10687%2C %2712%27%3A 1681%2C %27120%27%3A 14299%2C %271200%27%3A 13958%2C %27121%27%3A 33184%2C %27122%27%3A 38431%2C %27123%27%3A 18402%2C %27124%27%3A 39041%2C %27125%27%3A 25024%2C %27126%27%3A 39242%2C %27127%27%3A 35211%2C %27128%27%3A 37280%2C %27129%27%3A 39683%2C %2712th%27%3A 10890%2C %2712yr%27%3A 17641%2C %2713%27%3A 3671%2C %27130%27..." isContainer="True" shape="40547" />
<var name="word_to_index_file" type="str" qualifier="builtins" value="./models/1st_model_word_to_index.pkl" />
</xml>
Text: We loved it! Lots of room for the kids to write do...
Predicted Label: 1.0, Actual Label: 1
Text: As a non-hunter I was surprised at how helpful the...
Predicted Label: 1.0, Actual Label: 1
Text: Unbelievable that this was by Grisham. No real poi...
Predicted Label: 1.0, Actual Label: 0
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="RegexpTokenizer" type="ABCMeta" qualifier="abc" value="%3Cclass %27nltk.tokenize.regexp.RegexpTokenizer%27&gt;" isContainer="True" />
<var name="attention_weights" type="Tensor" qualifier="torch" value="tensor%28%5B%5B%5B0.0093%2C 0.0118%2C 0.0088%2C 0.0070%5D%2C%0A         %5B0.0046%2C 0.0879%2C 0.2792%2C 0.0863%5D%2C%0A         %5B0.0374%2C 0.0160%2C 0.0139%2C 0.0731...0%2C 0.0038%5D%2C%0A         %5B0.0739%2C 0.0764%2C 0.0853%2C 0.0072%5D%2C%0A         %5B0.0866%2C 0.1320%2C 0.1848%2C 0.0021%5D%5D%5D%2C grad_fn=%3CSoftmaxBackward0&gt;%29" isContainer="True" shape="(1, 27, 4)" />
<var name="attn" type="ndarray" qualifier="numpy" value="%5B%5B0.02079496 0.02612611 0.03224228 0.0114032 %5D%2C %5B0.01881037 0.02531989 0.04551664 0.00992196%5D%2C %5B0.01319279 0.10220847 0.05698064 0.1713977 %5D%2C %5B0.04351678 0.39807808 0.03069839 0.06400806%5D%2C %5B0.01382104 0.09124731 0.06101472 0.06236452%5D%2C %5B0.02079496 0.02612611 0.03224228 0.0114032 %5D%2C %5B0.02079496 0.02612611 0.03224228 0.0114032 %5D%2C %5B0.03595903 0.00937988 0.25692594 0.00399479%5D%2C %5B0.05844329 0.01805348 0.01877286 0.01615982%5D%2C %5B0.02079496 0.02612611 0.03224228 0.0114032 %5D%2C %5B0.00980551 0.08930284 0.00651963 0.0104781 %5D%2C %5B0.0053545  0.05325855 0.02467107 0.02799313%5D%2C %5B0.65615165 0.02459464 0.12582761 0.01226507%5D%2C %5B0.02079496 0.02612611 0.03224228 0.0114032 %5D%2C %5B0.02017532 0.03179996 0.17961878 0.55299765%5D%2C %5B0.02079496 0.02612611 0.03224228 0.0114032 %5D%5D" isContainer="True" shape="(16, 4)" />
<var name="avg_loss" type="float" qualifier="builtins" value="0.5819856327176094" />
<var name="batch_size" type="int" qualifier="builtins" value="1" />
<var name="best_f1" type="float64" qualifier="numpy" value="0.8370573902224065" shape="()" />
<var name="dev_data_path" type="str" qualifier="builtins" value="sentiment.dev.csv" />
<var name="dev_dataset" type="TextDataset" qualifier="__main__" value="%3C__main__.TextDataset object at 0x00000232EF22FBC0&gt;" isContainer="True" shape="20000" />
<var name="dev_f1" type="float64" qualifier="numpy" value="0.8180815876515987" shape="()" />
<var name="dev_list" type="list" qualifier="builtins" value="%5B%28%5B  96   96  193    4 7609   62   71   27  234   64  329   11   96    1%2C  629  314 7041 1811 1900 1018  177   96  104    4  105  106 4116   11%2C  264   11    1 1693  992   13 6499%5D%2C array%280%29%29%2C %28%5B   96   288     7  1160    71     3  1056   223   281    83 16366  2101%2C   268   607   140     7  1283    24 10093  1475    96 19270    98   951%2C 11996  2253   727   398     7    70    96     7 16366   781  2101   268%2C     7  3551    58    77  6499%5D%2C array%280%29%29%2C %28%5B  96    1   18 1818   27    0   21   96   15   88 5047   61    0   36%2C   61   96   13  104  190 4549   98   40   83 1712   61   96 1601   96%2C   96  551  200   81 1903    7   21  307   96 1043   96  772  200  172%2C   11  671 2278   96   96 1594   47   33 3211   15 3408  268    7  117%2C   24   33 5050%5D%2C array%281%29%29%2C %28%5B  96  193    4   18 1288   13  742 3822  862   96 3545 4912   77  128%2C 1236  884   96  128 3472  200  719 1755%5D%2C array%280%29%29%2C %28%5B  96  124  310  288    0   21   96    1  310   64   33 4288    6   96%2C  408  409 1695  151   62   11 ..." isContainer="True" shape="20000" />
<var name="dev_loader" type="DataLoader" qualifier="torch.utils.data.dataloader" value="%3Ctorch.utils.data.dataloader.DataLoader object at 0x00000232EF4AFBF0&gt;" isContainer="True" shape="20000" />
<var name="device" type="device" qualifier="torch" value="device%28type=%27cpu%27%29" isContainer="True" />
<var name="embedding_size" type="int" qualifier="builtins" value="50" />
<var name="embeddings_file_path" type="str" qualifier="builtins" value="./models/1st_model_embeddings_state_dict.pt" />
<var name="epoch" type="int" qualifier="builtins" value="0" />
<var name="epochs" type="int" qualifier="builtins" value="1" />
<var name="f" type="BufferedReader" qualifier="_io" value="%3C_io.BufferedReader name=%27./models/1st_model_index_to_word.pkl%27&gt;" isContainer="True" />
<var name="f1_scores" type="list" qualifier="builtins" value="%5B0.0%2C 0.21893018717289098%2C 0.29446606870874936%2C 0.5971060666401168%2C 0.48496934781003026%2C 0.6473546826255809%2C 0.7046656760772659%2C 0.6990291262135923%2C 0.7337489897240503%2C 0.7150351734827709%2C 0.7465940054495913%2C 0.749829893399864%2C 0.7700985761226725%2C 0.7603120264885797%2C 0.7680974799224591%2C 0.7579650274460982%2C 0.7954971857410882%2C 0.756486117432863%2C 0.7812174675360254%2C 0.7879639133488197%2C 0.768396679279381%2C 0.7723326799215906%2C 0.7731073573152253%2C 0.7886400873839432%2C 0.7827916505176901%2C 0.8015255045288415%2C 0.7956896551724137%2C 0.8103950103950104%2C 0.8042047143767255%2C 0.7872622733303848%2C 0.8037681622225771%2C 0.7996125699526474%2C 0.7792792792792793%2C 0.7899401728340351%2C 0.8128498927431591%2C 0.8020052827340844%2C 0.783627698345949%2C 0.8064017071218992%2C 0.7953884161405435%2C 0.8190939180802648%2C 0.8084879505224994%2C 0.7983602077070238%2C 0.7869421580155663%2C 0.8042299349240781%2C 0.805939524838013%2C 0.8133961166075869%2C 0.805041653142919%2C 0.8099191259171978%2C 0.8102107577626427%2C 0.8021671318338532%2C 0.792075892857142..." isContainer="True" shape="163" />
<var name="i" type="int" qualifier="builtins" value="2" />
<var name="index_to_word" type="dict" qualifier="builtins" value="%7B0%3A %27this%27%2C 1%3A %27was%27%2C 2%3A %27bought%27%2C 3%3A %27as%27%2C 4%3A %27a%27%2C 5%3A %27gift%27%2C 6%3A %27but%27%2C 7%3A %27the%27%2C 8%3A %27person%27%2C 9%3A %27who%27%2C 10%3A %27got%27%2C 11%3A %27it%27%2C 12%3A %27loved%27%2C 13%3A %27and%27%2C 14%3A %27they%27%2C 15%3A %27will%27%2C 16%3A %27use%27%2C 17%3A %27soon%27%2C 18%3A %27very%27%2C 19%3A %27well%27%2C 20%3A %27written%27%2C 21%3A %27book%27%2C 22%3A %27on%27%2C 23%3A %27period%27%2C 24%3A %27of%27%2C 25%3A %27world%27%2C 26%3A %27history%27%2C 27%3A %27with%27%2C 28%3A %27which%27%2C 29%3A %27i%27%2C 30%3A %27am%27%2C 31%3A %27familiar%27%2C 32%3A %27despite%27%2C 33%3A %27my%27%2C 34%3A %27familiarity%27%2C 35%3A %27subject%27%2C 36%3A %27area%27%2C 37%3A %27learned%27%2C 38%3A %27lot%27%2C 39%3A %27new%27%2C 40%3A %27information%27%2C 41%3A %27also%27%2C 42%3A %27one%27%2C 43%3A %27best%27%2C 44%3A %27concise%27%2C 45%3A %27descriptions%27%2C 46%3A %27wwii%27%2C 47%3A %27that%27%2C 48%3A %27have%27%2C 49%3A %27ever%27%2C 50%3A %27read%27%2C 51%3A %27thought%27%2C 52%3A %27provoking%27%2C 53%3A %27hot%27%2C 54%3A %27cross%27%2C 55%3A %27buns%27%2C 56%3A %27contains%27%2C 57%3A %27cast%27%2C 58%3A %27characters%27%2C 59%3A %27you%27%2C 60%3A %27fall%27%2C 61%3A %27in%27%2C 62%3A %27love%27%2C 63%3A %27want%27%2C 64%3A %27to%27%2C 65%3A %27hang%27%2C 66%3A %27out%27%2C 67%3A %27has%27%2C 68%3A %27few%27%2C 69%3A %27different%27%2C 70%3A %27plot%27%2C 71%3A %27story%27%2C 72%3A %27lines%27%2C 73%3A %27intersect%27%2C 74%3A %27unexpected%27%2C 75%3A %27ways%27%2C 76%3A %27stories%27%2C 77%3A %27are%27%2C 78%3A %27full%27%2C 79%3A %27h..." isContainer="True" shape="40547" />
<var name="index_to_word_file" type="str" qualifier="builtins" value="./models/1st_model_index_to_word.pkl" />
<var name="label" type="float" qualifier="builtins" value="1.0" />
<var name="labels" type="list" qualifier="builtins" value="%5B1%2C 1%2C 0%5D" isContainer="True" shape="3" />
<var name="learning_rate" type="float" qualifier="builtins" value="0.001" />
<var name="loss" type="Tensor" qualifier="torch" value="tensor%280.3133%2C grad_fn=%3CBinaryCrossEntropyWithLogitsBackward0&gt;%29" isContainer="True" shape="()" />
<var name="loss_function" type="BCEWithLogitsLoss" qualifier="torch.nn.modules.loss" value="BCEWithLogitsLoss%28%29" isContainer="True" />
<var name="losses" type="list" qualifier="builtins" value="%5B0.7063740156888961%2C 0.6690838242173195%2C 0.6710940192937851%2C 0.6416965731978417%2C 0.664360339820385%2C 0.6408256154060363%2C 0.6219880764484406%2C 0.6262354829907417%2C 0.6182727155685425%2C 0.6229372587800026%2C 0.6173186347484588%2C 0.6325475800037385%2C 0.5887129383683205%2C 0.6063905549049378%2C 0.5964332305192948%2C 0.6053036161065102%2C 0.576331036567688%2C 0.5984818696379661%2C 0.6024626339673996%2C 0.5853106815218926%2C 0.6045066975951194%2C 0.5990895519852638%2C 0.6025713908672333%2C 0.5945930997729302%2C 0.6004578600525856%2C 0.5832919328808784%2C 0.5881819829940796%2C 0.5846521648168563%2C 0.5884763289690018%2C 0.5964366135597229%2C 0.5868490883708%2C 0.5907454125285149%2C 0.6083347199559211%2C 0.5986561837792397%2C 0.5974684547781944%2C 0.5960528343319893%2C 0.5927959544062614%2C 0.5859969104528427%2C 0.6022085729837418%2C 0.5752854390740395%2C 0.5841937635540962%2C 0.5913211702108383%2C 0.6059050390124321%2C 0.5849579461812973%2C 0.5786286098361015%2C 0.5815764282941818%2C 0.5974919819831848%2C 0.5781187584400177%2C 0.5815025776624679%2C 0.5902935691475868%2C 0.58..." isContainer="True" shape="163" />
<var name="max_steps" type="int" qualifier="builtins" value="1000000000" />
<var name="model" type="DocumentAttentionClassifier" qualifier="__main__" value="DocumentAttentionClassifier%28%0A  %28embeddings%29%3A Embedding%2840547%2C 50%29%0A  %28linear%29%3A Linear%28in_features=200%2C out_features=1%2C bias=True%29%0A%29" isContainer="True" />
<var name="negative_samples" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B4205  Unbelievable that this was by Grisham. No real...      0%5D" isContainer="True" shape="(1, 2)" />
<var name="num_heads" type="int" qualifier="builtins" value="4" />
<var name="optimizer" type="AdamW" qualifier="torch.optim.adamw" value="AdamW %28%0AParameter Group 0%0A    amsgrad%3A False%0A    betas%3A %280.9%2C 0.999%29%0A    capturable%3A False%0A    differentiable%3A False%0A    eps%3A 1e-08%0A    foreach%3A None%0A    fused%3A None%0A    lr%3A 0.001%0A    maximize%3A False%0A    weight_decay%3A 0.01%0A%29" isContainer="True" />
<var name="patience" type="int" qualifier="builtins" value="30000" />
<var name="positive_samples" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B726   We loved it%21 Lots of room for the kids to writ...      1%5D %5B5711  As a non-hunter I was surprised at how helpful...      1%5D" isContainer="True" shape="(2, 2)" />
<var name="pre_label" type="float" qualifier="builtins" value="1.0" />
<var name="pred" type="float" qualifier="builtins" value="1.0" />
<var name="prediction" type="float" qualifier="builtins" value="1.0" />
<var name="predictions" type="list" qualifier="builtins" value="%5B0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C..." isContainer="True" shape="20000" />
<var name="probability" type="Tensor" qualifier="torch" value="tensor%28%5B0.6481%5D%29" isContainer="True" shape="(1,)" />
<var name="running_loss" type="float" qualifier="builtins" value="0.0" />
<var name="s" type="str" qualifier="builtins" value="%0AI%27m a big fan of his%2C and I have to say that this was a BIG letdown. It features%3A Stilted dialogue%2C no character development%2C no suspense%2C no description of Indian tradition and poor editing.%0A%0AAvoid at all costs.%0A" />
<var name="sample_text" type="str" qualifier="builtins" value="Although this product arrived on time and was nicely packaged%2C I found its quality lacking and performance subpar compared to other brands." />
<var name="selected_samples" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B726   We loved it%21 Lots of room for the kids to writ...      1%5D %5B5711  As a non-hunter I was surprised at how helpful...      1%5D %5B4205  Unbelievable that this was by Grisham. No real...      0%5D" isContainer="True" shape="(3, 2)" />
<var name="sent_dev_df" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B0      Picturing Perfect is a sappy love story with l...      0%5D %5B1      Seems like the same story as any other series ...      0%5D %5B2      I was very pleased with this book. I will be t...      1%5D %5B3      It is a very light and rather silly novel. The...      0%5D %5B4      I did not like this book. It was not to my tas...      0%5D %5B...                                                  ...    ...%5D %5B19995  Great content%2C the story is fantastic%2C but sho...      1%5D %5B19996  Typical book club book... Incest%2C child abuse%2C...      0%5D %5B19997  Fascinating book. Shorter than most Russell Ba...      1%5D %5B19998  This book is not well-organized%2C which is impo...      0%5D %5B19999  CAN WE CALL THIS A CLASSIC OF THE GENRE%3F I THI...      1%5D %5B%5D" isContainer="True" shape="(20000, 2)" />
<var name="sent_test_df" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27inst_id%27%2C %27text%27%2C %27predicted_label%27%5D %5B0            0  Really sad review as I absolutely loved the fi...   %5D %5B1            1  Excellent content%2C perfect for Christians who ...   %5D %5B2            2  This is an okay book if you need advice on bud...   %5D %5B3            3  This is one book you can%27t put down%21 This book...   %5D %5B4            4  There were to many names that I had no idenity...   %5D %5B...        ...                                                ...   %5D %5B19995    19995  I found this book to be a very entertaining an...   %5D %5B19996    19996  Wow%2C what a Middle School%21 Read this book your...   %5D %5B19997    19997  Not what I expected. Not enough about circular...   %5D %5B19998    19998  I like Joanne Fluke%27s mystery series starring ...   %5D %5B19999    19999  Grow some chickens%2C improve your land%2C make al...   %5D %5B%5D %5B0                  0.0  %5D %5B1                  1.0  %5D %5B2                  1.0  %5D %5B3                  1.0  %5D %5B4                  0.0  %5D %5B...                ...  %5D %5B19995         ..." isContainer="True" shape="(20000, 3)" />
<var name="sent_train_df" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B0       It was what I needed. There was no markings or...      1%5D %5B1       A cute little book. My wife gets the family wa...      1%5D %5B2       I bought these for 40.00 and for the price I j...      0%5D %5B3       It was interesting and enjoyable reading. Shor...      1%5D %5B4       A perfect ending to an amazing story. This was...      1%5D %5B...                                                   ...    ...%5D %5B159995  After reading every book Stephen King has to o...      1%5D %5B159996  Baby boomers who are experiencing %22aging eyeba...      0%5D %5B159997  Must read%2C must have%2C must read again. This bo...      1%5D %5B159998  Dr. Chopra%27s books are always enlightening and...      1%5D %5B159999  Boooring%21%21 Just enough to keep you intrigued f...      0%5D %5B%5D" isContainer="True" shape="(160000, 2)" />
<var name="step" type="int" qualifier="builtins" value="81499" />
<var name="steps_since_improvement" type="int" qualifier="builtins" value="30000" />
<var name="test_data" type="list" qualifier="builtins" value="%5Btensor%28%5B   96%2C   885%2C   626%2C     3%2C    96%2C  1132%2C    12%2C     7%2C   285%2C    21%2C%0A           96%2C    21%2C     1%2C  4050%2C     4%2C  6499...8504%2C  7595%2C     7%2C%0A         2087%2C   762%2C     7%2C   727%2C    42%2C   335%2C   385%2C   514%2C    98%2C   629%2C%0A          102%2C    13%2C   450%5D%29%2C tensor%28%5B  96%2C 1669%2C 1427%2C   98%2C   96%2C    9%2C   77%2C  207%2C 2651%2C  314%2C  804%2C   24%2C%0A           7%2C   96%2C   13%2C   86%2C 1887%2C   61%2C    7%2C  693%5D%29%2C tensor%28%5B   96%2C   193%2C   314%2C  4921%2C    21%2C   335%2C    59%2C   661%2C   633%2C    22%2C%0A         8229%2C    13%2C  3966%2C    96%2C   360%2C   345...  719%2C    96%2C   309%2C   497%2C    94%2C   719%2C  1105%2C%0A           59%2C    80%2C    32%2C     7%2C   269%2C   154%2C 20119%2C    64%2C     7%2C  2881%5D%29%2C tensor%28%5B  96%2C  193%2C   42%2C   21%2C   59%2C   92%2C  200%2C  506%2C  108%2C   96%2C   21%2C   15%2C%0A          80%2C   59%2C  218%2C   13%2C 8965%2C   59%2C   ...7%2C    4%2C  768%2C   13%2C%0A        3576%2C  677%2C   86%2C  678%2C   64%2C  287%2C  193%2C  537%2C  265%2C   96%2C  151%2C  329%2C%0A           0%2C  679%2C   21%5D%29%2C tensor%28%5B  96%2C  336%2C   64%2C  141%2C  352%2C   47%2C   96%2C  104%2C  204%2C   96%2C   27%2C   61%2C%0A       ..." isContainer="True" shape="20000" />
<var name="test_data_path" type="str" qualifier="builtins" value="sentiment.test.csv" />
<var name="test_list" type="list" qualifier="builtins" value="%5Btensor%28%5B   96%2C   885%2C   626%2C     3%2C    96%2C  1132%2C    12%2C     7%2C   285%2C    21%2C%0A           96%2C    21%2C     1%2C  4050%2C     4%2C  6499...8504%2C  7595%2C     7%2C%0A         2087%2C   762%2C     7%2C   727%2C    42%2C   335%2C   385%2C   514%2C    98%2C   629%2C%0A          102%2C    13%2C   450%5D%29%2C tensor%28%5B  96%2C 1669%2C 1427%2C   98%2C   96%2C    9%2C   77%2C  207%2C 2651%2C  314%2C  804%2C   24%2C%0A           7%2C   96%2C   13%2C   86%2C 1887%2C   61%2C    7%2C  693%5D%29%2C tensor%28%5B   96%2C   193%2C   314%2C  4921%2C    21%2C   335%2C    59%2C   661%2C   633%2C    22%2C%0A         8229%2C    13%2C  3966%2C    96%2C   360%2C   345...  719%2C    96%2C   309%2C   497%2C    94%2C   719%2C  1105%2C%0A           59%2C    80%2C    32%2C     7%2C   269%2C   154%2C 20119%2C    64%2C     7%2C  2881%5D%29%2C tensor%28%5B  96%2C  193%2C   42%2C   21%2C   59%2C   92%2C  200%2C  506%2C  108%2C   96%2C   21%2C   15%2C%0A          80%2C   59%2C  218%2C   13%2C 8965%2C   59%2C   ...7%2C    4%2C  768%2C   13%2C%0A        3576%2C  677%2C   86%2C  678%2C   64%2C  287%2C  193%2C  537%2C  265%2C   96%2C  151%2C  329%2C%0A           0%2C  679%2C   21%5D%29%2C tensor%28%5B  96%2C  336%2C   64%2C  141%2C  352%2C   47%2C   96%2C  104%2C  204%2C   96%2C   27%2C   61%2C%0A       ..." isContainer="True" shape="20000" />
<var name="test_output" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27inst_id%27%2C %27predicted_label%27%5D %5B0            0              0.0%5D %5B1            1              1.0%5D %5B2            2              1.0%5D %5B3            3              1.0%5D %5B4            4              0.0%5D %5B...        ...              ...%5D %5B19995    19995              1.0%5D %5B19996    19996              1.0%5D %5B19997    19997              0.0%5D %5B19998    19998              1.0%5D %5B19999    19999              1.0%5D %5B%5D" isContainer="True" shape="(20000, 2)" />
<var name="text" type="str" qualifier="builtins" value="When I first heard about this book I literally thought it was a baby book%2C but it was really good book. And any age could read this book." />
<var name="texts" type="list" qualifier="builtins" value="%5B%27We loved it%21 Lots of room for the kids to write down thier favorite things. We will keep this forever.%27%2C %27As a non-hunter I was surprised at how helpful the hunting analogies were to my decision making processes. I highly recommend this book to all aspiring entrepreneurs and ambitious sales people.%27%2C %27Unbelievable that this was by Grisham. No real point. Boring on the extreme. Try again John.%27%5D" isContainer="True" shape="3" />
<var name="tokenizer" type="RegexpTokenizer" qualifier="nltk.tokenize.regexp" value="RegexpTokenizer%28pattern=%27%5C%5Cw%2B%27%2C gaps=False%2C discard_empty=True%2C flags=re.UNICODE%7Cre.MULTILINE%7Cre.DOTALL%29" isContainer="True" />
<var name="tokens" type="list" qualifier="builtins" value="%5B%27%3CUNK&gt;%27%2C %27that%27%2C %27this%27%2C %27was%27%2C %27by%27%2C %27%3CUNK&gt;%27%2C %27%3CUNK&gt;%27%2C %27real%27%2C %27point%27%2C %27%3CUNK&gt;%27%2C %27on%27%2C %27the%27%2C %27extreme%27%2C %27%3CUNK&gt;%27%2C %27again%27%2C %27%3CUNK&gt;%27%5D" isContainer="True" shape="16" />
<var name="train_data_path" type="str" qualifier="builtins" value="sentiment.train.csv" />
<var name="train_dataset" type="TextDataset" qualifier="__main__" value="%3C__main__.TextDataset object at 0x00000232F2734410&gt;" isContainer="True" shape="160000" />
<var name="train_list" type="list" qualifier="builtins" value="%5B%28%5B   96     1   287    96   248    96     1   204 16850   291   110    24%2C    47    96   193   306    64    50    13    93%5D%2C array%281%29%29%2C %28%5B  96  884  234   21   96 1191 2472    7  693 1931 1926  268   96   96%2C   85 1688   96   21   67    7 1160  884 1578%5D%2C array%281%29%29%2C %28%5B  96    2  320   98 3569 7030   13   98    7  366   96  128 5745   14%2C  151   88  105 9655   96   88   96  123   59 1956  320   59  175   11%2C   15  128   88   96  140  105 9655 5834%5D%2C array%280%29%29%2C %28%5B  96    1  358   13  333  341   96   76 1775   83   96  241 1635 3070%2C   24   96   13 1196  729   61  305   95   96   76 1426   48    4  699%2C  117   96  115    4  486   24   96   96  356   76   96   62%5D%2C array%281%29%29%2C %28%5B  96 1427 1233   64  314  679   71   96    1  314 1131 1554 1555   98%2C  265 1905   96    1 7419   98 3204   87  310 1588  335   14  151  539%2C  232  287   14 1905  249    0    1    4  615  710   96   12   11%5D%2C array%281%29%29%2C %28%5B   96    64    88   314  1774  3195    24   345    24    96    26    96%2C    13  1178   341    ..." isContainer="True" shape="160000" />
<var name="train_loader" type="DataLoader" qualifier="torch.utils.data.dataloader" value="%3Ctorch.utils.data.dataloader.DataLoader object at 0x00000232F2735D00&gt;" isContainer="True" shape="160000" />
<var name="vocab_size" type="int" qualifier="builtins" value="40547" />
<var name="word_ids" type="Tensor" qualifier="torch" value="tensor%28%5B  96%2C  345%2C 8879%2C 1977%2C  385%2C 1364%2C   80%2C 4134%2C   24%2C 1105%2C  680%2C   19%2C%0A          13%2C   96%2C   96%2C   96%2C   94%2C   61%2C    0%2C   21%2C   13%2C   61%2C   96%2C   24%2C%0A          96%2C   96%2C  180%5D%29" isContainer="True" shape="(27,)" />
<var name="word_to_index" type="dict" qualifier="builtins" value="%7B%270%27%3A 6860%2C %2700%27%3A 7030%2C %27000%27%3A 7717%2C %27001%27%3A 38825%2C %27007%27%3A 28099%2C %2700am%27%3A 25993%2C %2701%27%3A 24762%2C %2702%27%3A 29846%2C %2703%27%3A 11089%2C %27039%27%3A 38140%2C %2704%27%3A 8057%2C %2705%27%3A 32280%2C %2706%27%3A 30353%2C %2707%27%3A 7063%2C %2708%27%3A 24586%2C %2709%27%3A 22275%2C %270f%27%3A 37971%2C %271%27%3A 793%2C %2710%27%3A 1684%2C %27100%27%3A 870%2C %271000%27%3A 10968%2C %2710000%27%3A 31123%2C %271000s%27%3A 20833%2C %271000x%27%3A 33996%2C %271001%27%3A 7910%2C %27100k%27%3A 39109%2C %27100s%27%3A 25367%2C %27100th%27%3A 879%2C %27101%27%3A 7005%2C %27101st%27%3A 26963%2C %27102%27%3A 29336%2C %27103%27%3A 31073%2C %27104%27%3A 31072%2C %27105%27%3A 27289%2C %27106%27%3A 11911%2C %271066%27%3A 34895%2C %27107%27%3A 733%2C %27108%27%3A 15245%2C %27109%27%3A 34772%2C %2710k%27%3A 16506%2C %2710th%27%3A 24530%2C %2710x%27%3A 22765%2C %2710yr%27%3A 28921%2C %2711%27%3A 3831%2C %27110%27%3A 18961%2C %271100%27%3A 36651%2C %27111%27%3A 18962%2C %27112%27%3A 11145%2C %27113%27%3A 32771%2C %27114%27%3A 24557%2C %27115%27%3A 15244%2C %27116%27%3A 19634%2C %27117%27%3A 39597%2C %27118%27%3A 21937%2C %27119%27%3A 38487%2C %2711pm%27%3A 25792%2C %2711th%27%3A 10687%2C %2712%27%3A 1681%2C %27120%27%3A 14299%2C %271200%27%3A 13958%2C %27121%27%3A 33184%2C %27122%27%3A 38431%2C %27123%27%3A 18402%2C %27124%27%3A 39041%2C %27125%27%3A 25024%2C %27126%27%3A 39242%2C %27127%27%3A 35211%2C %27128%27%3A 37280%2C %27129%27%3A 39683%2C %2712th%27%3A 10890%2C %2712yr%27%3A 17641%2C %2713%27%3A 3671%2C %27130%27..." isContainer="True" shape="40547" />
<var name="word_to_index_file" type="str" qualifier="builtins" value="./models/1st_model_word_to_index.pkl" />
</xml>
Text: We loved it! Lots of room for the kids to write do...
Predicted Label: 1.0, Actual Label: 1
Text: As a non-hunter I was surprised at how helpful the...
Predicted Label: 1.0, Actual Label: 1
Text: Purchased this along w/ANIMAL FARM. ANIMAL FARM is...
Predicted Label: 1.0, Actual Label: 0
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="RegexpTokenizer" type="ABCMeta" qualifier="abc" value="%3Cclass %27nltk.tokenize.regexp.RegexpTokenizer%27&gt;" isContainer="True" />
<var name="attention_weights" type="Tensor" qualifier="torch" value="tensor%28%5B%5B%5B0.0093%2C 0.0118%2C 0.0088%2C 0.0070%5D%2C%0A         %5B0.0046%2C 0.0879%2C 0.2792%2C 0.0863%5D%2C%0A         %5B0.0374%2C 0.0160%2C 0.0139%2C 0.0731...0%2C 0.0038%5D%2C%0A         %5B0.0739%2C 0.0764%2C 0.0853%2C 0.0072%5D%2C%0A         %5B0.0866%2C 0.1320%2C 0.1848%2C 0.0021%5D%5D%5D%2C grad_fn=%3CSoftmaxBackward0&gt;%29" isContainer="True" shape="(1, 27, 4)" />
<var name="attn" type="ndarray" qualifier="numpy" value="%5B%5B0.00820066 0.00635584 0.01305702 0.00312198%5D%2C %5B0.00520269 0.02486479 0.02307521 0.04692549%5D%2C %5B0.03225647 0.0108829  0.01926234 0.00199071%5D%2C %5B0.00187953 0.00795465 0.01671711 0.03298279%5D%2C %5B0.00820066 0.00635584 0.01305702 0.00312198%5D%2C %5B0.00820066 0.00635584 0.01305702 0.00312198%5D%2C %5B0.00820066 0.00635584 0.01305702 0.00312198%5D%2C %5B0.00820066 0.00635584 0.01305702 0.00312198%5D%2C %5B0.00857542 0.03072628 0.03424557 0.01345584%5D%2C %5B0.00324039 0.00502492 0.01194909 0.00888155%5D%2C %5B0.00211159 0.01295648 0.00999094 0.007664  %5D%2C %5B0.00481415 0.00528206 0.10072552 0.00823041%5D%2C %5B0.00820066 0.00635584 0.01305702 0.00312198%5D%2C %5B0.03341085 0.01210089 0.00324387 0.02058791%5D%2C %5B0.00060589 0.01022978 0.00996114 0.00133669%5D%2C %5B0.01212349 0.00832087 0.01306736 0.01432716%5D%2C %5B0.02746512 0.01324553 0.01614437 0.01530642%5D%2C %5B0.09771206 0.00418946 0.0098645  0.1676077 %5D%2C %5B0.10374302 0.0076138  0.00731716 0.1299005 %5D%2C %5B0.00496406 0.00123679 0.01363187 0.00354668%5D%2C %5B0.02537852 0.01263575 0.00284055 0.0298919 %5D%2C %5B0.00820066 ..." isContainer="True" shape="(54, 4)" />
<var name="avg_loss" type="float" qualifier="builtins" value="0.5819856327176094" />
<var name="batch_size" type="int" qualifier="builtins" value="1" />
<var name="best_f1" type="float64" qualifier="numpy" value="0.8370573902224065" shape="()" />
<var name="dev_data_path" type="str" qualifier="builtins" value="sentiment.dev.csv" />
<var name="dev_dataset" type="TextDataset" qualifier="__main__" value="%3C__main__.TextDataset object at 0x00000232EF22FBC0&gt;" isContainer="True" shape="20000" />
<var name="dev_f1" type="float64" qualifier="numpy" value="0.8180815876515987" shape="()" />
<var name="dev_list" type="list" qualifier="builtins" value="%5B%28%5B  96   96  193    4 7609   62   71   27  234   64  329   11   96    1%2C  629  314 7041 1811 1900 1018  177   96  104    4  105  106 4116   11%2C  264   11    1 1693  992   13 6499%5D%2C array%280%29%29%2C %28%5B   96   288     7  1160    71     3  1056   223   281    83 16366  2101%2C   268   607   140     7  1283    24 10093  1475    96 19270    98   951%2C 11996  2253   727   398     7    70    96     7 16366   781  2101   268%2C     7  3551    58    77  6499%5D%2C array%280%29%29%2C %28%5B  96    1   18 1818   27    0   21   96   15   88 5047   61    0   36%2C   61   96   13  104  190 4549   98   40   83 1712   61   96 1601   96%2C   96  551  200   81 1903    7   21  307   96 1043   96  772  200  172%2C   11  671 2278   96   96 1594   47   33 3211   15 3408  268    7  117%2C   24   33 5050%5D%2C array%281%29%29%2C %28%5B  96  193    4   18 1288   13  742 3822  862   96 3545 4912   77  128%2C 1236  884   96  128 3472  200  719 1755%5D%2C array%280%29%29%2C %28%5B  96  124  310  288    0   21   96    1  310   64   33 4288    6   96%2C  408  409 1695  151   62   11 ..." isContainer="True" shape="20000" />
<var name="dev_loader" type="DataLoader" qualifier="torch.utils.data.dataloader" value="%3Ctorch.utils.data.dataloader.DataLoader object at 0x00000232EF4AFBF0&gt;" isContainer="True" shape="20000" />
<var name="device" type="device" qualifier="torch" value="device%28type=%27cpu%27%29" isContainer="True" />
<var name="embedding_size" type="int" qualifier="builtins" value="50" />
<var name="embeddings_file_path" type="str" qualifier="builtins" value="./models/1st_model_embeddings_state_dict.pt" />
<var name="epoch" type="int" qualifier="builtins" value="0" />
<var name="epochs" type="int" qualifier="builtins" value="1" />
<var name="f" type="BufferedReader" qualifier="_io" value="%3C_io.BufferedReader name=%27./models/1st_model_index_to_word.pkl%27&gt;" isContainer="True" />
<var name="f1_scores" type="list" qualifier="builtins" value="%5B0.0%2C 0.21893018717289098%2C 0.29446606870874936%2C 0.5971060666401168%2C 0.48496934781003026%2C 0.6473546826255809%2C 0.7046656760772659%2C 0.6990291262135923%2C 0.7337489897240503%2C 0.7150351734827709%2C 0.7465940054495913%2C 0.749829893399864%2C 0.7700985761226725%2C 0.7603120264885797%2C 0.7680974799224591%2C 0.7579650274460982%2C 0.7954971857410882%2C 0.756486117432863%2C 0.7812174675360254%2C 0.7879639133488197%2C 0.768396679279381%2C 0.7723326799215906%2C 0.7731073573152253%2C 0.7886400873839432%2C 0.7827916505176901%2C 0.8015255045288415%2C 0.7956896551724137%2C 0.8103950103950104%2C 0.8042047143767255%2C 0.7872622733303848%2C 0.8037681622225771%2C 0.7996125699526474%2C 0.7792792792792793%2C 0.7899401728340351%2C 0.8128498927431591%2C 0.8020052827340844%2C 0.783627698345949%2C 0.8064017071218992%2C 0.7953884161405435%2C 0.8190939180802648%2C 0.8084879505224994%2C 0.7983602077070238%2C 0.7869421580155663%2C 0.8042299349240781%2C 0.805939524838013%2C 0.8133961166075869%2C 0.805041653142919%2C 0.8099191259171978%2C 0.8102107577626427%2C 0.8021671318338532%2C 0.792075892857142..." isContainer="True" shape="163" />
<var name="i" type="int" qualifier="builtins" value="2" />
<var name="index_to_word" type="dict" qualifier="builtins" value="%7B0%3A %27this%27%2C 1%3A %27was%27%2C 2%3A %27bought%27%2C 3%3A %27as%27%2C 4%3A %27a%27%2C 5%3A %27gift%27%2C 6%3A %27but%27%2C 7%3A %27the%27%2C 8%3A %27person%27%2C 9%3A %27who%27%2C 10%3A %27got%27%2C 11%3A %27it%27%2C 12%3A %27loved%27%2C 13%3A %27and%27%2C 14%3A %27they%27%2C 15%3A %27will%27%2C 16%3A %27use%27%2C 17%3A %27soon%27%2C 18%3A %27very%27%2C 19%3A %27well%27%2C 20%3A %27written%27%2C 21%3A %27book%27%2C 22%3A %27on%27%2C 23%3A %27period%27%2C 24%3A %27of%27%2C 25%3A %27world%27%2C 26%3A %27history%27%2C 27%3A %27with%27%2C 28%3A %27which%27%2C 29%3A %27i%27%2C 30%3A %27am%27%2C 31%3A %27familiar%27%2C 32%3A %27despite%27%2C 33%3A %27my%27%2C 34%3A %27familiarity%27%2C 35%3A %27subject%27%2C 36%3A %27area%27%2C 37%3A %27learned%27%2C 38%3A %27lot%27%2C 39%3A %27new%27%2C 40%3A %27information%27%2C 41%3A %27also%27%2C 42%3A %27one%27%2C 43%3A %27best%27%2C 44%3A %27concise%27%2C 45%3A %27descriptions%27%2C 46%3A %27wwii%27%2C 47%3A %27that%27%2C 48%3A %27have%27%2C 49%3A %27ever%27%2C 50%3A %27read%27%2C 51%3A %27thought%27%2C 52%3A %27provoking%27%2C 53%3A %27hot%27%2C 54%3A %27cross%27%2C 55%3A %27buns%27%2C 56%3A %27contains%27%2C 57%3A %27cast%27%2C 58%3A %27characters%27%2C 59%3A %27you%27%2C 60%3A %27fall%27%2C 61%3A %27in%27%2C 62%3A %27love%27%2C 63%3A %27want%27%2C 64%3A %27to%27%2C 65%3A %27hang%27%2C 66%3A %27out%27%2C 67%3A %27has%27%2C 68%3A %27few%27%2C 69%3A %27different%27%2C 70%3A %27plot%27%2C 71%3A %27story%27%2C 72%3A %27lines%27%2C 73%3A %27intersect%27%2C 74%3A %27unexpected%27%2C 75%3A %27ways%27%2C 76%3A %27stories%27%2C 77%3A %27are%27%2C 78%3A %27full%27%2C 79%3A %27h..." isContainer="True" shape="40547" />
<var name="index_to_word_file" type="str" qualifier="builtins" value="./models/1st_model_index_to_word.pkl" />
<var name="label" type="float" qualifier="builtins" value="1.0" />
<var name="labels" type="list" qualifier="builtins" value="%5B1%2C 1%2C 0%5D" isContainer="True" shape="3" />
<var name="learning_rate" type="float" qualifier="builtins" value="0.001" />
<var name="loss" type="Tensor" qualifier="torch" value="tensor%280.3133%2C grad_fn=%3CBinaryCrossEntropyWithLogitsBackward0&gt;%29" isContainer="True" shape="()" />
<var name="loss_function" type="BCEWithLogitsLoss" qualifier="torch.nn.modules.loss" value="BCEWithLogitsLoss%28%29" isContainer="True" />
<var name="losses" type="list" qualifier="builtins" value="%5B0.7063740156888961%2C 0.6690838242173195%2C 0.6710940192937851%2C 0.6416965731978417%2C 0.664360339820385%2C 0.6408256154060363%2C 0.6219880764484406%2C 0.6262354829907417%2C 0.6182727155685425%2C 0.6229372587800026%2C 0.6173186347484588%2C 0.6325475800037385%2C 0.5887129383683205%2C 0.6063905549049378%2C 0.5964332305192948%2C 0.6053036161065102%2C 0.576331036567688%2C 0.5984818696379661%2C 0.6024626339673996%2C 0.5853106815218926%2C 0.6045066975951194%2C 0.5990895519852638%2C 0.6025713908672333%2C 0.5945930997729302%2C 0.6004578600525856%2C 0.5832919328808784%2C 0.5881819829940796%2C 0.5846521648168563%2C 0.5884763289690018%2C 0.5964366135597229%2C 0.5868490883708%2C 0.5907454125285149%2C 0.6083347199559211%2C 0.5986561837792397%2C 0.5974684547781944%2C 0.5960528343319893%2C 0.5927959544062614%2C 0.5859969104528427%2C 0.6022085729837418%2C 0.5752854390740395%2C 0.5841937635540962%2C 0.5913211702108383%2C 0.6059050390124321%2C 0.5849579461812973%2C 0.5786286098361015%2C 0.5815764282941818%2C 0.5974919819831848%2C 0.5781187584400177%2C 0.5815025776624679%2C 0.5902935691475868%2C 0.58..." isContainer="True" shape="163" />
<var name="max_steps" type="int" qualifier="builtins" value="1000000000" />
<var name="model" type="DocumentAttentionClassifier" qualifier="__main__" value="DocumentAttentionClassifier%28%0A  %28embeddings%29%3A Embedding%2840547%2C 50%29%0A  %28linear%29%3A Linear%28in_features=200%2C out_features=1%2C bias=True%29%0A%29" isContainer="True" />
<var name="negative_samples" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B12445  Purchased this along w/ANIMAL FARM. ANIMAL FAR...      0%5D" isContainer="True" shape="(1, 2)" />
<var name="num_heads" type="int" qualifier="builtins" value="4" />
<var name="optimizer" type="AdamW" qualifier="torch.optim.adamw" value="AdamW %28%0AParameter Group 0%0A    amsgrad%3A False%0A    betas%3A %280.9%2C 0.999%29%0A    capturable%3A False%0A    differentiable%3A False%0A    eps%3A 1e-08%0A    foreach%3A None%0A    fused%3A None%0A    lr%3A 0.001%0A    maximize%3A False%0A    weight_decay%3A 0.01%0A%29" isContainer="True" />
<var name="patience" type="int" qualifier="builtins" value="30000" />
<var name="positive_samples" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B726   We loved it%21 Lots of room for the kids to writ...      1%5D %5B5711  As a non-hunter I was surprised at how helpful...      1%5D" isContainer="True" shape="(2, 2)" />
<var name="pre_label" type="float" qualifier="builtins" value="1.0" />
<var name="pred" type="float" qualifier="builtins" value="1.0" />
<var name="prediction" type="float" qualifier="builtins" value="1.0" />
<var name="predictions" type="list" qualifier="builtins" value="%5B0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C..." isContainer="True" shape="20000" />
<var name="probability" type="Tensor" qualifier="torch" value="tensor%28%5B0.6481%5D%29" isContainer="True" shape="(1,)" />
<var name="running_loss" type="float" qualifier="builtins" value="0.0" />
<var name="s" type="str" qualifier="builtins" value="%0AI%27m a big fan of his%2C and I have to say that this was a BIG letdown. It features%3A Stilted dialogue%2C no character development%2C no suspense%2C no description of Indian tradition and poor editing.%0A%0AAvoid at all costs.%0A" />
<var name="sample_text" type="str" qualifier="builtins" value="Although this product arrived on time and was nicely packaged%2C I found its quality lacking and performance subpar compared to other brands." />
<var name="selected_samples" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B726    We loved it%21 Lots of room for the kids to writ...      1%5D %5B5711   As a non-hunter I was surprised at how helpful...      1%5D %5B12445  Purchased this along w/ANIMAL FARM. ANIMAL FAR...      0%5D" isContainer="True" shape="(3, 2)" />
<var name="sent_dev_df" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B0      Picturing Perfect is a sappy love story with l...      0%5D %5B1      Seems like the same story as any other series ...      0%5D %5B2      I was very pleased with this book. I will be t...      1%5D %5B3      It is a very light and rather silly novel. The...      0%5D %5B4      I did not like this book. It was not to my tas...      0%5D %5B...                                                  ...    ...%5D %5B19995  Great content%2C the story is fantastic%2C but sho...      1%5D %5B19996  Typical book club book... Incest%2C child abuse%2C...      0%5D %5B19997  Fascinating book. Shorter than most Russell Ba...      1%5D %5B19998  This book is not well-organized%2C which is impo...      0%5D %5B19999  CAN WE CALL THIS A CLASSIC OF THE GENRE%3F I THI...      1%5D %5B%5D" isContainer="True" shape="(20000, 2)" />
<var name="sent_test_df" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27inst_id%27%2C %27text%27%2C %27predicted_label%27%5D %5B0            0  Really sad review as I absolutely loved the fi...   %5D %5B1            1  Excellent content%2C perfect for Christians who ...   %5D %5B2            2  This is an okay book if you need advice on bud...   %5D %5B3            3  This is one book you can%27t put down%21 This book...   %5D %5B4            4  There were to many names that I had no idenity...   %5D %5B...        ...                                                ...   %5D %5B19995    19995  I found this book to be a very entertaining an...   %5D %5B19996    19996  Wow%2C what a Middle School%21 Read this book your...   %5D %5B19997    19997  Not what I expected. Not enough about circular...   %5D %5B19998    19998  I like Joanne Fluke%27s mystery series starring ...   %5D %5B19999    19999  Grow some chickens%2C improve your land%2C make al...   %5D %5B%5D %5B0                  0.0  %5D %5B1                  1.0  %5D %5B2                  1.0  %5D %5B3                  1.0  %5D %5B4                  0.0  %5D %5B...                ...  %5D %5B19995         ..." isContainer="True" shape="(20000, 3)" />
<var name="sent_train_df" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B0       It was what I needed. There was no markings or...      1%5D %5B1       A cute little book. My wife gets the family wa...      1%5D %5B2       I bought these for 40.00 and for the price I j...      0%5D %5B3       It was interesting and enjoyable reading. Shor...      1%5D %5B4       A perfect ending to an amazing story. This was...      1%5D %5B...                                                   ...    ...%5D %5B159995  After reading every book Stephen King has to o...      1%5D %5B159996  Baby boomers who are experiencing %22aging eyeba...      0%5D %5B159997  Must read%2C must have%2C must read again. This bo...      1%5D %5B159998  Dr. Chopra%27s books are always enlightening and...      1%5D %5B159999  Boooring%21%21 Just enough to keep you intrigued f...      0%5D %5B%5D" isContainer="True" shape="(160000, 2)" />
<var name="step" type="int" qualifier="builtins" value="81499" />
<var name="steps_since_improvement" type="int" qualifier="builtins" value="30000" />
<var name="test_data" type="list" qualifier="builtins" value="%5Btensor%28%5B   96%2C   885%2C   626%2C     3%2C    96%2C  1132%2C    12%2C     7%2C   285%2C    21%2C%0A           96%2C    21%2C     1%2C  4050%2C     4%2C  6499...8504%2C  7595%2C     7%2C%0A         2087%2C   762%2C     7%2C   727%2C    42%2C   335%2C   385%2C   514%2C    98%2C   629%2C%0A          102%2C    13%2C   450%5D%29%2C tensor%28%5B  96%2C 1669%2C 1427%2C   98%2C   96%2C    9%2C   77%2C  207%2C 2651%2C  314%2C  804%2C   24%2C%0A           7%2C   96%2C   13%2C   86%2C 1887%2C   61%2C    7%2C  693%5D%29%2C tensor%28%5B   96%2C   193%2C   314%2C  4921%2C    21%2C   335%2C    59%2C   661%2C   633%2C    22%2C%0A         8229%2C    13%2C  3966%2C    96%2C   360%2C   345...  719%2C    96%2C   309%2C   497%2C    94%2C   719%2C  1105%2C%0A           59%2C    80%2C    32%2C     7%2C   269%2C   154%2C 20119%2C    64%2C     7%2C  2881%5D%29%2C tensor%28%5B  96%2C  193%2C   42%2C   21%2C   59%2C   92%2C  200%2C  506%2C  108%2C   96%2C   21%2C   15%2C%0A          80%2C   59%2C  218%2C   13%2C 8965%2C   59%2C   ...7%2C    4%2C  768%2C   13%2C%0A        3576%2C  677%2C   86%2C  678%2C   64%2C  287%2C  193%2C  537%2C  265%2C   96%2C  151%2C  329%2C%0A           0%2C  679%2C   21%5D%29%2C tensor%28%5B  96%2C  336%2C   64%2C  141%2C  352%2C   47%2C   96%2C  104%2C  204%2C   96%2C   27%2C   61%2C%0A       ..." isContainer="True" shape="20000" />
<var name="test_data_path" type="str" qualifier="builtins" value="sentiment.test.csv" />
<var name="test_list" type="list" qualifier="builtins" value="%5Btensor%28%5B   96%2C   885%2C   626%2C     3%2C    96%2C  1132%2C    12%2C     7%2C   285%2C    21%2C%0A           96%2C    21%2C     1%2C  4050%2C     4%2C  6499...8504%2C  7595%2C     7%2C%0A         2087%2C   762%2C     7%2C   727%2C    42%2C   335%2C   385%2C   514%2C    98%2C   629%2C%0A          102%2C    13%2C   450%5D%29%2C tensor%28%5B  96%2C 1669%2C 1427%2C   98%2C   96%2C    9%2C   77%2C  207%2C 2651%2C  314%2C  804%2C   24%2C%0A           7%2C   96%2C   13%2C   86%2C 1887%2C   61%2C    7%2C  693%5D%29%2C tensor%28%5B   96%2C   193%2C   314%2C  4921%2C    21%2C   335%2C    59%2C   661%2C   633%2C    22%2C%0A         8229%2C    13%2C  3966%2C    96%2C   360%2C   345...  719%2C    96%2C   309%2C   497%2C    94%2C   719%2C  1105%2C%0A           59%2C    80%2C    32%2C     7%2C   269%2C   154%2C 20119%2C    64%2C     7%2C  2881%5D%29%2C tensor%28%5B  96%2C  193%2C   42%2C   21%2C   59%2C   92%2C  200%2C  506%2C  108%2C   96%2C   21%2C   15%2C%0A          80%2C   59%2C  218%2C   13%2C 8965%2C   59%2C   ...7%2C    4%2C  768%2C   13%2C%0A        3576%2C  677%2C   86%2C  678%2C   64%2C  287%2C  193%2C  537%2C  265%2C   96%2C  151%2C  329%2C%0A           0%2C  679%2C   21%5D%29%2C tensor%28%5B  96%2C  336%2C   64%2C  141%2C  352%2C   47%2C   96%2C  104%2C  204%2C   96%2C   27%2C   61%2C%0A       ..." isContainer="True" shape="20000" />
<var name="test_output" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27inst_id%27%2C %27predicted_label%27%5D %5B0            0              0.0%5D %5B1            1              1.0%5D %5B2            2              1.0%5D %5B3            3              1.0%5D %5B4            4              0.0%5D %5B...        ...              ...%5D %5B19995    19995              1.0%5D %5B19996    19996              1.0%5D %5B19997    19997              0.0%5D %5B19998    19998              1.0%5D %5B19999    19999              1.0%5D %5B%5D" isContainer="True" shape="(20000, 2)" />
<var name="text" type="str" qualifier="builtins" value="When I first heard about this book I literally thought it was a baby book%2C but it was really good book. And any age could read this book." />
<var name="texts" type="list" qualifier="builtins" value="%5B%27We loved it%21 Lots of room for the kids to write down thier favorite things. We will keep this forever.%27%2C %27As a non-hunter I was surprised at how helpful the hunting analogies were to my decision making processes. I highly recommend this book to all aspiring entrepreneurs and ambitious sales people.%27%2C %27Purchased this along w/ANIMAL FARM. ANIMAL FARM is actually the item I%5C%27m reviewing%2C although it doesn%5C%27t come up. Editing an...every word w/ the letters %5C%27ive%5C%27 in it was replaced w/ %22Chapter IV%5C%27. Um...interesting. Returning ANIMAL FARM%2C not this book.%27%5D" isContainer="True" shape="3" />
<var name="tokenizer" type="RegexpTokenizer" qualifier="nltk.tokenize.regexp" value="RegexpTokenizer%28pattern=%27%5C%5Cw%2B%27%2C gaps=False%2C discard_empty=True%2C flags=re.UNICODE%7Cre.MULTILINE%7Cre.DOTALL%29" isContainer="True" />
<var name="tokens" type="list" qualifier="builtins" value="%5B%27%3CUNK&gt;%27%2C %27this%27%2C %27along%27%2C %27w%27%2C %27%3CUNK&gt;%27%2C %27%3CUNK&gt;%27%2C %27%3CUNK&gt;%27%2C %27%3CUNK&gt;%27%2C %27is%27%2C %27actually%27%2C %27the%27%2C %27item%27%2C %27%3CUNK&gt;%27%2C %27m%27%2C %27reviewing%27%2C %27although%27%2C %27it%27%2C %27doesn%27%2C %27t%27%2C %27come%27%2C %27up%27%2C %27%3CUNK&gt;%27%2C %27and%27%2C %27%3CUNK&gt;%27%2C %27score%27%2C %27for%27%2C %27this%27%2C %27print%27%2C %27should%27%2C %27be%27%2C %27a%27%2C %27%3CUNK&gt;%27%2C %27because%27%2C %27every%27%2C %27word%27%2C %27w%27%2C %27the%27%2C %27letters%27%2C %27ive%27%2C %27in%27%2C %27it%27%2C %27was%27%2C %27replaced%27%2C %27w%27%2C %27%3CUNK&gt;%27%2C %27%3CUNK&gt;%27%2C %27%3CUNK&gt;%27%2C %27interesting%27%2C %27%3CUNK&gt;%27%2C %27%3CUNK&gt;%27%2C %27%3CUNK&gt;%27%2C %27not%27%2C %27this%27%2C %27book%27%5D" isContainer="True" shape="54" />
<var name="train_data_path" type="str" qualifier="builtins" value="sentiment.train.csv" />
<var name="train_dataset" type="TextDataset" qualifier="__main__" value="%3C__main__.TextDataset object at 0x00000232F2734410&gt;" isContainer="True" shape="160000" />
<var name="train_list" type="list" qualifier="builtins" value="%5B%28%5B   96     1   287    96   248    96     1   204 16850   291   110    24%2C    47    96   193   306    64    50    13    93%5D%2C array%281%29%29%2C %28%5B  96  884  234   21   96 1191 2472    7  693 1931 1926  268   96   96%2C   85 1688   96   21   67    7 1160  884 1578%5D%2C array%281%29%29%2C %28%5B  96    2  320   98 3569 7030   13   98    7  366   96  128 5745   14%2C  151   88  105 9655   96   88   96  123   59 1956  320   59  175   11%2C   15  128   88   96  140  105 9655 5834%5D%2C array%280%29%29%2C %28%5B  96    1  358   13  333  341   96   76 1775   83   96  241 1635 3070%2C   24   96   13 1196  729   61  305   95   96   76 1426   48    4  699%2C  117   96  115    4  486   24   96   96  356   76   96   62%5D%2C array%281%29%29%2C %28%5B  96 1427 1233   64  314  679   71   96    1  314 1131 1554 1555   98%2C  265 1905   96    1 7419   98 3204   87  310 1588  335   14  151  539%2C  232  287   14 1905  249    0    1    4  615  710   96   12   11%5D%2C array%281%29%29%2C %28%5B   96    64    88   314  1774  3195    24   345    24    96    26    96%2C    13  1178   341    ..." isContainer="True" shape="160000" />
<var name="train_loader" type="DataLoader" qualifier="torch.utils.data.dataloader" value="%3Ctorch.utils.data.dataloader.DataLoader object at 0x00000232F2735D00&gt;" isContainer="True" shape="160000" />
<var name="vocab_size" type="int" qualifier="builtins" value="40547" />
<var name="word_ids" type="Tensor" qualifier="torch" value="tensor%28%5B  96%2C  345%2C 8879%2C 1977%2C  385%2C 1364%2C   80%2C 4134%2C   24%2C 1105%2C  680%2C   19%2C%0A          13%2C   96%2C   96%2C   96%2C   94%2C   61%2C    0%2C   21%2C   13%2C   61%2C   96%2C   24%2C%0A          96%2C   96%2C  180%5D%29" isContainer="True" shape="(27,)" />
<var name="word_to_index" type="dict" qualifier="builtins" value="%7B%270%27%3A 6860%2C %2700%27%3A 7030%2C %27000%27%3A 7717%2C %27001%27%3A 38825%2C %27007%27%3A 28099%2C %2700am%27%3A 25993%2C %2701%27%3A 24762%2C %2702%27%3A 29846%2C %2703%27%3A 11089%2C %27039%27%3A 38140%2C %2704%27%3A 8057%2C %2705%27%3A 32280%2C %2706%27%3A 30353%2C %2707%27%3A 7063%2C %2708%27%3A 24586%2C %2709%27%3A 22275%2C %270f%27%3A 37971%2C %271%27%3A 793%2C %2710%27%3A 1684%2C %27100%27%3A 870%2C %271000%27%3A 10968%2C %2710000%27%3A 31123%2C %271000s%27%3A 20833%2C %271000x%27%3A 33996%2C %271001%27%3A 7910%2C %27100k%27%3A 39109%2C %27100s%27%3A 25367%2C %27100th%27%3A 879%2C %27101%27%3A 7005%2C %27101st%27%3A 26963%2C %27102%27%3A 29336%2C %27103%27%3A 31073%2C %27104%27%3A 31072%2C %27105%27%3A 27289%2C %27106%27%3A 11911%2C %271066%27%3A 34895%2C %27107%27%3A 733%2C %27108%27%3A 15245%2C %27109%27%3A 34772%2C %2710k%27%3A 16506%2C %2710th%27%3A 24530%2C %2710x%27%3A 22765%2C %2710yr%27%3A 28921%2C %2711%27%3A 3831%2C %27110%27%3A 18961%2C %271100%27%3A 36651%2C %27111%27%3A 18962%2C %27112%27%3A 11145%2C %27113%27%3A 32771%2C %27114%27%3A 24557%2C %27115%27%3A 15244%2C %27116%27%3A 19634%2C %27117%27%3A 39597%2C %27118%27%3A 21937%2C %27119%27%3A 38487%2C %2711pm%27%3A 25792%2C %2711th%27%3A 10687%2C %2712%27%3A 1681%2C %27120%27%3A 14299%2C %271200%27%3A 13958%2C %27121%27%3A 33184%2C %27122%27%3A 38431%2C %27123%27%3A 18402%2C %27124%27%3A 39041%2C %27125%27%3A 25024%2C %27126%27%3A 39242%2C %27127%27%3A 35211%2C %27128%27%3A 37280%2C %27129%27%3A 39683%2C %2712th%27%3A 10890%2C %2712yr%27%3A 17641%2C %2713%27%3A 3671%2C %27130%27..." isContainer="True" shape="40547" />
<var name="word_to_index_file" type="str" qualifier="builtins" value="./models/1st_model_word_to_index.pkl" />
</xml>
Text: The author is creative to a fault. He's smart, wel...
Predicted Label: 1.0, Actual Label: 0
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="RegexpTokenizer" type="ABCMeta" qualifier="abc" value="%3Cclass %27nltk.tokenize.regexp.RegexpTokenizer%27&gt;" isContainer="True" />
<var name="attention_weights" type="Tensor" qualifier="torch" value="tensor%28%5B%5B%5B0.0093%2C 0.0118%2C 0.0088%2C 0.0070%5D%2C%0A         %5B0.0046%2C 0.0879%2C 0.2792%2C 0.0863%5D%2C%0A         %5B0.0374%2C 0.0160%2C 0.0139%2C 0.0731...0%2C 0.0038%5D%2C%0A         %5B0.0739%2C 0.0764%2C 0.0853%2C 0.0072%5D%2C%0A         %5B0.0866%2C 0.1320%2C 0.1848%2C 0.0021%5D%5D%5D%2C grad_fn=%3CSoftmaxBackward0&gt;%29" isContainer="True" shape="(1, 27, 4)" />
<var name="attn" type="ndarray" qualifier="numpy" value="%5B%5B8.23472906e-03 2.89742160e-03 4.17205831e-03 3.38709302e-04%5D%2C %5B4.30509336e-02 2.89626955e-03 5.67911612e-03 6.69019413e-04%5D%2C %5B8.61104392e-03 1.40071278e-02 1.09423548e-02 1.45984697e-03%5D%2C %5B1.84488727e-03 2.28635501e-02 2.67214868e-02 5.04992902e-04%5D%2C %5B3.54250930e-02 1.57479616e-03 1.82410493e-03 8.68211617e-04%5D%2C %5B1.85115337e-02 1.60736311e-03 2.48619192e-03 1.72437562e-04%5D%2C %5B1.71288953e-03 4.58385162e-02 8.18630122e-03 3.62165160e-02%5D%2C %5B8.23472906e-03 2.89742160e-03 4.17205831e-03 3.38709302e-04%5D%2C %5B1.70054026e-02 1.62425805e-02 1.44372007e-03 5.98643092e-04%5D%2C %5B2.23556370e-03 8.11736509e-02 2.29809340e-02 4.47609369e-03%5D%2C %5B7.81916920e-03 5.48643153e-03 1.02563918e-01 2.22173263e-03%5D%2C %5B4.77100387e-02 4.27502411e-04 2.70130695e-03 1.58265160e-04%5D%2C %5B5.19503374e-03 1.69910514e-03 1.01160239e-02 2.22899704e-04%5D%2C %5B1.85115337e-02 1.60736311e-03 2.48619192e-03 1.72437562e-04%5D%2C %5B2.85484847e-02 2.95456976e-01 1.10858306e-01 2.30733980e-03%5D%2C %5B7.34992186e-03 2.25074054e-03 7.44380581e-04 7.239804..." isContainer="True" shape="(53, 4)" />
<var name="avg_loss" type="float" qualifier="builtins" value="0.5819856327176094" />
<var name="batch_size" type="int" qualifier="builtins" value="1" />
<var name="best_f1" type="float64" qualifier="numpy" value="0.8370573902224065" shape="()" />
<var name="dev_data_path" type="str" qualifier="builtins" value="sentiment.dev.csv" />
<var name="dev_dataset" type="TextDataset" qualifier="__main__" value="%3C__main__.TextDataset object at 0x00000232EF22FBC0&gt;" isContainer="True" shape="20000" />
<var name="dev_f1" type="float64" qualifier="numpy" value="0.8180815876515987" shape="()" />
<var name="dev_list" type="list" qualifier="builtins" value="%5B%28%5B  96   96  193    4 7609   62   71   27  234   64  329   11   96    1%2C  629  314 7041 1811 1900 1018  177   96  104    4  105  106 4116   11%2C  264   11    1 1693  992   13 6499%5D%2C array%280%29%29%2C %28%5B   96   288     7  1160    71     3  1056   223   281    83 16366  2101%2C   268   607   140     7  1283    24 10093  1475    96 19270    98   951%2C 11996  2253   727   398     7    70    96     7 16366   781  2101   268%2C     7  3551    58    77  6499%5D%2C array%280%29%29%2C %28%5B  96    1   18 1818   27    0   21   96   15   88 5047   61    0   36%2C   61   96   13  104  190 4549   98   40   83 1712   61   96 1601   96%2C   96  551  200   81 1903    7   21  307   96 1043   96  772  200  172%2C   11  671 2278   96   96 1594   47   33 3211   15 3408  268    7  117%2C   24   33 5050%5D%2C array%281%29%29%2C %28%5B  96  193    4   18 1288   13  742 3822  862   96 3545 4912   77  128%2C 1236  884   96  128 3472  200  719 1755%5D%2C array%280%29%29%2C %28%5B  96  124  310  288    0   21   96    1  310   64   33 4288    6   96%2C  408  409 1695  151   62   11 ..." isContainer="True" shape="20000" />
<var name="dev_loader" type="DataLoader" qualifier="torch.utils.data.dataloader" value="%3Ctorch.utils.data.dataloader.DataLoader object at 0x00000232EF4AFBF0&gt;" isContainer="True" shape="20000" />
<var name="device" type="device" qualifier="torch" value="device%28type=%27cpu%27%29" isContainer="True" />
<var name="embedding_size" type="int" qualifier="builtins" value="50" />
<var name="embeddings_file_path" type="str" qualifier="builtins" value="./models/1st_model_embeddings_state_dict.pt" />
<var name="epoch" type="int" qualifier="builtins" value="0" />
<var name="epochs" type="int" qualifier="builtins" value="1" />
<var name="f" type="BufferedReader" qualifier="_io" value="%3C_io.BufferedReader name=%27./models/1st_model_index_to_word.pkl%27&gt;" isContainer="True" />
<var name="f1_scores" type="list" qualifier="builtins" value="%5B0.0%2C 0.21893018717289098%2C 0.29446606870874936%2C 0.5971060666401168%2C 0.48496934781003026%2C 0.6473546826255809%2C 0.7046656760772659%2C 0.6990291262135923%2C 0.7337489897240503%2C 0.7150351734827709%2C 0.7465940054495913%2C 0.749829893399864%2C 0.7700985761226725%2C 0.7603120264885797%2C 0.7680974799224591%2C 0.7579650274460982%2C 0.7954971857410882%2C 0.756486117432863%2C 0.7812174675360254%2C 0.7879639133488197%2C 0.768396679279381%2C 0.7723326799215906%2C 0.7731073573152253%2C 0.7886400873839432%2C 0.7827916505176901%2C 0.8015255045288415%2C 0.7956896551724137%2C 0.8103950103950104%2C 0.8042047143767255%2C 0.7872622733303848%2C 0.8037681622225771%2C 0.7996125699526474%2C 0.7792792792792793%2C 0.7899401728340351%2C 0.8128498927431591%2C 0.8020052827340844%2C 0.783627698345949%2C 0.8064017071218992%2C 0.7953884161405435%2C 0.8190939180802648%2C 0.8084879505224994%2C 0.7983602077070238%2C 0.7869421580155663%2C 0.8042299349240781%2C 0.805939524838013%2C 0.8133961166075869%2C 0.805041653142919%2C 0.8099191259171978%2C 0.8102107577626427%2C 0.8021671318338532%2C 0.792075892857142..." isContainer="True" shape="163" />
<var name="i" type="int" qualifier="builtins" value="0" />
<var name="index_to_word" type="dict" qualifier="builtins" value="%7B0%3A %27this%27%2C 1%3A %27was%27%2C 2%3A %27bought%27%2C 3%3A %27as%27%2C 4%3A %27a%27%2C 5%3A %27gift%27%2C 6%3A %27but%27%2C 7%3A %27the%27%2C 8%3A %27person%27%2C 9%3A %27who%27%2C 10%3A %27got%27%2C 11%3A %27it%27%2C 12%3A %27loved%27%2C 13%3A %27and%27%2C 14%3A %27they%27%2C 15%3A %27will%27%2C 16%3A %27use%27%2C 17%3A %27soon%27%2C 18%3A %27very%27%2C 19%3A %27well%27%2C 20%3A %27written%27%2C 21%3A %27book%27%2C 22%3A %27on%27%2C 23%3A %27period%27%2C 24%3A %27of%27%2C 25%3A %27world%27%2C 26%3A %27history%27%2C 27%3A %27with%27%2C 28%3A %27which%27%2C 29%3A %27i%27%2C 30%3A %27am%27%2C 31%3A %27familiar%27%2C 32%3A %27despite%27%2C 33%3A %27my%27%2C 34%3A %27familiarity%27%2C 35%3A %27subject%27%2C 36%3A %27area%27%2C 37%3A %27learned%27%2C 38%3A %27lot%27%2C 39%3A %27new%27%2C 40%3A %27information%27%2C 41%3A %27also%27%2C 42%3A %27one%27%2C 43%3A %27best%27%2C 44%3A %27concise%27%2C 45%3A %27descriptions%27%2C 46%3A %27wwii%27%2C 47%3A %27that%27%2C 48%3A %27have%27%2C 49%3A %27ever%27%2C 50%3A %27read%27%2C 51%3A %27thought%27%2C 52%3A %27provoking%27%2C 53%3A %27hot%27%2C 54%3A %27cross%27%2C 55%3A %27buns%27%2C 56%3A %27contains%27%2C 57%3A %27cast%27%2C 58%3A %27characters%27%2C 59%3A %27you%27%2C 60%3A %27fall%27%2C 61%3A %27in%27%2C 62%3A %27love%27%2C 63%3A %27want%27%2C 64%3A %27to%27%2C 65%3A %27hang%27%2C 66%3A %27out%27%2C 67%3A %27has%27%2C 68%3A %27few%27%2C 69%3A %27different%27%2C 70%3A %27plot%27%2C 71%3A %27story%27%2C 72%3A %27lines%27%2C 73%3A %27intersect%27%2C 74%3A %27unexpected%27%2C 75%3A %27ways%27%2C 76%3A %27stories%27%2C 77%3A %27are%27%2C 78%3A %27full%27%2C 79%3A %27h..." isContainer="True" shape="40547" />
<var name="index_to_word_file" type="str" qualifier="builtins" value="./models/1st_model_index_to_word.pkl" />
<var name="label" type="float" qualifier="builtins" value="1.0" />
<var name="labels" type="list" qualifier="builtins" value="%5B0%5D" isContainer="True" shape="1" />
<var name="learning_rate" type="float" qualifier="builtins" value="0.001" />
<var name="loss" type="Tensor" qualifier="torch" value="tensor%280.3133%2C grad_fn=%3CBinaryCrossEntropyWithLogitsBackward0&gt;%29" isContainer="True" shape="()" />
<var name="loss_function" type="BCEWithLogitsLoss" qualifier="torch.nn.modules.loss" value="BCEWithLogitsLoss%28%29" isContainer="True" />
<var name="losses" type="list" qualifier="builtins" value="%5B0.7063740156888961%2C 0.6690838242173195%2C 0.6710940192937851%2C 0.6416965731978417%2C 0.664360339820385%2C 0.6408256154060363%2C 0.6219880764484406%2C 0.6262354829907417%2C 0.6182727155685425%2C 0.6229372587800026%2C 0.6173186347484588%2C 0.6325475800037385%2C 0.5887129383683205%2C 0.6063905549049378%2C 0.5964332305192948%2C 0.6053036161065102%2C 0.576331036567688%2C 0.5984818696379661%2C 0.6024626339673996%2C 0.5853106815218926%2C 0.6045066975951194%2C 0.5990895519852638%2C 0.6025713908672333%2C 0.5945930997729302%2C 0.6004578600525856%2C 0.5832919328808784%2C 0.5881819829940796%2C 0.5846521648168563%2C 0.5884763289690018%2C 0.5964366135597229%2C 0.5868490883708%2C 0.5907454125285149%2C 0.6083347199559211%2C 0.5986561837792397%2C 0.5974684547781944%2C 0.5960528343319893%2C 0.5927959544062614%2C 0.5859969104528427%2C 0.6022085729837418%2C 0.5752854390740395%2C 0.5841937635540962%2C 0.5913211702108383%2C 0.6059050390124321%2C 0.5849579461812973%2C 0.5786286098361015%2C 0.5815764282941818%2C 0.5974919819831848%2C 0.5781187584400177%2C 0.5815025776624679%2C 0.5902935691475868%2C 0.58..." isContainer="True" shape="163" />
<var name="max_steps" type="int" qualifier="builtins" value="1000000000" />
<var name="model" type="DocumentAttentionClassifier" qualifier="__main__" value="DocumentAttentionClassifier%28%0A  %28embeddings%29%3A Embedding%2840547%2C 50%29%0A  %28linear%29%3A Linear%28in_features=200%2C out_features=1%2C bias=True%29%0A%29" isContainer="True" />
<var name="negative_sample" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B8285  The author is creative to a fault. He%27s smart%2C...      0%5D" isContainer="True" shape="(1, 2)" />
<var name="negative_samples" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B12445  Purchased this along w/ANIMAL FARM. ANIMAL FAR...      0%5D" isContainer="True" shape="(1, 2)" />
<var name="num_heads" type="int" qualifier="builtins" value="4" />
<var name="optimizer" type="AdamW" qualifier="torch.optim.adamw" value="AdamW %28%0AParameter Group 0%0A    amsgrad%3A False%0A    betas%3A %280.9%2C 0.999%29%0A    capturable%3A False%0A    differentiable%3A False%0A    eps%3A 1e-08%0A    foreach%3A None%0A    fused%3A None%0A    lr%3A 0.001%0A    maximize%3A False%0A    weight_decay%3A 0.01%0A%29" isContainer="True" />
<var name="patience" type="int" qualifier="builtins" value="30000" />
<var name="positive_samples" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B726   We loved it%21 Lots of room for the kids to writ...      1%5D %5B5711  As a non-hunter I was surprised at how helpful...      1%5D" isContainer="True" shape="(2, 2)" />
<var name="pre_label" type="float" qualifier="builtins" value="1.0" />
<var name="pred" type="float" qualifier="builtins" value="1.0" />
<var name="prediction" type="float" qualifier="builtins" value="1.0" />
<var name="predictions" type="list" qualifier="builtins" value="%5B0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C 1.0%2C 0.0%2C 0.0%2C 0.0%2C 1.0%2C..." isContainer="True" shape="20000" />
<var name="probability" type="Tensor" qualifier="torch" value="tensor%28%5B0.6481%5D%29" isContainer="True" shape="(1,)" />
<var name="running_loss" type="float" qualifier="builtins" value="0.0" />
<var name="s" type="str" qualifier="builtins" value="%0AI%27m a big fan of his%2C and I have to say that this was a BIG letdown. It features%3A Stilted dialogue%2C no character development%2C no suspense%2C no description of Indian tradition and poor editing.%0A%0AAvoid at all costs.%0A" />
<var name="sample_text" type="str" qualifier="builtins" value="Although this product arrived on time and was nicely packaged%2C I found its quality lacking and performance subpar compared to other brands." />
<var name="selected_samples" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B8285  The author is creative to a fault. He%27s smart%2C...      0%5D" isContainer="True" shape="(1, 2)" />
<var name="sent_dev_df" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B0      Picturing Perfect is a sappy love story with l...      0%5D %5B1      Seems like the same story as any other series ...      0%5D %5B2      I was very pleased with this book. I will be t...      1%5D %5B3      It is a very light and rather silly novel. The...      0%5D %5B4      I did not like this book. It was not to my tas...      0%5D %5B...                                                  ...    ...%5D %5B19995  Great content%2C the story is fantastic%2C but sho...      1%5D %5B19996  Typical book club book... Incest%2C child abuse%2C...      0%5D %5B19997  Fascinating book. Shorter than most Russell Ba...      1%5D %5B19998  This book is not well-organized%2C which is impo...      0%5D %5B19999  CAN WE CALL THIS A CLASSIC OF THE GENRE%3F I THI...      1%5D %5B%5D" isContainer="True" shape="(20000, 2)" />
<var name="sent_test_df" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27inst_id%27%2C %27text%27%2C %27predicted_label%27%5D %5B0            0  Really sad review as I absolutely loved the fi...   %5D %5B1            1  Excellent content%2C perfect for Christians who ...   %5D %5B2            2  This is an okay book if you need advice on bud...   %5D %5B3            3  This is one book you can%27t put down%21 This book...   %5D %5B4            4  There were to many names that I had no idenity...   %5D %5B...        ...                                                ...   %5D %5B19995    19995  I found this book to be a very entertaining an...   %5D %5B19996    19996  Wow%2C what a Middle School%21 Read this book your...   %5D %5B19997    19997  Not what I expected. Not enough about circular...   %5D %5B19998    19998  I like Joanne Fluke%27s mystery series starring ...   %5D %5B19999    19999  Grow some chickens%2C improve your land%2C make al...   %5D %5B%5D %5B0                  0.0  %5D %5B1                  1.0  %5D %5B2                  1.0  %5D %5B3                  1.0  %5D %5B4                  0.0  %5D %5B...                ...  %5D %5B19995         ..." isContainer="True" shape="(20000, 3)" />
<var name="sent_train_df" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27text%27%2C %27label%27%5D %5B0       It was what I needed. There was no markings or...      1%5D %5B1       A cute little book. My wife gets the family wa...      1%5D %5B2       I bought these for 40.00 and for the price I j...      0%5D %5B3       It was interesting and enjoyable reading. Shor...      1%5D %5B4       A perfect ending to an amazing story. This was...      1%5D %5B...                                                   ...    ...%5D %5B159995  After reading every book Stephen King has to o...      1%5D %5B159996  Baby boomers who are experiencing %22aging eyeba...      0%5D %5B159997  Must read%2C must have%2C must read again. This bo...      1%5D %5B159998  Dr. Chopra%27s books are always enlightening and...      1%5D %5B159999  Boooring%21%21 Just enough to keep you intrigued f...      0%5D %5B%5D" isContainer="True" shape="(160000, 2)" />
<var name="step" type="int" qualifier="builtins" value="81499" />
<var name="steps_since_improvement" type="int" qualifier="builtins" value="30000" />
<var name="test_data" type="list" qualifier="builtins" value="%5Btensor%28%5B   96%2C   885%2C   626%2C     3%2C    96%2C  1132%2C    12%2C     7%2C   285%2C    21%2C%0A           96%2C    21%2C     1%2C  4050%2C     4%2C  6499...8504%2C  7595%2C     7%2C%0A         2087%2C   762%2C     7%2C   727%2C    42%2C   335%2C   385%2C   514%2C    98%2C   629%2C%0A          102%2C    13%2C   450%5D%29%2C tensor%28%5B  96%2C 1669%2C 1427%2C   98%2C   96%2C    9%2C   77%2C  207%2C 2651%2C  314%2C  804%2C   24%2C%0A           7%2C   96%2C   13%2C   86%2C 1887%2C   61%2C    7%2C  693%5D%29%2C tensor%28%5B   96%2C   193%2C   314%2C  4921%2C    21%2C   335%2C    59%2C   661%2C   633%2C    22%2C%0A         8229%2C    13%2C  3966%2C    96%2C   360%2C   345...  719%2C    96%2C   309%2C   497%2C    94%2C   719%2C  1105%2C%0A           59%2C    80%2C    32%2C     7%2C   269%2C   154%2C 20119%2C    64%2C     7%2C  2881%5D%29%2C tensor%28%5B  96%2C  193%2C   42%2C   21%2C   59%2C   92%2C  200%2C  506%2C  108%2C   96%2C   21%2C   15%2C%0A          80%2C   59%2C  218%2C   13%2C 8965%2C   59%2C   ...7%2C    4%2C  768%2C   13%2C%0A        3576%2C  677%2C   86%2C  678%2C   64%2C  287%2C  193%2C  537%2C  265%2C   96%2C  151%2C  329%2C%0A           0%2C  679%2C   21%5D%29%2C tensor%28%5B  96%2C  336%2C   64%2C  141%2C  352%2C   47%2C   96%2C  104%2C  204%2C   96%2C   27%2C   61%2C%0A       ..." isContainer="True" shape="20000" />
<var name="test_data_path" type="str" qualifier="builtins" value="sentiment.test.csv" />
<var name="test_list" type="list" qualifier="builtins" value="%5Btensor%28%5B   96%2C   885%2C   626%2C     3%2C    96%2C  1132%2C    12%2C     7%2C   285%2C    21%2C%0A           96%2C    21%2C     1%2C  4050%2C     4%2C  6499...8504%2C  7595%2C     7%2C%0A         2087%2C   762%2C     7%2C   727%2C    42%2C   335%2C   385%2C   514%2C    98%2C   629%2C%0A          102%2C    13%2C   450%5D%29%2C tensor%28%5B  96%2C 1669%2C 1427%2C   98%2C   96%2C    9%2C   77%2C  207%2C 2651%2C  314%2C  804%2C   24%2C%0A           7%2C   96%2C   13%2C   86%2C 1887%2C   61%2C    7%2C  693%5D%29%2C tensor%28%5B   96%2C   193%2C   314%2C  4921%2C    21%2C   335%2C    59%2C   661%2C   633%2C    22%2C%0A         8229%2C    13%2C  3966%2C    96%2C   360%2C   345...  719%2C    96%2C   309%2C   497%2C    94%2C   719%2C  1105%2C%0A           59%2C    80%2C    32%2C     7%2C   269%2C   154%2C 20119%2C    64%2C     7%2C  2881%5D%29%2C tensor%28%5B  96%2C  193%2C   42%2C   21%2C   59%2C   92%2C  200%2C  506%2C  108%2C   96%2C   21%2C   15%2C%0A          80%2C   59%2C  218%2C   13%2C 8965%2C   59%2C   ...7%2C    4%2C  768%2C   13%2C%0A        3576%2C  677%2C   86%2C  678%2C   64%2C  287%2C  193%2C  537%2C  265%2C   96%2C  151%2C  329%2C%0A           0%2C  679%2C   21%5D%29%2C tensor%28%5B  96%2C  336%2C   64%2C  141%2C  352%2C   47%2C   96%2C  104%2C  204%2C   96%2C   27%2C   61%2C%0A       ..." isContainer="True" shape="20000" />
<var name="test_output" type="DataFrame" qualifier="pandas.core.frame" value="%5B%27inst_id%27%2C %27predicted_label%27%5D %5B0            0              0.0%5D %5B1            1              1.0%5D %5B2            2              1.0%5D %5B3            3              1.0%5D %5B4            4              0.0%5D %5B...        ...              ...%5D %5B19995    19995              1.0%5D %5B19996    19996              1.0%5D %5B19997    19997              0.0%5D %5B19998    19998              1.0%5D %5B19999    19999              1.0%5D %5B%5D" isContainer="True" shape="(20000, 2)" />
<var name="text" type="str" qualifier="builtins" value="When I first heard about this book I literally thought it was a baby book%2C but it was really good book. And any age could read this book." />
<var name="texts" type="list" qualifier="builtins" value="%5B%22The author is creative to a fault. He%27s smart%2C well educated and a pretentious show off. If this book were an emperor%2C he wou...clothes. A negative star would be lovely. I struggled through the bile to the bitter end and couldn%27t wait to be done with it.%22%5D" isContainer="True" shape="1" />
<var name="tokenizer" type="RegexpTokenizer" qualifier="nltk.tokenize.regexp" value="RegexpTokenizer%28pattern=%27%5C%5Cw%2B%27%2C gaps=False%2C discard_empty=True%2C flags=re.UNICODE%7Cre.MULTILINE%7Cre.DOTALL%29" isContainer="True" />
<var name="tokens" type="list" qualifier="builtins" value="%5B%27%3CUNK&gt;%27%2C %27author%27%2C %27is%27%2C %27creative%27%2C %27to%27%2C %27a%27%2C %27fault%27%2C %27%3CUNK&gt;%27%2C %27s%27%2C %27smart%27%2C %27well%27%2C %27educated%27%2C %27and%27%2C %27a%27%2C %27pretentious%27%2C %27show%27%2C %27off%27%2C %27%3CUNK&gt;%27%2C %27this%27%2C %27book%27%2C %27were%27%2C %27an%27%2C %27emperor%27%2C %27he%27%2C %27would%27%2C %27be%27%2C %27wearing%27%2C %27no%27%2C %27clothes%27%2C %27%3CUNK&gt;%27%2C %27negative%27%2C %27star%27%2C %27would%27%2C %27be%27%2C %27lovely%27%2C %27%3CUNK&gt;%27%2C %27struggled%27%2C %27through%27%2C %27the%27%2C %27bile%27%2C %27to%27%2C %27the%27%2C %27bitter%27%2C %27end%27%2C %27and%27%2C %27couldn%27%2C %27t%27%2C %27wait%27%2C %27to%27%2C %27be%27%2C %27done%27%2C %27with%27%2C %27it%27%5D" isContainer="True" shape="53" />
<var name="train_data_path" type="str" qualifier="builtins" value="sentiment.train.csv" />
<var name="train_dataset" type="TextDataset" qualifier="__main__" value="%3C__main__.TextDataset object at 0x00000232F2734410&gt;" isContainer="True" shape="160000" />
<var name="train_list" type="list" qualifier="builtins" value="%5B%28%5B   96     1   287    96   248    96     1   204 16850   291   110    24%2C    47    96   193   306    64    50    13    93%5D%2C array%281%29%29%2C %28%5B  96  884  234   21   96 1191 2472    7  693 1931 1926  268   96   96%2C   85 1688   96   21   67    7 1160  884 1578%5D%2C array%281%29%29%2C %28%5B  96    2  320   98 3569 7030   13   98    7  366   96  128 5745   14%2C  151   88  105 9655   96   88   96  123   59 1956  320   59  175   11%2C   15  128   88   96  140  105 9655 5834%5D%2C array%280%29%29%2C %28%5B  96    1  358   13  333  341   96   76 1775   83   96  241 1635 3070%2C   24   96   13 1196  729   61  305   95   96   76 1426   48    4  699%2C  117   96  115    4  486   24   96   96  356   76   96   62%5D%2C array%281%29%29%2C %28%5B  96 1427 1233   64  314  679   71   96    1  314 1131 1554 1555   98%2C  265 1905   96    1 7419   98 3204   87  310 1588  335   14  151  539%2C  232  287   14 1905  249    0    1    4  615  710   96   12   11%5D%2C array%281%29%29%2C %28%5B   96    64    88   314  1774  3195    24   345    24    96    26    96%2C    13  1178   341    ..." isContainer="True" shape="160000" />
<var name="train_loader" type="DataLoader" qualifier="torch.utils.data.dataloader" value="%3Ctorch.utils.data.dataloader.DataLoader object at 0x00000232F2735D00&gt;" isContainer="True" shape="160000" />
<var name="vocab_size" type="int" qualifier="builtins" value="40547" />
<var name="word_ids" type="Tensor" qualifier="torch" value="tensor%28%5B  96%2C  345%2C 8879%2C 1977%2C  385%2C 1364%2C   80%2C 4134%2C   24%2C 1105%2C  680%2C   19%2C%0A          13%2C   96%2C   96%2C   96%2C   94%2C   61%2C    0%2C   21%2C   13%2C   61%2C   96%2C   24%2C%0A          96%2C   96%2C  180%5D%29" isContainer="True" shape="(27,)" />
<var name="word_to_index" type="dict" qualifier="builtins" value="%7B%270%27%3A 6860%2C %2700%27%3A 7030%2C %27000%27%3A 7717%2C %27001%27%3A 38825%2C %27007%27%3A 28099%2C %2700am%27%3A 25993%2C %2701%27%3A 24762%2C %2702%27%3A 29846%2C %2703%27%3A 11089%2C %27039%27%3A 38140%2C %2704%27%3A 8057%2C %2705%27%3A 32280%2C %2706%27%3A 30353%2C %2707%27%3A 7063%2C %2708%27%3A 24586%2C %2709%27%3A 22275%2C %270f%27%3A 37971%2C %271%27%3A 793%2C %2710%27%3A 1684%2C %27100%27%3A 870%2C %271000%27%3A 10968%2C %2710000%27%3A 31123%2C %271000s%27%3A 20833%2C %271000x%27%3A 33996%2C %271001%27%3A 7910%2C %27100k%27%3A 39109%2C %27100s%27%3A 25367%2C %27100th%27%3A 879%2C %27101%27%3A 7005%2C %27101st%27%3A 26963%2C %27102%27%3A 29336%2C %27103%27%3A 31073%2C %27104%27%3A 31072%2C %27105%27%3A 27289%2C %27106%27%3A 11911%2C %271066%27%3A 34895%2C %27107%27%3A 733%2C %27108%27%3A 15245%2C %27109%27%3A 34772%2C %2710k%27%3A 16506%2C %2710th%27%3A 24530%2C %2710x%27%3A 22765%2C %2710yr%27%3A 28921%2C %2711%27%3A 3831%2C %27110%27%3A 18961%2C %271100%27%3A 36651%2C %27111%27%3A 18962%2C %27112%27%3A 11145%2C %27113%27%3A 32771%2C %27114%27%3A 24557%2C %27115%27%3A 15244%2C %27116%27%3A 19634%2C %27117%27%3A 39597%2C %27118%27%3A 21937%2C %27119%27%3A 38487%2C %2711pm%27%3A 25792%2C %2711th%27%3A 10687%2C %2712%27%3A 1681%2C %27120%27%3A 14299%2C %271200%27%3A 13958%2C %27121%27%3A 33184%2C %27122%27%3A 38431%2C %27123%27%3A 18402%2C %27124%27%3A 39041%2C %27125%27%3A 25024%2C %27126%27%3A 39242%2C %27127%27%3A 35211%2C %27128%27%3A 37280%2C %27129%27%3A 39683%2C %2712th%27%3A 10890%2C %2712yr%27%3A 17641%2C %2713%27%3A 3671%2C %27130%27..." isContainer="True" shape="40547" />
<var name="word_to_index_file" type="str" qualifier="builtins" value="./models/1st_model_word_to_index.pkl" />
