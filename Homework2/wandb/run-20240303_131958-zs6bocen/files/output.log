<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="RegexpTokenizer" type="ABCMeta" qualifier="abc" value="%3Cclass %27nltk.tokenize.regexp.RegexpTokenizer%27&gt;" isContainer="True" />
<var name="batch_sizes" type="list" qualifier="builtins" value="%5B2%2C 8%2C 32%2C 64%2C 128%2C 256%2C 512%2C 1024%2C 2048%2C 4096%2C 8192%5D" isContainer="True" shape="11" />
<var name="best_batch_size" type="int" qualifier="builtins" value="128" />
<var name="context_size" type="int" qualifier="builtins" value="12" />
<var name="corpus" type="Corpus" qualifier="__main__" value="%3C__main__.Corpus object at 0x000001ADDBBF1B20&gt;" isContainer="True" />
<var name="criterion" type="BCELoss" qualifier="torch.nn.modules.loss" value="BCELoss%28%29" isContainer="True" />
<var name="device" type="device" qualifier="torch" value="device%28type=%27cpu%27%29" isContainer="True" />
<var name="embedding_size" type="int" qualifier="builtins" value="50" />
<var name="estimated_times_per_epoch" type="list" qualifier="builtins" value="%5B%5D" isContainer="True" shape="0" />
<var name="last_loss_sum" type="int" qualifier="builtins" value="0" />
<var name="log_dir" type="str" qualifier="builtins" value="runs" />
<var name="loss_sum" type="int" qualifier="builtins" value="0" />
<var name="lr" type="float" qualifier="builtins" value="5e-05" />
<var name="max_step" type="NoneType" qualifier="builtins" value="None" />
<var name="model" type="Word2Vec" qualifier="__main__" value="Word2Vec%28%0A  %28target_embeddings%29%3A Embedding%2829065%2C 50%29%0A  %28context_embeddings%29%3A Embedding%2829065%2C 50%29%0A  %28sig%29%3A Sigmoid%28%29%0A%29" isContainer="True" />
<var name="num_epoch" type="int" qualifier="builtins" value="5" />
<var name="num_negative_samples_per_target" type="int" qualifier="builtins" value="2" />
<var name="optimizer" type="AdamW" qualifier="torch.optim.adamw" value="AdamW %28%0AParameter Group 0%0A    amsgrad%3A False%0A    betas%3A %280.9%2C 0.999%29%0A    capturable%3A False%0A    differentiable%3A False%0A    eps%3A 1e-08%0A    foreach%3A None%0A    fused%3A None%0A    lr%3A 5e-05%0A    maximize%3A False%0A    weight_decay%3A 0.01%0A%29" isContainer="True" />
<var name="stop_words" type="set" qualifier="builtins" value="%7B%27a%27%2C %27about%27%2C %27above%27%2C %27after%27%2C %27again%27%2C %27against%27%2C %27ain%27%2C %27all%27%2C %27am%27%2C %27an%27%2C %27and%27%2C %27any%27%2C %27are%27%2C %27aren%27%2C %22aren%27t%22%2C %27as%27%2C %27at%27%2C %27be%27%2C %27because%27%2C %27been%27%2C %27before%27%2C %27being%27%2C %27below%27%2C %27between%27%2C %27both%27%2C %27but%27%2C %27by%27%2C %27can%27%2C %27couldn%27%2C %22couldn%27t%22%2C %27d%27%2C %27did%27%2C %27didn%27%2C %22didn%27t%22%2C %27do%27%2C %27does%27%2C %27doesn%27%2C %22doesn%27t%22%2C %27doing%27%2C %27don%27%2C %22don%27t%22%2C %27down%27%2C %27during%27%2C %27each%27%2C %27few%27%2C %27for%27%2C %27from%27%2C %27further%27%2C %27had%27%2C %27hadn%27%2C %22hadn%27t%22%2C %27has%27%2C %27hasn%27%2C %22hasn%27t%22%2C %27have%27%2C %27haven%27%2C %22haven%27t%22%2C %27having%27%2C %27he%27%2C %27her%27%2C %27here%27%2C %27hers%27%2C %27herself%27%2C %27him%27%2C %27himself%27%2C %27his%27%2C %27how%27%2C %27i%27%2C %27if%27%2C %27in%27%2C %27into%27%2C %27is%27%2C %27isn%27%2C %22isn%27t%22%2C %27it%27%2C %22it%27s%22%2C %27its%27%2C %27itself%27%2C %27just%27%2C %27ll%27%2C %27m%27%2C %27ma%27%2C %27me%27%2C %27mightn%27%2C %22mightn%27t%22%2C %27more%27%2C %27most%27%2C %27mustn%27%2C %22mustn%27t%22%2C %27my%27%2C %27myself%27%2C %27needn%27%2C %22needn%27t%22%2C %27no%27%2C %27nor%27%2C %27not%27%2C %27now%27%2C %27o%27%2C %27of%27%2C %27off%27%2C %27on%27%2C %27once%27%2C %27only%27%2C %27or%27%2C %27other%27%2C %27our%27%2C %27ours%27%2C %27ourselves%27%2C %27out%27%2C %27over%27%2C %27own%27%2C %27re%27%2C %27s%27%2C %27same%27%2C %27shan%27%2C %22shan%27t%22%2C %27she%27%2C %22she%27s%22%2C %27should%27%2C %22should%27ve%22%2C %27shouldn%27%2C %22shouldn%27t%22%2C %27so%27%2C %27some%27%2C..." isContainer="True" shape="179" />
<var name="stopwords" type="WordListCorpusReader" qualifier="nltk.corpus.reader.wordlist" value="%3CWordListCorpusReader in %27C%3A%5C%5CUsers%5C%5C16979%5C%5CAppData%5C%5CRoaming%5C%5Cnltk_data%5C%5Ccorpora%5C%5Cstopwords%27&gt;" isContainer="True" />
<var name="times_per_batch" type="list" qualifier="builtins" value="%5B%5D" isContainer="True" shape="0" />
<var name="train_dataloader" type="DataLoader" qualifier="torch.utils.data.dataloader" value="%3Ctorch.utils.data.dataloader.DataLoader object at 0x000001ADDBD8FC50&gt;" isContainer="True" shape="39517" />
<var name="training_data" type="list" qualifier="builtins" value="%5B%281%2C %5B    2     3   637  1552     9    38   900   304 10189  2097     0  1130%5D%2C %5B1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %282%2C %5B    1     3     4  9568  2068  7647 18237   156 26645  2073   521  6972%5D%2C %5B1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %283%2C %5B    1     2     4     5  1845   367  6323 16394 18149   605  1565   456%5D%2C %5B1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %284%2C %5B    2     3     5     6  7799 13968     0  2123   912  1907  1160     0%5D%2C %5B1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %285%2C %5B   3    4    6 1050  488 6183 1449  417   74 4478    0 8488%5D%2C %5B1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %286%2C %5B    4     5     7  4959  1811    10  6183     0     0 28236 11530  2001%5D%2C %5B1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %280%2C %5B    5     6     7     8  9006 23693   213  3613  2895  1128  2072  1027%5D%2C %5B1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %287%2C %5B    6     8     9  3883  7656  1208  6510  1034   686    59  6608 28111%5D%2C %5B1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %288%2C %5B    7     9    11    42   409  2907    25  1349  5697 ..." isContainer="True" shape="5058077" />
<var name="vocab_size" type="int" qualifier="builtins" value="29065" />
<var name="window_size" type="int" qualifier="builtins" value="2" />
