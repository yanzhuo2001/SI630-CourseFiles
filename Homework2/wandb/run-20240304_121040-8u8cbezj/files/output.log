
Epoch  0
Step 100, Avg Loss: 0.6594374620914459
Step 200, Avg Loss: 0.5282400479912758
Step 300, Avg Loss: 0.4730995899438858
Step 400, Avg Loss: 0.45681241363286973
Step 500, Avg Loss: 0.4494984319806099
Step 600, Avg Loss: 0.4456832244992256
Step 700, Avg Loss: 0.4428903779387474
Step 800, Avg Loss: 0.4411688441038132
Step 900, Avg Loss: 0.4400681331753731
Step 1000, Avg Loss: 0.4390158012509346
Step 1100, Avg Loss: 0.4381306812167168
Step 1200, Avg Loss: 0.43734187841415406
Step 1300, Avg Loss: 0.43712877333164213
Step 1400, Avg Loss: 0.4358492913842201
Step 1500, Avg Loss: 0.4345658388733864
Step 1600, Avg Loss: 0.43347447514534
Step 1700, Avg Loss: 0.43163663417100906
Step 1800, Avg Loss: 0.43045701295137406
Epoch  1
Step 100, Avg Loss: 0.42731167435646056
Step 200, Avg Loss: 0.4258879989385605
Step 300, Avg Loss: 0.4246179288625717
Step 400, Avg Loss: 0.4231753641366959
Step 500, Avg Loss: 0.4219521945714951
Step 600, Avg Loss: 0.4210386773943901
Step 700, Avg Loss: 0.4194173187017441
Step 800, Avg Loss: 0.41849326074123383
Step 900, Avg Loss: 0.4174340775609016
Step 1000, Avg Loss: 0.41596745401620866
Step 1100, Avg Loss: 0.4150912353396416
Step 1200, Avg Loss: 0.4143409171700478
Step 1300, Avg Loss: 0.4130997896194458
Step 1400, Avg Loss: 0.4121535855531693
Step 1500, Avg Loss: 0.4111367264389992
Step 1600, Avg Loss: 0.4103546842932701
Step 1700, Avg Loss: 0.4093793392181396
Step 1800, Avg Loss: 0.4087007009983063
Epoch  2
Step 100, Avg Loss: 0.40613736003637313
<xml><var name="_dummy_ipython_val"  />
<var name="_dummy_special_var"  />
<var name="RegexpTokenizer" type="ABCMeta" qualifier="abc" value="%3Cclass %27nltk.tokenize.regexp.RegexpTokenizer%27&gt;" isContainer="True" />
<var name="avg_loss" type="float" qualifier="builtins" value="0.40613736003637313" />
<var name="best_batch_size" type="int" qualifier="builtins" value="4096" />
<var name="context_ids" type="Tensor" qualifier="torch" value="tensor%28%5B%5B 2680%2C  1548%2C   394%2C  ...%2C   200%2C  1212%2C   955%5D%2C%0A        %5B  213%2C   341%2C  4259%2C  ...%2C    21%2C  2750%2C 10711%5D%2C%0A        %5B ...%5B 1187%2C   281%2C  6864%2C  ...%2C     0%2C 13583%2C  1096%5D%2C%0A        %5B  693%2C 16467%2C  2605%2C  ...%2C  3044%2C  7465%2C 23962%5D%5D%2C dtype=torch.int32%29" isContainer="True" shape="(4096, 12)" />
<var name="context_size" type="int" qualifier="builtins" value="12" />
<var name="corpus" type="Corpus" qualifier="__main__" value="%3C__main__.Corpus object at 0x0000016961294950&gt;" isContainer="True" />
<var name="criterion" type="BCELoss" qualifier="torch.nn.modules.loss" value="BCELoss%28%29" isContainer="True" />
<var name="data" type="list" qualifier="builtins" value="%5Btensor%28%5B160%2C  63%2C 508%2C  ...%2C 336%2C 285%2C 218%5D%2C dtype=torch.int32%29%2C tensor%28%5B%5B 2680%2C  1548%2C   394%2C  ...%2C   200%2C  1212%2C   955%5D%2C%0A        %5B  213%2C   341%2C  4259%2C  ...%2C    21%2C  2750%2C 10711%5D%2C%0A        %5B ...%5B 1187%2C   281%2C  6864%2C  ...%2C     0%2C 13583%2C  1096%5D%2C%0A        %5B  693%2C 16467%2C  2605%2C  ...%2C  3044%2C  7465%2C 23962%5D%5D%2C dtype=torch.int32%29%2C tensor%28%5B%5B1.%2C 0.%2C 0.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A        %5B1.%2C 1.%2C 0.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A        %5B1.%2C 1.%2C 0.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A      ....%2C 1.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A        %5B1.%2C 1.%2C 0.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A        %5B1.%2C 1.%2C 0.%2C  ...%2C 0.%2C 0.%2C 0.%5D%5D%2C dtype=torch.float64%29%5D" isContainer="True" shape="3" />
<var name="device" type="device" qualifier="torch" value="device%28type=%27cpu%27%29" isContainer="True" />
<var name="embedding_size" type="int" qualifier="builtins" value="50" />
<var name="epoch" type="int" qualifier="builtins" value="2" />
<var name="f" type="BufferedWriter" qualifier="_io" value="%3C_io.BufferedWriter name=%27./models/1st_model_index_to_word.pkl%27&gt;" isContainer="True" />
<var name="index_to_word" type="dict" qualifier="builtins" value="%7B0%3A %27this%27%2C 1%3A %27was%27%2C 2%3A %27bought%27%2C 3%3A %27as%27%2C 4%3A %27a%27%2C 5%3A %27gift%27%2C 6%3A %27but%27%2C 7%3A %27the%27%2C 8%3A %27person%27%2C 9%3A %27who%27%2C 10%3A %27got%27%2C 11%3A %27it%27%2C 12%3A %27loved%27%2C 13%3A %27and%27%2C 14%3A %27they%27%2C 15%3A %27will%27%2C 16%3A %27use%27%2C 17%3A %27soon%27%2C 18%3A %27very%27%2C 19%3A %27well%27%2C 20%3A %27written%27%2C 21%3A %27book%27%2C 22%3A %27on%27%2C 23%3A %27period%27%2C 24%3A %27of%27%2C 25%3A %27world%27%2C 26%3A %27history%27%2C 27%3A %27with%27%2C 28%3A %27which%27%2C 29%3A %27i%27%2C 30%3A %27am%27%2C 31%3A %27familiar%27%2C 32%3A %27despite%27%2C 33%3A %27my%27%2C 34%3A %27familiarity%27%2C 35%3A %27subject%27%2C 36%3A %27area%27%2C 37%3A %27learned%27%2C 38%3A %27lot%27%2C 39%3A %27new%27%2C 40%3A %27information%27%2C 41%3A %27also%27%2C 42%3A %27one%27%2C 43%3A %27best%27%2C 44%3A %27concise%27%2C 45%3A %27descriptions%27%2C 46%3A %27wwii%27%2C 47%3A %27that%27%2C 48%3A %27have%27%2C 49%3A %27ever%27%2C 50%3A %27read%27%2C 51%3A %27thought%27%2C 52%3A %27provoking%27%2C 53%3A %27hot%27%2C 54%3A %27cross%27%2C 55%3A %27buns%27%2C 56%3A %27contains%27%2C 57%3A %27cast%27%2C 58%3A %27characters%27%2C 59%3A %27you%27%2C 60%3A %27fall%27%2C 61%3A %27in%27%2C 62%3A %27love%27%2C 63%3A %27want%27%2C 64%3A %27to%27%2C 65%3A %27hang%27%2C 66%3A %27out%27%2C 67%3A %27has%27%2C 68%3A %27few%27%2C 69%3A %27different%27%2C 70%3A %27plot%27%2C 71%3A %27story%27%2C 72%3A %27lines%27%2C 73%3A %27intersect%27%2C 74%3A %27unexpected%27%2C 75%3A %27ways%27%2C 76%3A %27stories%27%2C 77%3A %27are%27%2C 78%3A %27full%27%2C 79%3A %27h..." isContainer="True" shape="29216" />
<var name="labels" type="Tensor" qualifier="torch" value="tensor%28%5B%5B1.%2C 0.%2C 0.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A        %5B1.%2C 1.%2C 0.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A        %5B1.%2C 1.%2C 0.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A      ....%2C 1.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A        %5B1.%2C 1.%2C 0.%2C  ...%2C 0.%2C 0.%2C 0.%5D%2C%0A        %5B1.%2C 1.%2C 0.%2C  ...%2C 0.%2C 0.%2C 0.%5D%5D%2C dtype=torch.float64%29" isContainer="True" shape="(4096, 12)" />
<var name="loss" type="Tensor" qualifier="torch" value="tensor%280.4051%2C grad_fn=%3CBinaryCrossEntropyBackward0&gt;%29" isContainer="True" shape="()" />
<var name="loss_sum" type="float" qualifier="builtins" value="20.68401402235031" />
<var name="lr" type="float" qualifier="builtins" value="0.001" />
<var name="max_step" type="int" qualifier="builtins" value="1000000000" />
<var name="model" type="Word2Vec" qualifier="__main__" value="Word2Vec%28%0A  %28target_embeddings%29%3A Embedding%2829216%2C 50%29%0A  %28context_embeddings%29%3A Embedding%2829216%2C 50%29%0A  %28sig%29%3A Sigmoid%28%29%0A%29" isContainer="True" />
<var name="model_name" type="str" qualifier="builtins" value="1st_model" />
<var name="num_epoch" type="int" qualifier="builtins" value="10" />
<var name="num_negative_samples_per_target" type="int" qualifier="builtins" value="2" />
<var name="optimizer" type="Adam" qualifier="torch.optim.adam" value="Adam %28%0AParameter Group 0%0A    amsgrad%3A False%0A    betas%3A %280.9%2C 0.999%29%0A    capturable%3A False%0A    differentiable%3A False%0A    eps%3A 1e-08%0A    foreach%3A None%0A    fused%3A None%0A    lr%3A 0.001%0A    maximize%3A False%0A    weight_decay%3A 0%0A%29" isContainer="True" />
<var name="outputs" type="Tensor" qualifier="torch" value="tensor%28%5B%5B3.5164e-01%2C 3.0139e-01%2C 2.4342e-01%2C  ...%2C 2.5573e-04%2C 1.8617e-01%2C%0A         2.0857e-01%5D%2C%0A        %5B6.4063e-01%2C 4.6435e-...%2C%0A        %5B2.8910e-01%2C 8.9032e-02%2C 2.2664e-01%2C  ...%2C 2.4929e-01%2C 9.6820e-02%2C%0A         8.5081e-02%5D%5D%2C grad_fn=%3CSqueezeBackward0&gt;%29" isContainer="True" shape="(4096, 12)" />
<var name="step" type="int" qualifier="builtins" value="150" />
<var name="stop_words" type="set" qualifier="builtins" value="%7B%27a%27%2C %27about%27%2C %27above%27%2C %27after%27%2C %27again%27%2C %27against%27%2C %27ain%27%2C %27all%27%2C %27am%27%2C %27an%27%2C %27and%27%2C %27any%27%2C %27are%27%2C %27aren%27%2C %22aren%27t%22%2C %27as%27%2C %27at%27%2C %27be%27%2C %27because%27%2C %27been%27%2C %27before%27%2C %27being%27%2C %27below%27%2C %27between%27%2C %27both%27%2C %27but%27%2C %27by%27%2C %27can%27%2C %27couldn%27%2C %22couldn%27t%22%2C %27d%27%2C %27did%27%2C %27didn%27%2C %22didn%27t%22%2C %27do%27%2C %27does%27%2C %27doesn%27%2C %22doesn%27t%22%2C %27doing%27%2C %27don%27%2C %22don%27t%22%2C %27down%27%2C %27during%27%2C %27each%27%2C %27few%27%2C %27for%27%2C %27from%27%2C %27further%27%2C %27had%27%2C %27hadn%27%2C %22hadn%27t%22%2C %27has%27%2C %27hasn%27%2C %22hasn%27t%22%2C %27have%27%2C %27haven%27%2C %22haven%27t%22%2C %27having%27%2C %27he%27%2C %27her%27%2C %27here%27%2C %27hers%27%2C %27herself%27%2C %27him%27%2C %27himself%27%2C %27his%27%2C %27how%27%2C %27i%27%2C %27if%27%2C %27in%27%2C %27into%27%2C %27is%27%2C %27isn%27%2C %22isn%27t%22%2C %27it%27%2C %22it%27s%22%2C %27its%27%2C %27itself%27%2C %27just%27%2C %27ll%27%2C %27m%27%2C %27ma%27%2C %27me%27%2C %27mightn%27%2C %22mightn%27t%22%2C %27more%27%2C %27most%27%2C %27mustn%27%2C %22mustn%27t%22%2C %27my%27%2C %27myself%27%2C %27needn%27%2C %22needn%27t%22%2C %27no%27%2C %27nor%27%2C %27not%27%2C %27now%27%2C %27o%27%2C %27of%27%2C %27off%27%2C %27on%27%2C %27once%27%2C %27only%27%2C %27or%27%2C %27other%27%2C %27our%27%2C %27ours%27%2C %27ourselves%27%2C %27out%27%2C %27over%27%2C %27own%27%2C %27re%27%2C %27s%27%2C %27same%27%2C %27shan%27%2C %22shan%27t%22%2C %27she%27%2C %22she%27s%22%2C %27should%27%2C %22should%27ve%22%2C %27shouldn%27%2C %22shouldn%27t%22%2C %27so%27%2C %27some%27%2C..." isContainer="True" shape="179" />
<var name="stopwords" type="WordListCorpusReader" qualifier="nltk.corpus.reader.wordlist" value="%3CWordListCorpusReader in %27C%3A%5C%5CUsers%5C%5C16979%5C%5CAppData%5C%5CRoaming%5C%5Cnltk_data%5C%5Ccorpora%5C%5Cstopwords%27&gt;" isContainer="True" />
<var name="target_ids" type="Tensor" qualifier="torch" value="tensor%28%5B160%2C  63%2C 508%2C  ...%2C 336%2C 285%2C 218%5D%2C dtype=torch.int32%29" isContainer="True" shape="(4096,)" />
<var name="train_dataloader" type="DataLoader" qualifier="torch.utils.data.dataloader" value="%3Ctorch.utils.data.dataloader.DataLoader object at 0x0000016961CEDBE0&gt;" isContainer="True" shape="1843" />
<var name="training_data" type="list" qualifier="builtins" value="%5B%282%2C %5B   5  327  919   33   61  502  198 8452 1330    3  656 7931%5D%2C %5B1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %285%2C %5B    2     8  1288  6141 16699   106 26348  1296   269  5512  1160   210%5D%2C %5B1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %287%2C %5B    2     5     8  4877 14814 16593   310   923   250  6282 12190    26%5D%2C %5B1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %288%2C %5B   5   10 1360  503 1214  681    0  590  264 4763  811  229%5D%2C %5B1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %289%2C %5B   8   10   12   81 3292    4 6924 3669 1127   45 4732   13%5D%2C %5B1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %2810%2C %5B    8    12     4 28234  9806  1242  7397 22891   145     4  2550  1928%5D%2C %5B1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %2812%2C %5B   10     6   653  1293   578     0   222   193 18648  1116   814  2802%5D%2C %5B1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %2814%2C %5B   10    12    16  6152   703  5058   582   345    64  5148 28086    62%5D%2C %5B1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.%5D%29%2C %2815%2C %5B   12    16   225  1936    50   761  4310   283  6506 20142     7  1946%5D%2C ..." isContainer="True" shape="7545136" />
<var name="vocab_size" type="int" qualifier="builtins" value="29216" />
<var name="window_size" type="int" qualifier="builtins" value="2" />
<var name="word_to_index" type="dict" qualifier="builtins" value="%7B%270%27%3A 6669%2C %2700%27%3A 6830%2C %27000%27%3A 7476%2C %27007%27%3A 24096%2C %2701%27%3A 21836%2C %2702%27%3A 25554%2C %2703%27%3A 10593%2C %2704%27%3A 7803%2C %2705%27%3A 25933%2C %2706%27%3A 27739%2C %2707%27%3A 6863%2C %2708%27%3A 21706%2C %2709%27%3A 19994%2C %271%27%3A 788%2C %2710%27%3A 1667%2C %27100%27%3A 864%2C %271000%27%3A 10486%2C %271000s%27%3A 18881%2C %271001%27%3A 7662%2C %27100k%27%3A 28397%2C %27100th%27%3A 873%2C %27101%27%3A 6805%2C %27101st%27%3A 23354%2C %27102%27%3A 24843%2C %27103%27%3A 28903%2C %27104%27%3A 26685%2C %27105%27%3A 23564%2C %27106%27%3A 11336%2C %27107%27%3A 728%2C %27108%27%3A 14263%2C %27109%27%3A 24953%2C %2710k%27%3A 15342%2C %2710th%27%3A 21670%2C %2710x%27%3A 20378%2C %2711%27%3A 3768%2C %27110%27%3A 17373%2C %27111%27%3A 17374%2C %27112%27%3A 10642%2C %27113%27%3A 29007%2C %27114%27%3A 21685%2C %27115%27%3A 14262%2C %27116%27%3A 17929%2C %27117%27%3A 28869%2C %27118%27%3A 19735%2C %27119%27%3A 28776%2C %2711th%27%3A 10228%2C %2712%27%3A 1664%2C %27120%27%3A 13445%2C %271200%27%3A 13142%2C %27121%27%3A 27593%2C %27122%27%3A 29035%2C %27123%27%3A 16922%2C %27124%27%3A 28295%2C %27125%27%3A 22023%2C %27126%27%3A 28560%2C %27127%27%3A 25552%2C %27128%27%3A 27768%2C %2712th%27%3A 10418%2C %2713%27%3A 3613%2C %27130%27%3A 19995%2C %271300%27%3A 16108%2C %27131%27%3A 21232%2C %27133%27%3A 26384%2C %27134%27%3A 27974%2C %27135%27%3A 28264%2C %27136%27%3A 27783%2C %27138%27%3A 22966%2C %2713th%27%3A 14721%2C %2714%27%3A 3595%2C %27140%27%3A 3710%2C %271400%27%3A 27223%2C %27141%27%3A 28723%2C %27144%27%3A 17452%2C %27..." isContainer="True" shape="29216" />
<var name="writer" type="SummaryWriter" qualifier="torch.utils.tensorboard.writer" value="%3Ctorch.utils.tensorboard.writer.SummaryWriter object at 0x000001692EDAB0B0&gt;" isContainer="True" />
