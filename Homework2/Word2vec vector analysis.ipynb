{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2: Word2vec Vector Analysis\n",
    "\n",
    "*Important Note:* Start this notebook only after you've gotten your word2vec model up and running!\n",
    "\n",
    "Many NLP packages support working with word embeddings. In this notebook you can work through the various problems assigned in Task 3. We've provided the basic functionality for loading word vectors using [Gensim](https://radimrehurek.com/gensim/models/keyedvectors.html), a good library for learning and using word vectors, and for working with the vectors. \n",
    "\n",
    "One of the fun parts of word vectors is getting a sense of what they learned. Feel free to explore the vectors here! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-01T14:52:11.920321600Z",
     "start_time": "2024-03-01T14:52:11.852092800Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-01T14:52:11.948575500Z",
     "start_time": "2024-03-01T14:52:11.854614100Z"
    }
   },
   "outputs": [],
   "source": [
    "word_vectors = KeyedVectors.load_word2vec_format('./models/1st_model.kv', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-01T14:52:12.088755300Z",
     "start_time": "2024-03-01T14:52:11.936543Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar words to 'books': [('love', 0.9999497532844543), ('work', 0.9999481439590454), ('well', 0.9999444484710693), ('first', 0.9999440312385559), ('book', 0.9999424815177917), ('author', 0.9999419450759888), ('like', 0.9999396800994873), ('read', 0.9999395608901978), ('characters', 0.9999390244483948), ('would', 0.9999367594718933)]\n",
      "Most similar words to 'photos': [('set', 0.9993400573730469), ('done', 0.9993173480033875), ('missing', 0.9993118047714233), ('normal', 0.9993030428886414), ('lost', 0.999299943447113), ('took', 0.9992998242378235), ('make', 0.9992910027503967), ('mind', 0.9992880821228027), ('tale', 0.9992778301239014), ('original', 0.9992752075195312)]\n",
      "Most similar words to 'man': [('nice', 0.9998269081115723), ('especially', 0.99981290102005), ('quick', 0.9998125433921814), ('page', 0.9998111724853516), ('lacking', 0.999808132648468), ('times', 0.9998021721839905), ('ending', 0.9997940063476562), ('place', 0.9997866749763489), ('much', 0.9997830390930176), ('setting', 0.9997828602790833)]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Key 'football' not present in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# 计算每个目标词的最相似词并打印结果\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m target \u001B[38;5;129;01min\u001B[39;00m targets:\n\u001B[1;32m----> 6\u001B[0m     similar_words \u001B[38;5;241m=\u001B[39m \u001B[43mword_vectors\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msimilar_by_word\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMost similar words to \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtarget\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msimilar_words\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mD:\\Pycharm\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:862\u001B[0m, in \u001B[0;36mKeyedVectors.similar_by_word\u001B[1;34m(self, word, topn, restrict_vocab)\u001B[0m\n\u001B[0;32m    860\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msimilar_by_word\u001B[39m(\u001B[38;5;28mself\u001B[39m, word, topn\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, restrict_vocab\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    861\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Compatibility alias for similar_by_key().\"\"\"\u001B[39;00m\n\u001B[1;32m--> 862\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msimilar_by_key\u001B[49m\u001B[43m(\u001B[49m\u001B[43mword\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtopn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrestrict_vocab\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Pycharm\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:888\u001B[0m, in \u001B[0;36mKeyedVectors.similar_by_key\u001B[1;34m(self, key, topn, restrict_vocab)\u001B[0m\n\u001B[0;32m    864\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msimilar_by_key\u001B[39m(\u001B[38;5;28mself\u001B[39m, key, topn\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, restrict_vocab\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    865\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Find the top-N most similar keys.\u001B[39;00m\n\u001B[0;32m    866\u001B[0m \n\u001B[0;32m    867\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    886\u001B[0m \n\u001B[0;32m    887\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 888\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmost_similar\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpositive\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtopn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtopn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrestrict_vocab\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrestrict_vocab\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Pycharm\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:841\u001B[0m, in \u001B[0;36mKeyedVectors.most_similar\u001B[1;34m(self, positive, negative, topn, clip_start, clip_end, restrict_vocab, indexer)\u001B[0m\n\u001B[0;32m    838\u001B[0m         weight[idx] \u001B[38;5;241m=\u001B[39m item[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m    840\u001B[0m \u001B[38;5;66;03m# compute the weighted average of all keys\u001B[39;00m\n\u001B[1;32m--> 841\u001B[0m mean \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_mean_vector\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkeys\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpre_normalize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpost_normalize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_missing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    842\u001B[0m all_keys \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m    843\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_index(key) \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m keys \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, _KEY_TYPES) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhas_index_for(key)\n\u001B[0;32m    844\u001B[0m ]\n\u001B[0;32m    846\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m indexer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(topn, \u001B[38;5;28mint\u001B[39m):\n",
      "File \u001B[1;32mD:\\Pycharm\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:518\u001B[0m, in \u001B[0;36mKeyedVectors.get_mean_vector\u001B[1;34m(self, keys, weights, pre_normalize, post_normalize, ignore_missing)\u001B[0m\n\u001B[0;32m    516\u001B[0m         total_weight \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mabs\u001B[39m(weights[idx])\n\u001B[0;32m    517\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m ignore_missing:\n\u001B[1;32m--> 518\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mKey \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m not present in vocabulary\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    520\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m total_weight \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    521\u001B[0m     mean \u001B[38;5;241m=\u001B[39m mean \u001B[38;5;241m/\u001B[39m total_weight\n",
      "\u001B[1;31mKeyError\u001B[0m: \"Key 'football' not present in vocabulary\""
     ]
    }
   ],
   "source": [
    "# 选择10个目标词\n",
    "targets = [\"books\", \"photos\", \"man\", \"football\", \"son\", \"fantasy\", \"magnificent\", \"active\", \"insight\", \"super\"]\n",
    "\n",
    "# 计算每个目标词的最相似词并打印结果\n",
    "for target in targets:\n",
    "    similar_words = word_vectors.similar_by_word(target)\n",
    "    print(f\"Most similar words to '{target}': {similar_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-01T15:23:10.046139Z",
     "start_time": "2024-03-01T15:23:10.013339900Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_analogy(a, b, c):\n",
    "    return word_vectors.most_similar(positive=[b, c], negative=[a])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-01T15:23:19.068839500Z",
     "start_time": "2024-03-01T15:23:19.019627400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analogy 1: man - woman + king = class\n"
     ]
    }
   ],
   "source": [
    "# 五个有趣的词类比\n",
    "analogy_1 = get_analogy('man', 'woman', 'king')  # Queen\n",
    "# analogy_2 = get_analogy('school', 'university', 'teacher') # winter\n",
    "\n",
    "# 打印结果\n",
    "print(\"Analogy 1: {} - {} + {} = {}\".format('man', 'woman', 'king', analogy_1))\n",
    "# print(\"Analogy 2: {} - {} + {} = {}\".format('summer', 'hot', 'cold', analogy_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-01T14:52:12.020773Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
