{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2: Word2vec Vector Analysis\n",
    "\n",
    "*Important Note:* Start this notebook only after you've gotten your word2vec model up and running!\n",
    "\n",
    "Many NLP packages support working with word embeddings. In this notebook you can work through the various problems assigned in Task 3. We've provided the basic functionality for loading word vectors using [Gensim](https://radimrehurek.com/gensim/models/keyedvectors.html), a good library for learning and using word vectors, and for working with the vectors. \n",
    "\n",
    "One of the fun parts of word vectors is getting a sense of what they learned. Feel free to explore the vectors here! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-01T05:07:27.308006500Z",
     "start_time": "2024-03-01T05:07:27.258137200Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-01T05:07:28.702564300Z",
     "start_time": "2024-03-01T05:07:27.263656600Z"
    }
   },
   "outputs": [],
   "source": [
    "word_vectors = KeyedVectors.load_word2vec_format('./models/1st_model.kv', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-01T05:07:28.719273800Z",
     "start_time": "2024-03-01T05:07:28.702564300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([-0.24461013, -0.24444914, -0.24616927,  0.24130394,  0.24216819,\n       -0.23994693,  0.26128703,  0.23743668, -0.22223039, -0.24069509,\n        0.24169089,  0.2442502 , -0.24720648, -0.23974386, -0.21334736,\n        0.23675282,  0.23930179, -0.230349  ,  0.23815374,  0.24417   ,\n       -0.25888503,  0.23276587,  0.23550652,  0.23229983, -0.24458691,\n       -0.24042997,  0.24093594, -0.24271278, -0.22289899, -0.22750556,\n        0.26142213,  0.25664857,  0.24420586, -0.23595543,  0.2441588 ,\n       -0.28203505,  0.23484278,  0.24270374,  0.24447103,  0.21895288,\n       -0.24553147, -0.21835624,  0.24140723, -0.24341728, -0.23050313,\n        0.24151494,  0.232939  , -0.2418909 ,  0.24445504, -0.23761186],\n      dtype=float32)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-01T05:07:28.767194900Z",
     "start_time": "2024-03-01T05:07:28.712975600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar words to 'books': [('each', 0.9998968839645386), ('overcomplicated', 0.9998929500579834), ('elongated', 0.9998924136161804), ('interviewing', 0.9998897314071655), ('heroism', 0.9998864531517029), ('sabrina', 0.9998857378959656), ('grandiose', 0.9998847842216492), ('asbestos', 0.9998845458030701), ('sex', 0.9998843669891357), ('bordering', 0.9998832941055298)]\n",
      "Most similar words to 'photos': [('scholar', 0.999980628490448), ('salinger', 0.9999781847000122), ('wit', 0.9999752044677734), ('incompetent', 0.9999729990959167), ('executive', 0.9999727010726929), ('horse', 0.9999725818634033), ('introductions', 0.999972403049469), ('peasant', 0.9999720454216003), ('strangely', 0.9999719262123108), ('preposterous', 0.999971330165863)]\n",
      "Most similar words to 'man': [('punch', 0.9999710321426392), ('terrific', 0.9999706149101257), ('formula', 0.999970018863678), ('size', 0.999969482421875), ('classic', 0.9999693632125854), ('bang', 0.9999681711196899), ('direct', 0.9999680519104004), ('bulb', 0.9999679327011108), ('value', 0.9999676942825317), ('boy', 0.999967634677887)]\n",
      "Most similar words to 'football': [('watchmen', 0.9999673962593079), ('denning', 0.9999621510505676), ('franklin', 0.9999585151672363), ('locke', 0.9999561905860901), ('praised', 0.999955952167511), ('rowing', 0.9999558925628662), ('unending', 0.9999555349349976), ('wilbur', 0.9999544620513916), ('ruled', 0.999954342842102), ('segregation', 0.9999541640281677)]\n",
      "Most similar words to 'son': [('6', 0.9999591708183289), ('realm', 0.9999578595161438), ('tablet', 0.9999560117721558), ('rehash', 0.9999555349349976), ('contemporary', 0.9999525547027588), ('textured', 0.9999525547027588), ('17', 0.9999522566795349), ('70', 0.9999518394470215), ('self', 0.9999517798423767), ('27', 0.9999516606330872)]\n",
      "Most similar words to 'fantasy': [('comprehensive', 0.9999874830245972), ('government', 0.9999874234199524), ('catholic', 0.9999837875366211), ('incredible', 0.9999825358390808), ('medieval', 0.9999821782112122), ('thread', 0.9999808669090271), ('harry', 0.999980092048645), ('boyfriend', 0.9999800324440002), ('types', 0.9999797940254211), ('celebration', 0.9999797344207764)]\n",
      "Most similar words to 'magnificent': [('purposes', 0.999995231628418), ('baby', 0.9999940395355225), ('ignorant', 0.9999935030937195), ('constantly', 0.9999933242797852), ('ford', 0.9999926686286926), ('ex', 0.9999926686286926), ('neighbors', 0.9999925494194031), ('fold', 0.9999921321868896), ('darcy', 0.9999920129776001), ('beforehand', 0.9999919533729553)]\n",
      "Most similar words to 'active': [('drier', 0.999989926815033), ('passport', 0.9999898076057434), ('hired', 0.9999884963035583), ('endlessly', 0.9999878406524658), ('proven', 0.9999874830245972), ('everybody', 0.9999870657920837), ('paintings', 0.9999865889549255), ('backwards', 0.999986469745636), ('rabbit', 0.9999863505363464), ('brady', 0.9999862313270569)]\n",
      "Most similar words to 'insight': [('tent', 0.9999789595603943), ('tactical', 0.9999761581420898), ('apocalyptic', 0.9999755620956421), ('rooted', 0.9999744892120361), ('confessions', 0.9999744296073914), ('consequences', 0.9999741911888123), ('definitive', 0.9999730587005615), ('coincidence', 0.9999729990959167), ('special', 0.9999722242355347), ('throwing', 0.9999722242355347)]\n",
      "Most similar words to 'super': [('reasonable', 0.9999842047691345), ('sayings', 0.999981701374054), ('boyhood', 0.9999808073043823), ('imitation', 0.9999799132347107), ('joseph', 0.9999798536300659), ('failure', 0.9999794363975525), ('chess', 0.9999793767929077), ('christie', 0.9999793767929077), ('stalking', 0.9999790787696838), ('vincenzi', 0.9999788403511047)]\n"
     ]
    }
   ],
   "source": [
    "# 选择10个目标词\n",
    "targets = [\"books\", \"photos\", \"man\", \"football\", \"son\", \"fantasy\", \"magnificent\", \"active\", \"insight\", \"super\"]\n",
    "\n",
    "# 计算每个目标词的最相似词并打印结果\n",
    "for target in targets:\n",
    "    similar_words = word_vectors.similar_by_word(target)\n",
    "    print(f\"Most similar words to '{target}': {similar_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-01T05:07:28.767194900Z",
     "start_time": "2024-03-01T05:07:28.736350Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_analogy(a, b, c):\n",
    "    return word_vectors.most_similar(positive=[b, c], negative=[a])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-01T05:07:28.768194400Z",
     "start_time": "2024-03-01T05:07:28.741358700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analogy 1: man - woman + king = buttons\n",
      "Analogy 2: summer - hot + cold = satanism\n"
     ]
    }
   ],
   "source": [
    "# 五个有趣的词类比\n",
    "analogy_1 = get_analogy('man', 'woman', 'king')  # Queen\n",
    "analogy_2 = get_analogy('school', 'university', 'teacher') # winter\n",
    "\n",
    "# 打印结果\n",
    "print(\"Analogy 1: {} - {} + {} = {}\".format('man', 'woman', 'king', analogy_1))\n",
    "print(\"Analogy 2: {} - {} + {} = {}\".format('summer', 'hot', 'cold', analogy_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T05:07:28.768194400Z",
     "start_time": "2024-03-01T05:07:28.750992600Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
